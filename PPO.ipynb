{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57bc8db5-12ed-462a-afef-4e5652cf044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import GrayScaleObservation, ResizeObservation, FrameStack\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, VecTransposeImage\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.logger import HParam\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback, EvalCallback, CallbackList\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d3716d-7451-472e-8040-f69a4018ffc5",
   "metadata": {},
   "source": [
    "# Variable Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "530b811f-849f-4dfd-8e3b-4eea0026c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 5000000\n",
    "custom_eval_freq = 100000\n",
    "eval_episodes = 30\n",
    "experiment = \"training_3/PPO\"\n",
    "kombinationen_path = \"./3_kombinationen_PPO.csv\"\n",
    "ergebnisse_path = \"./3_ergebnisse_PPO.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46ddb602-4a6a-4533-a50a-8d053f7cd32f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_update_interval = 10000\n",
    "loop_start = 0\n",
    "vf_coef = 1\n",
    "clip_range = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ca7871-0e40-49b2-96c3-f3eff1b5d7b9",
   "metadata": {},
   "source": [
    "# UnverÃ¤nderte Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29fd1b50-e422-4228-87f4-c1862674b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = \"ALE/Pacman-v5\"\n",
    "frameskip = 3\n",
    "image_size = 84\n",
    "frame_stack = 4\n",
    "input_shape = (4, 84, 84)\n",
    "LOG_DIR = f\"./experiments/{experiment}/logs/\"\n",
    "BEST_MODEL_LOG_DIR = f\"./experiments/{experiment}/logs/best_model/\"\n",
    "EVAL_ENV_LOG_DIR = f\"./experiments/{experiment}/logs/eval_log/\"\n",
    "BEST_MODEL_DIR = f\"./experiments/{experiment}/train/\"\n",
    "MODEL_WEIGHTS_FILE = \"best_model.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea075e2-7fb7-44d8-943a-dac510d8f3f8",
   "metadata": {},
   "source": [
    "# Eigene CNN-Klasse und Callback-Klassen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4566dfb4-8d45-4130-ad4d-8f72ab76cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardTensorboardCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardTensorboardCallback, self).__init__(verbose)\n",
    "        self.total_reward = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        reward = self.locals[\"rewards\"]\n",
    "        self.total_reward += np.sum(reward)\n",
    "\n",
    "        if self.locals[\"dones\"][0]:\n",
    "            self.logger.record(\"total_reward_steps\", self.total_reward)\n",
    "            \n",
    "            self.total_reward = 0\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a13e758f-ab3d-4790-937e-5a60dc2a6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParamCallback(BaseCallback):\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        hparam_dict = {\n",
    "            \"algorithm\": self.model.__class__.__name__,\n",
    "            \"learning rate\": self.model.learning_rate,\n",
    "            \"gamma\": self.model.gamma,\n",
    "            \"batch size\": self.model.batch_size,\n",
    "            \"entropiekoeffizient\": self.model.ent_coef\n",
    "        }\n",
    "\n",
    "        metric_dict = {\n",
    "            \"rollout/ep_len_mean\": 0,\n",
    "            \"train/value_loss\": 0.0,\n",
    "        }\n",
    "        self.logger.record(\n",
    "            \"hparams\",\n",
    "            HParam(hparam_dict, metric_dict),\n",
    "            exclude=(\"stdout\", \"log\", \"json\", \"csv\"),\n",
    "        )\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cf82673-f09b-4dbf-9dab-5a9d96c4a2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvalCallback(EvalCallback):\n",
    "    def _on_step(self) -> bool:\n",
    "        continue_training = True\n",
    "\n",
    "        if self.eval_freq > 0 and self.n_calls % self.eval_freq == 0 and self.n_calls >= 500000:\n",
    "            # Sync training and eval env if there is VecNormalize\n",
    "            if self.model.get_vec_normalize_env() is not None:\n",
    "                try:\n",
    "                    sync_envs_normalization(self.training_env, self.eval_env)\n",
    "                except AttributeError as e:\n",
    "                    raise AssertionError(\n",
    "                        \"Training and eval env are not wrapped the same way, \"\n",
    "                        \"see https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html#evalcallback \"\n",
    "                        \"and warning above.\"\n",
    "                    ) from e\n",
    "\n",
    "            # Reset success rate buffer\n",
    "            self._is_success_buffer = []\n",
    "\n",
    "            episode_rewards, episode_lengths = evaluate_policy(\n",
    "                self.model,\n",
    "                self.eval_env,\n",
    "                n_eval_episodes=self.n_eval_episodes,\n",
    "                render=self.render,\n",
    "                deterministic=self.deterministic,\n",
    "                return_episode_rewards=True,\n",
    "                warn=self.warn,\n",
    "                callback=self._log_success_callback,\n",
    "            )\n",
    "\n",
    "            if self.log_path is not None:\n",
    "                self.evaluations_timesteps.append(self.num_timesteps)\n",
    "                self.evaluations_results.append(episode_rewards)\n",
    "                self.evaluations_length.append(episode_lengths)\n",
    "\n",
    "                kwargs = {}\n",
    "                # Save success log if present\n",
    "                if len(self._is_success_buffer) > 0:\n",
    "                    self.evaluations_successes.append(self._is_success_buffer)\n",
    "                    kwargs = dict(successes=self.evaluations_successes)\n",
    "\n",
    "                np.savez(\n",
    "                    self.log_path,\n",
    "                    timesteps=self.evaluations_timesteps,\n",
    "                    results=self.evaluations_results,\n",
    "                    ep_lengths=self.evaluations_length,\n",
    "                    **kwargs,\n",
    "                )\n",
    "\n",
    "            mean_reward, std_reward = np.mean(episode_rewards), np.std(episode_rewards)\n",
    "            mean_ep_length, std_ep_length = np.mean(episode_lengths), np.std(episode_lengths)\n",
    "            self.last_mean_reward = mean_reward\n",
    "\n",
    "            if self.verbose >= 1:\n",
    "                print(f\"Eval num_timesteps={self.num_timesteps}, \" f\"episode_reward={mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "                print(f\"Episode length: {mean_ep_length:.2f} +/- {std_ep_length:.2f}\")\n",
    "            # Add to current Logger\n",
    "            self.logger.record(\"eval/mean_reward\", float(mean_reward))\n",
    "            self.logger.record(\"eval/mean_ep_length\", mean_ep_length)\n",
    "\n",
    "            if len(self._is_success_buffer) > 0:\n",
    "                success_rate = np.mean(self._is_success_buffer)\n",
    "                if self.verbose >= 1:\n",
    "                    print(f\"Success rate: {100 * success_rate:.2f}%\")\n",
    "                self.logger.record(\"eval/success_rate\", success_rate)\n",
    "\n",
    "            # Dump log so the evaluation results are printed with the correct timestep\n",
    "            self.logger.record(\"time/total_timesteps\", self.num_timesteps, exclude=\"tensorboard\")\n",
    "            self.logger.dump(self.num_timesteps)\n",
    "\n",
    "            if mean_reward > self.best_mean_reward:\n",
    "                if self.verbose >= 1:\n",
    "                    print(\"New best mean reward!\")\n",
    "                if self.best_model_save_path is not None:\n",
    "                    self.model.save(os.path.join(self.best_model_save_path, \"best_model\"))\n",
    "                self.best_mean_reward = mean_reward\n",
    "                # Trigger callback on new best model, if needed\n",
    "                if self.callback_on_new_best is not None:\n",
    "                    continue_training = self.callback_on_new_best.on_step()\n",
    "\n",
    "            # Trigger callback after every evaluation, if needed\n",
    "            if self.callback is not None:\n",
    "                continue_training = continue_training and self._on_event()\n",
    "\n",
    "        return continue_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f793624-02f5-48c0-80ca-b86dc97036dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kombinationen = []\n",
    "\n",
    "with open(kombinationen_path, 'r') as file:\n",
    "    reader = csv.reader(file, delimiter='\\t')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        row = [int(val) if val.isdigit() else float(val.replace(',', '.')) for val in row]\n",
    "        kombinationen.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f93e75-5620-4578-8da2-06e9188d0260",
   "metadata": {},
   "source": [
    "# Erstellung der Trainungs- und Testumgebung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16881c4d-95c7-4e94-bd4f-6a9de7ebd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(game, frameskip=frameskip)\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "env = ResizeObservation(env, image_size)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "env = VecFrameStack(env, frame_stack, channels_order=\"last\")\n",
    "\n",
    "eval_env = gym.make(game, frameskip=frameskip)\n",
    "eval_env = Monitor(eval_env, EVAL_ENV_LOG_DIR)\n",
    "eval_env = GrayScaleObservation(eval_env, keep_dim=True)\n",
    "eval_env = ResizeObservation(eval_env, image_size)\n",
    "eval_env = DummyVecEnv([lambda: eval_env])\n",
    "eval_env = VecFrameStack(eval_env, frame_stack, channels_order=\"last\")\n",
    "eval_env = VecTransposeImage(eval_env)\n",
    "\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b13b55-ff15-46bc-a91b-fdec0a0fc3c1",
   "metadata": {},
   "source": [
    "# Erstellung der Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa00d4e0-6817-4e49-b3d5-2028a07e87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparam_callback = HParamCallback()\n",
    "reward_callback = RewardTensorboardCallback()\n",
    "eval_callback = CustomEvalCallback(eval_env, best_model_save_path=BEST_MODEL_DIR,\n",
    "                                  log_path=BEST_MODEL_LOG_DIR, eval_freq=custom_eval_freq,\n",
    "                                  deterministic=True, render=False, n_eval_episodes=eval_episodes)\n",
    "callback_list = CallbackList([eval_callback, reward_callback, hparam_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f56d4a-7220-44d3-b19f-a6fe4952eefb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "427ff848-13ee-4d75-af6b-10c53fa37e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "Logging to ./experiments/training_3/PPO/logs/0/PPO_1\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 325      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "| total_reward_steps | 9        |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 334          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| total_reward_steps      | 15           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016605644 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | -0.00697     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.108        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000663    |\n",
      "|    value_loss           | 0.109        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 343          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| total_reward_steps      | 13           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022300226 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0803       |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00229     |\n",
      "|    value_loss           | 0.118        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| total_reward_steps      | 20           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026813508 |\n",
      "|    clip_fraction        | 0.0943       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.119        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    value_loss           | 0.154        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| total_reward_steps      | 13          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002210483 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| total_reward_steps      | 15           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016466719 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0546       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000801    |\n",
      "|    value_loss           | 0.128        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| total_reward_steps      | 14           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010548879 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.172        |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 0.135        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 356          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| total_reward_steps      | 11           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021511137 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.179        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 0.155        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| total_reward_steps      | 11           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020007384 |\n",
      "|    clip_fraction        | 0.0658       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0657       |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 0.0988       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001727976 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0638      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| total_reward_steps      | 16           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016370841 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0898       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 0.128        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| total_reward_steps      | 14          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002080935 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| total_reward_steps      | 7            |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028158831 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.57        |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.123        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 0.093        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| total_reward_steps      | 15           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016348778 |\n",
      "|    clip_fraction        | 0.0966       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0953       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 357          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| total_reward_steps      | 19           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020366039 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0269       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 357        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 91         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00213111 |\n",
      "|    clip_fraction        | 0.0955     |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.54      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.048      |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.00548   |\n",
      "|    value_loss           | 0.0998     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| total_reward_steps      | 5            |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021143602 |\n",
      "|    clip_fraction        | 0.0881       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.062        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0455       |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    value_loss           | 1.17         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001946476 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| total_reward_steps      | 15           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029867264 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.0735       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.619        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    value_loss           | 0.18         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 358          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| total_reward_steps      | 13           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024582625 |\n",
      "|    clip_fraction        | 0.0975       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0116       |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 0.144        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| total_reward_steps      | 20           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028363306 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00853      |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00863     |\n",
      "|    value_loss           | 0.145        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| total_reward_steps      | 14           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028184396 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.56        |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00142     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| total_reward_steps      | 10           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031963782 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.55        |\n",
      "|    explained_variance   | 0.317        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0515       |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00881     |\n",
      "|    value_loss           | 0.127        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| total_reward_steps      | 11           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031596525 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.54        |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.062        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 359          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| total_reward_steps      | 34           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031462433 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0245       |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.0086      |\n",
      "|    value_loss           | 0.153        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| total_reward_steps      | 10          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003773651 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0618      |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| total_reward_steps      | 9           |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003683672 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.2         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 360       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 159       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| total_reward_steps      | 19        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0035449 |\n",
      "|    clip_fraction        | 0.185     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.53     |\n",
      "|    explained_variance   | 0.417     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0163    |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -0.0104   |\n",
      "|    value_loss           | 0.123     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| total_reward_steps      | 17           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034226293 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0192       |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    value_loss           | 0.0966       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| total_reward_steps      | 21           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040569776 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.51        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.262        |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| total_reward_steps      | 37           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030996457 |\n",
      "|    clip_fraction        | 0.137        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.144        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0945       |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 0.889        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 181         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| total_reward_steps      | 16          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003470876 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0792      |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| total_reward_steps      | 12           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040944195 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.044        |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0105      |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| total_reward_steps      | 26           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035765553 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.135        |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 0.102        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| total_reward_steps      | 26           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038477906 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.46        |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.129        |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    value_loss           | 0.138        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| total_reward_steps      | 39           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038312497 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0411       |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00986     |\n",
      "|    value_loss           | 0.221        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| total_reward_steps      | 18          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004285825 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.171       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| total_reward_steps      | 26           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039429846 |\n",
      "|    clip_fraction        | 0.212        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.125        |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00943     |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| total_reward_steps      | 25           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042581027 |\n",
      "|    clip_fraction        | 0.205        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0327       |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0116      |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| total_reward_steps      | 29           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041510314 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0485       |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.0111      |\n",
      "|    value_loss           | 0.15         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| total_reward_steps      | 27          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004249038 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 0.735       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006118557 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003825896 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 0.663       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005458855 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00441    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 255        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| total_reward_steps      | 49         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00446723 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.115      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0321     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00843   |\n",
      "|    value_loss           | 0.185      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 260          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| total_reward_steps      | 44           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044627814 |\n",
      "|    clip_fraction        | 0.229        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.232        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0662       |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 0.729        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| total_reward_steps      | 16           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042631454 |\n",
      "|    clip_fraction        | 0.237        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0025      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 0.104        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| total_reward_steps      | 17           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039969385 |\n",
      "|    clip_fraction        | 0.209        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0153       |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.0112      |\n",
      "|    value_loss           | 0.139        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| total_reward_steps      | 25           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060416334 |\n",
      "|    clip_fraction        | 0.241        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0307       |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 0.101        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 102400       |\n",
      "| total_reward_steps      | 12           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044387104 |\n",
      "|    clip_fraction        | 0.203        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.163        |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 0.156        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| total_reward_steps      | 33           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054743076 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -0.0786      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    value_loss           | 3.55         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| total_reward_steps      | 27           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048803426 |\n",
      "|    clip_fraction        | 0.231        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | 0.0845       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0139      |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| total_reward_steps      | 29           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054566553 |\n",
      "|    clip_fraction        | 0.226        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00743      |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 3.46         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 110592      |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004817362 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.415       |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00974    |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 311          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| total_reward_steps      | 96           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052575506 |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.0956       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.15         |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00829     |\n",
      "|    value_loss           | 0.919        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 317         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005268856 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0655      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    value_loss           | 0.784       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| total_reward_steps      | 30          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005977805 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00806    |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 328         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| total_reward_steps      | 20          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005274147 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 120832      |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004090978 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 340          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| total_reward_steps      | 30           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062982077 |\n",
      "|    clip_fraction        | 0.263        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0111       |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.0148      |\n",
      "|    value_loss           | 0.0941       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005506118 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.837       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| total_reward_steps      | 187         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006194527 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 357          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| total_reward_steps      | 48           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069847656 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -0.0112      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 6.13         |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | 0.00648      |\n",
      "|    value_loss           | 12.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005386778 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0323      |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 368          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| total_reward_steps      | 40           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049404046 |\n",
      "|    clip_fraction        | 0.234        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | -0.0347      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 5.41         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.000692    |\n",
      "|    value_loss           | 2.95         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 374          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| total_reward_steps      | 39           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055379816 |\n",
      "|    clip_fraction        | 0.253        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0502       |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 0.0879       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 379          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| total_reward_steps      | 38           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057933955 |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0546       |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005169075 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| total_reward_steps      | 42           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067627993 |\n",
      "|    clip_fraction        | 0.29         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -0.0491      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.21         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.000405    |\n",
      "|    value_loss           | 2.69         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| total_reward_steps      | 35           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058048265 |\n",
      "|    clip_fraction        | 0.275        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0257       |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.014       |\n",
      "|    value_loss           | 0.122        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 145408       |\n",
      "| total_reward_steps      | 52           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055987276 |\n",
      "|    clip_fraction        | 0.263        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.353        |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.00901     |\n",
      "|    value_loss           | 0.597        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006355204 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.086       |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006934312 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.0538      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 3.39        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 419          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| total_reward_steps      | 42           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049983016 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.31         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 2.87         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004684668 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005416212 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.311       |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.714       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004946149 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0864      |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 0.788       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 360       |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 442       |\n",
      "|    total_timesteps      | 159744    |\n",
      "| total_reward_steps      | 49        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0061227 |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.38     |\n",
      "|    explained_variance   | 0.339     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | -0.025    |\n",
      "|    n_updates            | 770       |\n",
      "|    policy_gradient_loss | -0.0112   |\n",
      "|    value_loss           | 0.134     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005318035 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00817     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 454          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| total_reward_steps      | 42           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060447454 |\n",
      "|    clip_fraction        | 0.278        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0261       |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.019       |\n",
      "|    value_loss           | 0.118        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 165888      |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008787697 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 3.35        |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 360      |\n",
      "|    iterations           | 82       |\n",
      "|    time_elapsed         | 465      |\n",
      "|    total_timesteps      | 167936   |\n",
      "| total_reward_steps      | 65       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.005938 |\n",
      "|    clip_fraction        | 0.288    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -1.35    |\n",
      "|    explained_variance   | 0.194    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.0612   |\n",
      "|    n_updates            | 810      |\n",
      "|    policy_gradient_loss | -0.00648 |\n",
      "|    value_loss           | 0.495    |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 471          |\n",
      "|    total_timesteps      | 169984       |\n",
      "| total_reward_steps      | 67           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066130525 |\n",
      "|    clip_fraction        | 0.274        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00299     |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | -0.011       |\n",
      "|    value_loss           | 0.474        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 476          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| total_reward_steps      | 47           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052798567 |\n",
      "|    clip_fraction        | 0.264        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00348     |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00978     |\n",
      "|    value_loss           | 0.355        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 482          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| total_reward_steps      | 60           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057740747 |\n",
      "|    clip_fraction        | 0.282        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0142       |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.123        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 488         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006198629 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0595      |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010853409 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.471       |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| total_reward_steps      | 42           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074766213 |\n",
      "|    clip_fraction        | 0.341        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.0325      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0172       |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00984     |\n",
      "|    value_loss           | 0.159        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| total_reward_steps      | 46           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070055416 |\n",
      "|    clip_fraction        | 0.324        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0407       |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    value_loss           | 0.131        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006731717 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00291     |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 516          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| total_reward_steps      | 45           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071464907 |\n",
      "|    clip_fraction        | 0.293        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0158      |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.016       |\n",
      "|    value_loss           | 0.0932       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 521          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| total_reward_steps      | 41           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051876404 |\n",
      "|    clip_fraction        | 0.274        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.103        |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.148        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 190464      |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006845456 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0023     |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.0981      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006946356 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 538          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| total_reward_steps      | 70           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067146234 |\n",
      "|    clip_fraction        | 0.278        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0276       |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.0172      |\n",
      "|    value_loss           | 0.104        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006016985 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    value_loss           | 0.692       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 549          |\n",
      "|    total_timesteps      | 198656       |\n",
      "| total_reward_steps      | 46           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060212268 |\n",
      "|    clip_fraction        | 0.239        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36         |\n",
      "|    n_updates            | 960          |\n",
      "|    policy_gradient_loss | -0.0124      |\n",
      "|    value_loss           | 0.449        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 98           |\n",
      "|    time_elapsed         | 555          |\n",
      "|    total_timesteps      | 200704       |\n",
      "| total_reward_steps      | 55           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062783426 |\n",
      "|    clip_fraction        | 0.292        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0648       |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 0.629        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 561          |\n",
      "|    total_timesteps      | 202752       |\n",
      "| total_reward_steps      | 35           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067644254 |\n",
      "|    clip_fraction        | 0.313        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.013       |\n",
      "|    n_updates            | 980          |\n",
      "|    policy_gradient_loss | -0.018       |\n",
      "|    value_loss           | 0.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 566          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| total_reward_steps      | 54           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068584112 |\n",
      "|    clip_fraction        | 0.302        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0013      |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 0.114        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 206848      |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006962535 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 577          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| total_reward_steps      | 25           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061847167 |\n",
      "|    clip_fraction        | 0.277        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.144        |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.015       |\n",
      "|    value_loss           | 0.136        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007891605 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0502     |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 589         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007363281 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.00889    |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 594          |\n",
      "|    total_timesteps      | 215040       |\n",
      "| total_reward_steps      | 63           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053487234 |\n",
      "|    clip_fraction        | 0.256        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | 0.604        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0109      |\n",
      "|    n_updates            | 1040         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.125        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 600          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| total_reward_steps      | 38           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062072696 |\n",
      "|    clip_fraction        | 0.292        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.471        |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 0.91         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 605        |\n",
      "|    total_timesteps      | 219136     |\n",
      "| total_reward_steps      | 71         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00976989 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -0.0469    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.172      |\n",
      "|    n_updates            | 1060       |\n",
      "|    policy_gradient_loss | -0.000787  |\n",
      "|    value_loss           | 2.64       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 221184      |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008016729 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.97        |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 0.429       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 361      |\n",
      "|    iterations           | 109      |\n",
      "|    time_elapsed         | 617      |\n",
      "|    total_timesteps      | 223232   |\n",
      "| total_reward_steps      | 51       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.007057 |\n",
      "|    clip_fraction        | 0.289    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -1.3     |\n",
      "|    explained_variance   | 0.613    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.0531   |\n",
      "|    n_updates            | 1080     |\n",
      "|    policy_gradient_loss | -0.0133  |\n",
      "|    value_loss           | 0.127    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 225280      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006339892 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00496    |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 628          |\n",
      "|    total_timesteps      | 227328       |\n",
      "| total_reward_steps      | 41           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075789467 |\n",
      "|    clip_fraction        | 0.318        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0612       |\n",
      "|    n_updates            | 1100         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 0.146        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 633          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| total_reward_steps      | 56           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066844756 |\n",
      "|    clip_fraction        | 0.312        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0669       |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 0.134        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 231424     |\n",
      "| total_reward_steps      | 49         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00788032 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.045      |\n",
      "|    n_updates            | 1120       |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 0.126      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007616097 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0397      |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 235520      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008473103 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00723    |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008375198 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0184     |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 662          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| total_reward_steps      | 60           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078081577 |\n",
      "|    clip_fraction        | 0.323        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0031      |\n",
      "|    n_updates            | 1160         |\n",
      "|    policy_gradient_loss | -0.0196      |\n",
      "|    value_loss           | 0.134        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 668          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| total_reward_steps      | 50           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059525506 |\n",
      "|    clip_fraction        | 0.292        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0633       |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.0176      |\n",
      "|    value_loss           | 0.103        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008759648 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0549      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 679          |\n",
      "|    total_timesteps      | 245760       |\n",
      "| total_reward_steps      | 39           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076806657 |\n",
      "|    clip_fraction        | 0.31         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0115       |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 0.099        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 685          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| total_reward_steps      | 74           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070482315 |\n",
      "|    clip_fraction        | 0.28         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0309      |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    value_loss           | 0.121        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| total_reward_steps      | 118          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136021115 |\n",
      "|    clip_fraction        | 0.399        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.167        |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | 0.00424      |\n",
      "|    value_loss           | 3            |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 696        |\n",
      "|    total_timesteps      | 251904     |\n",
      "| total_reward_steps      | 52         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01005015 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.227      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.129      |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.0081    |\n",
      "|    value_loss           | 2.69       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007548541 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0418      |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 707          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| total_reward_steps      | 59           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072888257 |\n",
      "|    clip_fraction        | 0.318        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.086        |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.0161      |\n",
      "|    value_loss           | 0.114        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 713          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| total_reward_steps      | 44           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075530903 |\n",
      "|    clip_fraction        | 0.311        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.0185      |\n",
      "|    value_loss           | 0.113        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 719         |\n",
      "|    total_timesteps      | 260096      |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007541392 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0781      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 724          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| total_reward_steps      | 52           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077780527 |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0624       |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.0186      |\n",
      "|    value_loss           | 0.1          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 730          |\n",
      "|    total_timesteps      | 264192       |\n",
      "| total_reward_steps      | 49           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067551155 |\n",
      "|    clip_fraction        | 0.283        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0358      |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 0.13         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 736          |\n",
      "|    total_timesteps      | 266240       |\n",
      "| total_reward_steps      | 52           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064830245 |\n",
      "|    clip_fraction        | 0.273        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.0482       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.113        |\n",
      "|    n_updates            | 1290         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 13.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 741          |\n",
      "|    total_timesteps      | 268288       |\n",
      "| total_reward_steps      | 42           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067528803 |\n",
      "|    clip_fraction        | 0.319        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0108      |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.0165      |\n",
      "|    value_loss           | 0.0977       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008618547 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.033      |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.083       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 361        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 753        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| total_reward_steps      | 42         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00785282 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0357     |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.0155    |\n",
      "|    value_loss           | 0.452      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 758         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009627616 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.0923      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 764         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008042107 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.015      |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 769          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| total_reward_steps      | 41           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072918646 |\n",
      "|    clip_fraction        | 0.33         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0883       |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.0201      |\n",
      "|    value_loss           | 0.0971       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 361          |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 775          |\n",
      "|    total_timesteps      | 280576       |\n",
      "| total_reward_steps      | 34           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074714115 |\n",
      "|    clip_fraction        | 0.291        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.145        |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.0187      |\n",
      "|    value_loss           | 0.105        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 780         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403335 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675545 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00708    |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 792         |\n",
      "|    total_timesteps      | 286720      |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008240206 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.0939      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009958312 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.334       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007829169 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.019       |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 808        |\n",
      "|    total_timesteps      | 292864     |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022579 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00407   |\n",
      "|    n_updates            | 1420       |\n",
      "|    policy_gradient_loss | -0.0237    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 144        |\n",
      "|    time_elapsed         | 814        |\n",
      "|    total_timesteps      | 294912     |\n",
      "| total_reward_steps      | 64         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00739296 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.813      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 1430       |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    value_loss           | 0.0849     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 820          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| total_reward_steps      | 56           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082443915 |\n",
      "|    clip_fraction        | 0.294        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00907      |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.0189      |\n",
      "|    value_loss           | 0.092        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 825         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006846523 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.0361      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 301056      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007920526 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 836         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008931264 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0543      |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 149        |\n",
      "|    time_elapsed         | 842        |\n",
      "|    total_timesteps      | 305152     |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01550438 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.202      |\n",
      "|    n_updates            | 1480       |\n",
      "|    policy_gradient_loss | 0.00124    |\n",
      "|    value_loss           | 2.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 848         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| total_reward_steps      | 126         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018251602 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0594      |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021059321 |\n",
      "|    clip_fraction        | 0.459       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.0188     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | 0.0165      |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 859         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015173948 |\n",
      "|    clip_fraction        | 0.463       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.0443     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 0.925       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012080584 |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -0.0447     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0926      |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 0.706       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 870         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014578069 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.0651      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.245       |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.000999    |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 876         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012881853 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0444      |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 881         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279556 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 157         |\n",
      "|    time_elapsed         | 887         |\n",
      "|    total_timesteps      | 321536      |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009547991 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0446      |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 362          |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 893          |\n",
      "|    total_timesteps      | 323584       |\n",
      "| total_reward_steps      | 62           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104597295 |\n",
      "|    clip_fraction        | 0.391        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0269      |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.0141      |\n",
      "|    value_loss           | 0.373        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010989819 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010645688 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0326      |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.099       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 910        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| total_reward_steps      | 194        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01547754 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.596      |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.00143   |\n",
      "|    value_loss           | 2.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 915         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012698962 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.18        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | 0.00922     |\n",
      "|    value_loss           | 9.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 921         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029939221 |\n",
      "|    clip_fraction        | 0.506       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | 0.0223      |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 926         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016653301 |\n",
      "|    clip_fraction        | 0.472       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    value_loss           | 0.784       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 362        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 932        |\n",
      "|    total_timesteps      | 337920     |\n",
      "| total_reward_steps      | 45         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01399154 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | -0.671     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00998    |\n",
      "|    n_updates            | 1640       |\n",
      "|    policy_gradient_loss | -2.71e-05  |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 938         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012929104 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 944         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009290956 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0103     |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 949         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011174489 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 362         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 955         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009391511 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.0793      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 961         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009833306 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 171         |\n",
      "|    time_elapsed         | 968         |\n",
      "|    total_timesteps      | 350208      |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008782106 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0348     |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 361         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 975         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010646397 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00813    |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.094       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 360         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013910499 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.0848      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0359      |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 360          |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 989          |\n",
      "|    total_timesteps      | 356352       |\n",
      "| total_reward_steps      | 60           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110942675 |\n",
      "|    clip_fraction        | 0.38         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0525       |\n",
      "|    n_updates            | 1730         |\n",
      "|    policy_gradient_loss | -0.0175      |\n",
      "|    value_loss           | 0.708        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 996         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011314414 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0126      |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 359         |\n",
      "|    iterations           | 176         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 360448      |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010806393 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0043      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| total_reward_steps      | 199         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010200299 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1016        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018575208 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.00749    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | 0.00652     |\n",
      "|    value_loss           | 9.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 358         |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 1023        |\n",
      "|    total_timesteps      | 366592      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011877701 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000609   |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 1030        |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010920451 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0312      |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0642      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 357         |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 370688      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007132254 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.377      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0203     |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    value_loss           | 0.0428      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 1044        |\n",
      "|    total_timesteps      | 372736      |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009088131 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 0.0899      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 356        |\n",
      "|    iterations           | 183        |\n",
      "|    time_elapsed         | 1051       |\n",
      "|    total_timesteps      | 374784     |\n",
      "| total_reward_steps      | 128        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16099523 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.08      |\n",
      "|    explained_variance   | -0.0177    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.256      |\n",
      "|    n_updates            | 1820       |\n",
      "|    policy_gradient_loss | 0.0417     |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 356         |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1057        |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016081065 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.66        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | 0.00378     |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 1064        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009806337 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -1.85       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0254      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | 0.000178    |\n",
      "|    value_loss           | 0.0387      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 355          |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 1071         |\n",
      "|    total_timesteps      | 380928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048715547 |\n",
      "|    clip_fraction        | 0.245        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.37        |\n",
      "|    explained_variance   | -2.96        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0405      |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 0.00514      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 355         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1078        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005000133 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.948      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00579     |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    value_loss           | 0.00434     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 1084        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004614142 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -6.01       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0271     |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 0.0015      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 1091         |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039723595 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | -0.238       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00291     |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 0.00797      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 1098         |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044219494 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -10.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00392     |\n",
      "|    n_updates            | 1890         |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    value_loss           | 0.000816     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 1104         |\n",
      "|    total_timesteps      | 391168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042721466 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.022       |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 0.00689      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 1110        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003702268 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -1.89       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 0.000804    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 354         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005894696 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -3.49       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00972    |\n",
      "|    value_loss           | 0.000878    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 354          |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 1122         |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045117387 |\n",
      "|    clip_fraction        | 0.23         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -0.269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0308      |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00958     |\n",
      "|    value_loss           | 0.00566      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 1128         |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052821664 |\n",
      "|    clip_fraction        | 0.206        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | -3.95        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0477      |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.00823     |\n",
      "|    value_loss           | 0.000695     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 196          |\n",
      "|    time_elapsed         | 1134         |\n",
      "|    total_timesteps      | 401408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037956745 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -2.04        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0303      |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    value_loss           | 0.00103      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 1140         |\n",
      "|    total_timesteps      | 403456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035874564 |\n",
      "|    clip_fraction        | 0.169        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -10.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0307      |\n",
      "|    n_updates            | 1960         |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 0.000584     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 353         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 1146        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004271184 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -2.06       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    value_loss           | 0.000633    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 1153         |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049263276 |\n",
      "|    clip_fraction        | 0.184        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -1.23        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0352      |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.0128      |\n",
      "|    value_loss           | 0.000812     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 353          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 1160         |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066348254 |\n",
      "|    clip_fraction        | 0.239        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0223      |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.0143      |\n",
      "|    value_loss           | 0.0145       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 201          |\n",
      "|    time_elapsed         | 1166         |\n",
      "|    total_timesteps      | 411648       |\n",
      "| total_reward_steps      | 33           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040925522 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | -5.29        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0524      |\n",
      "|    n_updates            | 2000         |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.00127      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 352         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 1173        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008349791 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.0335      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 352          |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 1180         |\n",
      "|    total_timesteps      | 415744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070070894 |\n",
      "|    clip_fraction        | 0.274        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.213        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0357      |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.0147      |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 351          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 1187         |\n",
      "|    total_timesteps      | 417792       |\n",
      "| total_reward_steps      | 49           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079342965 |\n",
      "|    clip_fraction        | 0.305        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.0965       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0372      |\n",
      "|    n_updates            | 2030         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 0.0934       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1193        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009703758 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 206         |\n",
      "|    time_elapsed         | 1200        |\n",
      "|    total_timesteps      | 421888      |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013331084 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39        |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.000934   |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 351         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 1207        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012967411 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 2.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 350        |\n",
      "|    iterations           | 208        |\n",
      "|    time_elapsed         | 1214       |\n",
      "|    total_timesteps      | 425984     |\n",
      "| total_reward_steps      | 88         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01082968 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.0594     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.034     |\n",
      "|    n_updates            | 2070       |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.169      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 1220        |\n",
      "|    total_timesteps      | 428032      |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030742714 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.0707      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.316       |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    value_loss           | 15.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 1227        |\n",
      "|    total_timesteps      | 430080      |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013319211 |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 350         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 1234        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011060574 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 1240        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| total_reward_steps      | 200         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017408002 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.29        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | 0.000765    |\n",
      "|    value_loss           | 2.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 1247        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028386869 |\n",
      "|    clip_fraction        | 0.563       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.0402     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | 0.0192      |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 1254        |\n",
      "|    total_timesteps      | 438272      |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017118666 |\n",
      "|    clip_fraction        | 0.476       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0424      |\n",
      "|    n_updates            | 2130        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 349         |\n",
      "|    iterations           | 215         |\n",
      "|    time_elapsed         | 1261        |\n",
      "|    total_timesteps      | 440320      |\n",
      "| total_reward_steps      | 138         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015676726 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.151       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 0.868       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 1267        |\n",
      "|    total_timesteps      | 442368      |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024001542 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.954       |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | 0.00371     |\n",
      "|    value_loss           | 2.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1274        |\n",
      "|    total_timesteps      | 444416      |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012289079 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.86        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 0.773       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 1281        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011807898 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0449      |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 348         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 1288        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013546222 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0786      |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00727    |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 220          |\n",
      "|    time_elapsed         | 1294         |\n",
      "|    total_timesteps      | 450560       |\n",
      "| total_reward_steps      | 69           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102182515 |\n",
      "|    clip_fraction        | 0.343        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0369       |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.0152      |\n",
      "|    value_loss           | 0.126        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 452608       |\n",
      "| total_reward_steps      | 77           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121444175 |\n",
      "|    clip_fraction        | 0.369        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0619       |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.0188      |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 222        |\n",
      "|    time_elapsed         | 1308       |\n",
      "|    total_timesteps      | 454656     |\n",
      "| total_reward_steps      | 124        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02266303 |\n",
      "|    clip_fraction        | 0.448      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.19       |\n",
      "|    n_updates            | 2210       |\n",
      "|    policy_gradient_loss | 0.0134     |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 1314        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014791066 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.128       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.01        |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 347          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 1320         |\n",
      "|    total_timesteps      | 458752       |\n",
      "| total_reward_steps      | 101          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135021685 |\n",
      "|    clip_fraction        | 0.411        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.06         |\n",
      "|    n_updates            | 2230         |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 0.588        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 225        |\n",
      "|    time_elapsed         | 1326       |\n",
      "|    total_timesteps      | 460800     |\n",
      "| total_reward_steps      | 74         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01229187 |\n",
      "|    clip_fraction        | 0.406      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.493      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.91       |\n",
      "|    n_updates            | 2240       |\n",
      "|    policy_gradient_loss | -0.00957   |\n",
      "|    value_loss           | 0.531      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 1332       |\n",
      "|    total_timesteps      | 462848     |\n",
      "| total_reward_steps      | 76         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01291402 |\n",
      "|    clip_fraction        | 0.399      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.439      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0186     |\n",
      "|    n_updates            | 2250       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 0.143      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 1338       |\n",
      "|    total_timesteps      | 464896     |\n",
      "| total_reward_steps      | 80         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00932444 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0351     |\n",
      "|    n_updates            | 2260       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 347        |\n",
      "|    iterations           | 228        |\n",
      "|    time_elapsed         | 1343       |\n",
      "|    total_timesteps      | 466944     |\n",
      "| total_reward_steps      | 69         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01199765 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.663      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00786   |\n",
      "|    n_updates            | 2270       |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    value_loss           | 0.112      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 1349        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013367522 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0303     |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 1356        |\n",
      "|    total_timesteps      | 471040      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011011562 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 347         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1362        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| total_reward_steps      | 160         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011086391 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00622     |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 347       |\n",
      "|    iterations           | 232       |\n",
      "|    time_elapsed         | 1369      |\n",
      "|    total_timesteps      | 475136    |\n",
      "| total_reward_steps      | 75        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0703845 |\n",
      "|    clip_fraction        | 0.448     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.07     |\n",
      "|    explained_variance   | 0.069     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.775     |\n",
      "|    n_updates            | 2310      |\n",
      "|    policy_gradient_loss | 0.0184    |\n",
      "|    value_loss           | 9.43      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015007114 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -0.688      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.000236   |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1382        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013209805 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | -0.439      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 1389        |\n",
      "|    total_timesteps      | 481280      |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012970867 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 0.564       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1395        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012218695 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0599      |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 346         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 1402        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013990033 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0747      |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1409        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010277808 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1415        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013697572 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0791      |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -5.07e-06   |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 1422        |\n",
      "|    total_timesteps      | 491520      |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013671802 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0231      |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 1429        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012238257 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00829    |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 345         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010873133 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0619      |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 1442        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009198947 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.099       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 344         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009357939 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0205     |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=500000, episode_reward=50.17 +/- 6.53\n",
      "Episode length: 1002.23 +/- 126.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 50.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011032176 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0755      |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00872    |\n",
      "|    value_loss           | 0.588       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 336      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 1492     |\n",
      "|    total_timesteps | 501760   |\n",
      "| total_reward_steps | 99       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 1499        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010569938 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 1505        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011106776 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0998      |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 1512        |\n",
      "|    total_timesteps      | 507904      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012187216 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00409    |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 1519         |\n",
      "|    total_timesteps      | 509952       |\n",
      "| total_reward_steps      | 59           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097315125 |\n",
      "|    clip_fraction        | 0.362        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.683        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0422       |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.0193      |\n",
      "|    value_loss           | 0.0953       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 335        |\n",
      "|    iterations           | 250        |\n",
      "|    time_elapsed         | 1525       |\n",
      "|    total_timesteps      | 512000     |\n",
      "| total_reward_steps      | 61         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01046662 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0407     |\n",
      "|    n_updates            | 2490       |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    value_loss           | 0.16       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 1532        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010717467 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 1538        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009428795 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010888267 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00794     |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 254         |\n",
      "|    time_elapsed         | 1551        |\n",
      "|    total_timesteps      | 520192      |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010668747 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00592    |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012841123 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0874      |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 1563        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010729314 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.0944      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 1569        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361982 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1574        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010781745 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.0932      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 1580        |\n",
      "|    total_timesteps      | 530432      |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013406992 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0176      |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 1586        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011069837 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000804    |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.213       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 1591        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014030544 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0584      |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 1597        |\n",
      "|    total_timesteps      | 536576      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013145581 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000914    |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 1602        |\n",
      "|    total_timesteps      | 538624      |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012306092 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.0997      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 336        |\n",
      "|    iterations           | 264        |\n",
      "|    time_elapsed         | 1608       |\n",
      "|    total_timesteps      | 540672     |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01365193 |\n",
      "|    clip_fraction        | 0.376      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 2630       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 0.241      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 336         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 1614        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010045684 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0672      |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 1621        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012163299 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.013      |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 1628        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010888027 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0061      |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 335        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 1634       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| total_reward_steps      | 78         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01250701 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.827      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0184    |\n",
      "|    n_updates            | 2670       |\n",
      "|    policy_gradient_loss | -0.0235    |\n",
      "|    value_loss           | 0.1        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 335        |\n",
      "|    iterations           | 269        |\n",
      "|    time_elapsed         | 1641       |\n",
      "|    total_timesteps      | 550912     |\n",
      "| total_reward_steps      | 73         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01218347 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.839      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00896    |\n",
      "|    n_updates            | 2680       |\n",
      "|    policy_gradient_loss | -0.0202    |\n",
      "|    value_loss           | 0.104      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 1648        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012235314 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00607     |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 1654        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010471663 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00952    |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 335       |\n",
      "|    iterations           | 272       |\n",
      "|    time_elapsed         | 1661      |\n",
      "|    total_timesteps      | 557056    |\n",
      "| total_reward_steps      | 94        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0116558 |\n",
      "|    clip_fraction        | 0.364     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.964    |\n",
      "|    explained_variance   | 0.765     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.00655   |\n",
      "|    n_updates            | 2710      |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    value_loss           | 0.117     |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 335          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 1668         |\n",
      "|    total_timesteps      | 559104       |\n",
      "| total_reward_steps      | 84           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128931515 |\n",
      "|    clip_fraction        | 0.392        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00542      |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.0151      |\n",
      "|    value_loss           | 0.562        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 335         |\n",
      "|    iterations           | 274         |\n",
      "|    time_elapsed         | 1675        |\n",
      "|    total_timesteps      | 561152      |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010965329 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0815      |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 1681        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011896962 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.61        |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.555       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013377723 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 567296      |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012487432 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0909      |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | -0.00906    |\n",
      "|    value_loss           | 0.521       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1702        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015302585 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00595    |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 571392      |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017744172 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1715        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011630982 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 1722        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011019832 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00606     |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 334         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 1729        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012243129 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.3         |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.724       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014060557 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0169     |\n",
      "|    n_updates            | 2820        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 1742        |\n",
      "|    total_timesteps      | 581632      |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011704984 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 1749        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013368877 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.0799      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 1756        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014249602 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 1762        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013567826 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.983      |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0404      |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 1769        |\n",
      "|    total_timesteps      | 589824      |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011432147 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0996      |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.474       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 1776        |\n",
      "|    total_timesteps      | 591872      |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013741641 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 333         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 1783        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| total_reward_steps      | 142         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013571557 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 1789        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015142183 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.706       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 332         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 1796        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011989582 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=90.63 +/- 12.94\n",
      "Episode length: 1404.07 +/- 115.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | 90.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013108687 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0813      |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 0.421       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 323    |\n",
      "|    iterations      | 293    |\n",
      "|    time_elapsed    | 1856   |\n",
      "|    total_timesteps | 600064 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 1862        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016420512 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0181      |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 1868        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013183002 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.0986      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 1874        |\n",
      "|    total_timesteps      | 606208      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013572986 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0367      |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 1881        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011858588 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 1887        |\n",
      "|    total_timesteps      | 610304      |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013447873 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00534    |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 1894        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012361446 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 1901        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| total_reward_steps      | 173         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027886564 |\n",
      "|    clip_fraction        | 0.454       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.55        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 323         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 1908        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013808999 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.021      |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.172       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 1914        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013326116 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 1921        |\n",
      "|    total_timesteps      | 620544      |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012076769 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00911    |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013091501 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00402     |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 1935        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014352083 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 1941        |\n",
      "|    total_timesteps      | 626688      |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014054958 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.561       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 1948        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013027223 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.949      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 630784      |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011950747 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.82        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| total_reward_steps      | 153         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012072507 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 1968        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014918352 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0807      |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    value_loss           | 1.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 1975        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012143668 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 1982        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| total_reward_steps      | 144         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014208991 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00601    |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 1989        |\n",
      "|    total_timesteps      | 641024      |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014564093 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.603       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 1995        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015078495 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0075      |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.554       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 2002        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014123214 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 2009        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| total_reward_steps      | 167         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011973232 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 2016        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046290055 |\n",
      "|    clip_fraction        | 0.551       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.134       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.757       |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    value_loss           | 4.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 318         |\n",
      "|    time_elapsed         | 2022        |\n",
      "|    total_timesteps      | 651264      |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016073726 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015488624 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.01        |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 2036        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| total_reward_steps      | 155         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016055634 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 321         |\n",
      "|    time_elapsed         | 2043        |\n",
      "|    total_timesteps      | 657408      |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018015657 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.679       |\n",
      "|    n_updates            | 3200        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 0.887       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 2049        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018657576 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0749      |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 2056        |\n",
      "|    total_timesteps      | 661504      |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013376772 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 324        |\n",
      "|    time_elapsed         | 2062       |\n",
      "|    total_timesteps      | 663552     |\n",
      "| total_reward_steps      | 95         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01238868 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.639      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0141     |\n",
      "|    n_updates            | 3230       |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    value_loss           | 0.13       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 2069        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015625615 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 2075        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013541167 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0119     |\n",
      "|    n_updates            | 3250        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 2081        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014729282 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0761      |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 2087        |\n",
      "|    total_timesteps      | 671744      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012549015 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0902      |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 321        |\n",
      "|    iterations           | 329        |\n",
      "|    time_elapsed         | 2093       |\n",
      "|    total_timesteps      | 673792     |\n",
      "| total_reward_steps      | 101        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08238895 |\n",
      "|    clip_fraction        | 0.518      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.963     |\n",
      "|    explained_variance   | 0.111      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 6.79       |\n",
      "|    n_updates            | 3280       |\n",
      "|    policy_gradient_loss | 0.0318     |\n",
      "|    value_loss           | 13         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 2098        |\n",
      "|    total_timesteps      | 675840      |\n",
      "| total_reward_steps      | 135         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017113332 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0961      |\n",
      "|    n_updates            | 3290        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 2104        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019080289 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.84        |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 2110        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| total_reward_steps      | 162         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012948537 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.043      |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 322        |\n",
      "|    iterations           | 333        |\n",
      "|    time_elapsed         | 2115       |\n",
      "|    total_timesteps      | 681984     |\n",
      "| total_reward_steps      | 172        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01732041 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.531      |\n",
      "|    n_updates            | 3320       |\n",
      "|    policy_gradient_loss | -0.00547   |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 2121        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015520835 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 335         |\n",
      "|    time_elapsed         | 2126        |\n",
      "|    total_timesteps      | 686080      |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012208637 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 3340        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 2132        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| total_reward_steps      | 150         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016105417 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.371       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 2138        |\n",
      "|    total_timesteps      | 690176      |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013083106 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0994      |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014480201 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0899      |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 2151        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015698604 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0782      |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.431       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 322        |\n",
      "|    iterations           | 340        |\n",
      "|    time_elapsed         | 2158       |\n",
      "|    total_timesteps      | 696320     |\n",
      "| total_reward_steps      | 59         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273291 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.918     |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0336     |\n",
      "|    n_updates            | 3390       |\n",
      "|    policy_gradient_loss | -0.00837   |\n",
      "|    value_loss           | 0.578      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 322         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 2164        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018485783 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.00992    |\n",
      "|    value_loss           | 0.414       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=103.97 +/- 29.53\n",
      "Episode length: 1402.30 +/- 173.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | 104         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| total_reward_steps      | 133         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014958974 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00511     |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 315    |\n",
      "|    iterations      | 342    |\n",
      "|    time_elapsed    | 2222   |\n",
      "|    total_timesteps | 700416 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 2229        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012366012 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0464      |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 2235        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| total_reward_steps      | 244         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025782395 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.66        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | 0.00398     |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 345        |\n",
      "|    time_elapsed         | 2242       |\n",
      "|    total_timesteps      | 706560     |\n",
      "| total_reward_steps      | 74         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06967332 |\n",
      "|    clip_fraction        | 0.536      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.871     |\n",
      "|    explained_variance   | 0.076      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.258      |\n",
      "|    n_updates            | 3440       |\n",
      "|    policy_gradient_loss | 0.0241     |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 2249        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023854174 |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | -0.0361     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | 0.00334     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 347        |\n",
      "|    time_elapsed         | 2256       |\n",
      "|    total_timesteps      | 710656     |\n",
      "| total_reward_steps      | 174        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02539545 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.765     |\n",
      "|    explained_variance   | 0.0662     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.13       |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | -0.000997  |\n",
      "|    value_loss           | 2.38       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 2262        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029207913 |\n",
      "|    clip_fraction        | 0.444       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 349        |\n",
      "|    time_elapsed         | 2269       |\n",
      "|    total_timesteps      | 714752     |\n",
      "| total_reward_steps      | 109        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01806548 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.901     |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00709    |\n",
      "|    n_updates            | 3480       |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    value_loss           | 0.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 2276        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018457688 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | 0.00486     |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 2283        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022442639 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.206       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0496      |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 2289        |\n",
      "|    total_timesteps      | 720896      |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017056543 |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00603    |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 353        |\n",
      "|    time_elapsed         | 2296       |\n",
      "|    total_timesteps      | 722944     |\n",
      "| total_reward_steps      | 165        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01667736 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.864     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0165     |\n",
      "|    n_updates            | 3520       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 0.493      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 2303       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| total_reward_steps      | 86         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979167 |\n",
      "|    clip_fraction        | 0.453      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.964     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.428      |\n",
      "|    n_updates            | 3530       |\n",
      "|    policy_gradient_loss | -0.00235   |\n",
      "|    value_loss           | 2.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 2310        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014651703 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.965      |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 2316        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020724233 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.987      |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 2323        |\n",
      "|    total_timesteps      | 731136      |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014574203 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 0.272       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 2329        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| total_reward_steps      | 147         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015781231 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00167     |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 359        |\n",
      "|    time_elapsed         | 2336       |\n",
      "|    total_timesteps      | 735232     |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01806659 |\n",
      "|    clip_fraction        | 0.42       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | 0.312      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.146      |\n",
      "|    n_updates            | 3580       |\n",
      "|    policy_gradient_loss | 0.00199    |\n",
      "|    value_loss           | 2.02       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 2342        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| total_reward_steps      | 169         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017803337 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.965      |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0275      |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 2348        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017114777 |\n",
      "|    clip_fraction        | 0.411       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.926      |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    value_loss           | 0.863       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 2355        |\n",
      "|    total_timesteps      | 741376      |\n",
      "| total_reward_steps      | 272         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016108025 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.963      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00427     |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 314         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 2361        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| total_reward_steps      | 151         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031217078 |\n",
      "|    clip_fraction        | 0.461       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.508       |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | 0.0125      |\n",
      "|    value_loss           | 9.8         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 314        |\n",
      "|    iterations           | 364        |\n",
      "|    time_elapsed         | 2367       |\n",
      "|    total_timesteps      | 745472     |\n",
      "| total_reward_steps      | 102        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02216173 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | -0.0769    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.147      |\n",
      "|    n_updates            | 3630       |\n",
      "|    policy_gradient_loss | 0.00425    |\n",
      "|    value_loss           | 2.54       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 2372        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021699455 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.329       |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 2378        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017711915 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00955    |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 367         |\n",
      "|    time_elapsed         | 2384        |\n",
      "|    total_timesteps      | 751616      |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018952642 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0205      |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 2389        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| total_reward_steps      | 227         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016277831 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 2395        |\n",
      "|    total_timesteps      | 755712      |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047756262 |\n",
      "|    clip_fraction        | 0.459       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.967      |\n",
      "|    explained_variance   | 0.062       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.328       |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | 0.00453     |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 2400        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| total_reward_steps      | 135         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018372707 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00468     |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 2406       |\n",
      "|    total_timesteps      | 759808     |\n",
      "| total_reward_steps      | 101        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01649711 |\n",
      "|    clip_fraction        | 0.421      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00598    |\n",
      "|    n_updates            | 3700       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 0.111      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 2412        |\n",
      "|    total_timesteps      | 761856      |\n",
      "| total_reward_steps      | 188         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020250108 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.894      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0272      |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.538       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 2418        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021459337 |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15        |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | 0.00314     |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 2425        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016639646 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 2432        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016800394 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0839      |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 2438        |\n",
      "|    total_timesteps      | 770048      |\n",
      "| total_reward_steps      | 120         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016601767 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 2445        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017329626 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 2452        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| total_reward_steps      | 184         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019787878 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 2459        |\n",
      "|    total_timesteps      | 776192      |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023685811 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    value_loss           | 2.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 2465        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| total_reward_steps      | 167         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015281741 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.371       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 2472        |\n",
      "|    total_timesteps      | 780288      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019341907 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | 0.00153     |\n",
      "|    value_loss           | 2.23        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 382        |\n",
      "|    time_elapsed         | 2479       |\n",
      "|    total_timesteps      | 782336     |\n",
      "| total_reward_steps      | 168        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02203621 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.256      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.292      |\n",
      "|    n_updates            | 3810       |\n",
      "|    policy_gradient_loss | -0.0065    |\n",
      "|    value_loss           | 1.65       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 2485        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025205977 |\n",
      "|    clip_fraction        | 0.456       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | 0.00252     |\n",
      "|    value_loss           | 3           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 315        |\n",
      "|    iterations           | 384        |\n",
      "|    time_elapsed         | 2492       |\n",
      "|    total_timesteps      | 786432     |\n",
      "| total_reward_steps      | 107        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08550353 |\n",
      "|    clip_fraction        | 0.484      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.863     |\n",
      "|    explained_variance   | -0.0182    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.344      |\n",
      "|    n_updates            | 3830       |\n",
      "|    policy_gradient_loss | 0.0334     |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 2499        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038592555 |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | -0.181      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | 0.00212     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 2506        |\n",
      "|    total_timesteps      | 790528      |\n",
      "| total_reward_steps      | 127         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018975072 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 2512        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016908234 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 0.517       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 2519        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016155107 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0664      |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 2526        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020463593 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 315         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 2533        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020070344 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.496       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=141.13 +/- 61.12\n",
      "Episode length: 1395.70 +/- 241.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | 141         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| total_reward_steps      | 185         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015013157 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0574      |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 309    |\n",
      "|    iterations      | 391    |\n",
      "|    time_elapsed    | 2590   |\n",
      "|    total_timesteps | 800768 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 392        |\n",
      "|    time_elapsed         | 2597       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| total_reward_steps      | 153        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01628936 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0182    |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 2604        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759219 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.000262   |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 2610        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018561956 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.918      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0741      |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.383       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 2617        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017944153 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.847      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 2623        |\n",
      "|    total_timesteps      | 811008      |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020662902 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.357       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 2630        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015975863 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 2636        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015553732 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0195      |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.529       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 2642        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013050411 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.941      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0437      |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 2647        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| total_reward_steps      | 260         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013619555 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.551       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 309       |\n",
      "|    iterations           | 401       |\n",
      "|    time_elapsed         | 2653      |\n",
      "|    total_timesteps      | 821248    |\n",
      "| total_reward_steps      | 124       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0410364 |\n",
      "|    clip_fraction        | 0.491     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.921    |\n",
      "|    explained_variance   | 0.153     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.08      |\n",
      "|    n_updates            | 4000      |\n",
      "|    policy_gradient_loss | 0.0258    |\n",
      "|    value_loss           | 12.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 2659        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018616758 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.081       |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 2664        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015641518 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.411       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 2670        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| total_reward_steps      | 210         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020331152 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 2676        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| total_reward_steps      | 138         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022320978 |\n",
      "|    clip_fraction        | 0.468       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    value_loss           | 2.03        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 406        |\n",
      "|    time_elapsed         | 2681       |\n",
      "|    total_timesteps      | 831488     |\n",
      "| total_reward_steps      | 59         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02244104 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.816     |\n",
      "|    explained_variance   | 0.284      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0721     |\n",
      "|    n_updates            | 4050       |\n",
      "|    policy_gradient_loss | -0.0063    |\n",
      "|    value_loss           | 1.71       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 2687        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018855935 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.256       |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.339       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 2693        |\n",
      "|    total_timesteps      | 835584      |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014636833 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 2699       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692825 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.843     |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.659      |\n",
      "|    n_updates            | 4080       |\n",
      "|    policy_gradient_loss | 0.00524    |\n",
      "|    value_loss           | 3.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 2706        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| total_reward_steps      | 261         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015464451 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0185     |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 2712        |\n",
      "|    total_timesteps      | 841728      |\n",
      "| total_reward_steps      | 148         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043808844 |\n",
      "|    clip_fraction        | 0.474       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.522       |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 9.03        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 310        |\n",
      "|    iterations           | 412        |\n",
      "|    time_elapsed         | 2719       |\n",
      "|    total_timesteps      | 843776     |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01817501 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.832     |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0582     |\n",
      "|    n_updates            | 4110       |\n",
      "|    policy_gradient_loss | -0.00712   |\n",
      "|    value_loss           | 0.569      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 2726        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050821222 |\n",
      "|    clip_fraction        | 0.51        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.0917      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.385       |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | 0.0195      |\n",
      "|    value_loss           | 8.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 2733        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028054705 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | -0.0334     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0861      |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 0.354       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 2739        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044061393 |\n",
      "|    clip_fraction        | 0.492       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.416       |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 2746        |\n",
      "|    total_timesteps      | 851968      |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024198044 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | -0.0142     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | 0.00304     |\n",
      "|    value_loss           | 0.531       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 2753        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020188386 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 2760        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| total_reward_steps      | 128         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016438592 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 2766        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017624829 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.69        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 2773        |\n",
      "|    total_timesteps      | 860160      |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016686726 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.091       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0753      |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 2780        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014930226 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0667      |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 0.427       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 2787        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013787564 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.864      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 2793        |\n",
      "|    total_timesteps      | 866304      |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015518248 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 310          |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 2800         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| total_reward_steps      | 76           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142982295 |\n",
      "|    clip_fraction        | 0.369        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.942       |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0232      |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | -0.0214      |\n",
      "|    value_loss           | 0.106        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 2807        |\n",
      "|    total_timesteps      | 870400      |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015406614 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.296       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 2814        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012347718 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 2820        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018222235 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 2827        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| total_reward_steps      | 160         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013916846 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0291      |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 2834        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016456878 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 2841        |\n",
      "|    total_timesteps      | 880640      |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013693396 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.873      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 431        |\n",
      "|    time_elapsed         | 2847       |\n",
      "|    total_timesteps      | 882688     |\n",
      "| total_reward_steps      | 228        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353727 |\n",
      "|    clip_fraction        | 0.405      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.746      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0264    |\n",
      "|    n_updates            | 4300       |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 2854        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| total_reward_steps      | 137         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046935655 |\n",
      "|    clip_fraction        | 0.46        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0696      |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | 0.0166      |\n",
      "|    value_loss           | 9.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 2861        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| total_reward_steps      | 357         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019938856 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 309        |\n",
      "|    iterations           | 434        |\n",
      "|    time_elapsed         | 2868       |\n",
      "|    total_timesteps      | 888832     |\n",
      "| total_reward_steps      | 81         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10527416 |\n",
      "|    clip_fraction        | 0.514      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 46.1       |\n",
      "|    n_updates            | 4330       |\n",
      "|    policy_gradient_loss | 0.0425     |\n",
      "|    value_loss           | 15.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 890880      |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030564595 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.73       |\n",
      "|    explained_variance   | -0.188      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0814      |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    value_loss           | 0.818       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 2881        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| total_reward_steps      | 133         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020116363 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 2888        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| total_reward_steps      | 223         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023316173 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.95        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00058    |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 2895        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029164119 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.698      |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.36        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 309         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 2901        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015717257 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0274      |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=92.43 +/- 16.79\n",
      "Episode length: 811.70 +/- 130.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 812         |\n",
      "|    mean_reward          | 92.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| total_reward_steps      | 227         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018825686 |\n",
      "|    clip_fraction        | 0.456       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 0.599       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 306      |\n",
      "|    iterations      | 440      |\n",
      "|    time_elapsed    | 2935     |\n",
      "|    total_timesteps | 901120   |\n",
      "| total_reward_steps | 222      |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 2941       |\n",
      "|    total_timesteps      | 903168     |\n",
      "| total_reward_steps      | 113        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09078308 |\n",
      "|    clip_fraction        | 0.541      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.72      |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 66.2       |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | 0.0281     |\n",
      "|    value_loss           | 17.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 2946        |\n",
      "|    total_timesteps      | 905216      |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026114874 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0454      |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 2952        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019955825 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.338       |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 2958        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018714137 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 307      |\n",
      "|    iterations           | 445      |\n",
      "|    time_elapsed         | 2963     |\n",
      "|    total_timesteps      | 911360   |\n",
      "| total_reward_steps      | 74       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.015914 |\n",
      "|    clip_fraction        | 0.36     |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.741   |\n",
      "|    explained_variance   | 0.572    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.104    |\n",
      "|    n_updates            | 4440     |\n",
      "|    policy_gradient_loss | -0.00728 |\n",
      "|    value_loss           | 0.464    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 2969        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017494822 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0567      |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 2975        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019966248 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0036      |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 2980        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014524642 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 449        |\n",
      "|    time_elapsed         | 2986       |\n",
      "|    total_timesteps      | 919552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01312352 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.989     |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.05       |\n",
      "|    n_updates            | 4480       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 0.0832     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 2993        |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010072511 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -3.15       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00946     |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    value_loss           | 0.0135      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 451          |\n",
      "|    time_elapsed         | 2999         |\n",
      "|    total_timesteps      | 923648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062624672 |\n",
      "|    clip_fraction        | 0.28         |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | -0.221       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0158      |\n",
      "|    n_updates            | 4500         |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 0.00888      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 3006        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009438811 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | -8.41       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00309    |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 0.00196     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 453        |\n",
      "|    time_elapsed         | 3013       |\n",
      "|    total_timesteps      | 927744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00551157 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | -10        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00815   |\n",
      "|    n_updates            | 4520       |\n",
      "|    policy_gradient_loss | -0.00589   |\n",
      "|    value_loss           | 0.0015     |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 3019         |\n",
      "|    total_timesteps      | 929792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062644593 |\n",
      "|    clip_fraction        | 0.262        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | -0.762       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0206      |\n",
      "|    n_updates            | 4530         |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 0.00572      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 455          |\n",
      "|    time_elapsed         | 3026         |\n",
      "|    total_timesteps      | 931840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050592953 |\n",
      "|    clip_fraction        | 0.218        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -6.56        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0307      |\n",
      "|    n_updates            | 4540         |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    value_loss           | 0.0016       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 3033         |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037541168 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -12.2        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0291      |\n",
      "|    n_updates            | 4550         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 0.00119      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 457          |\n",
      "|    time_elapsed         | 3039         |\n",
      "|    total_timesteps      | 935936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029950573 |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.23        |\n",
      "|    explained_variance   | -2.13        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00542     |\n",
      "|    n_updates            | 4560         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 0.00121      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 3046         |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053056367 |\n",
      "|    clip_fraction        | 0.236        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -2.92        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0298      |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | -0.00906     |\n",
      "|    value_loss           | 0.00129      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 459          |\n",
      "|    time_elapsed         | 3053         |\n",
      "|    total_timesteps      | 940032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055947686 |\n",
      "|    clip_fraction        | 0.199        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | -8.4         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0339      |\n",
      "|    n_updates            | 4580         |\n",
      "|    policy_gradient_loss | -0.00809     |\n",
      "|    value_loss           | 0.000972     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 3059         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053642206 |\n",
      "|    clip_fraction        | 0.219        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | -6.65        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0343      |\n",
      "|    n_updates            | 4590         |\n",
      "|    policy_gradient_loss | -0.00982     |\n",
      "|    value_loss           | 0.0011       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 3066        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005928379 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -16.6       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    value_loss           | 0.000908    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 462          |\n",
      "|    time_elapsed         | 3073         |\n",
      "|    total_timesteps      | 946176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052931285 |\n",
      "|    clip_fraction        | 0.212        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | -1.94        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00905     |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    value_loss           | 0.000887     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 307          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 3079         |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045378697 |\n",
      "|    clip_fraction        | 0.231        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -7.93        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0296      |\n",
      "|    n_updates            | 4620         |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    value_loss           | 0.000757     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 464         |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004579826 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -1.84       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0592     |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    value_loss           | 0.000948    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 3093        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004682116 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -0.495      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.0034      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 3100       |\n",
      "|    total_timesteps      | 954368     |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07616414 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.0327     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.05       |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | 0.0328     |\n",
      "|    value_loss           | 9.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 3106        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015745545 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0248     |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 3113        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013883058 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 3120        |\n",
      "|    total_timesteps      | 960512      |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013204843 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 3127        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012676454 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.03       |\n",
      "|    value_loss           | 0.0767      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 3133        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| total_reward_steps      | 217         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014096768 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.0754      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 3140        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020220932 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | 0.00678     |\n",
      "|    value_loss           | 9.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 3147        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| total_reward_steps      | 126         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012976553 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00591    |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 3154        |\n",
      "|    total_timesteps      | 970752      |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018581929 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.5         |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 3161        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014024854 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 3167        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015362389 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 3174        |\n",
      "|    total_timesteps      | 976896      |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159976 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 3181        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014123375 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.997      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 479        |\n",
      "|    time_elapsed         | 3188       |\n",
      "|    total_timesteps      | 980992     |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01738578 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.84      |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.172      |\n",
      "|    n_updates            | 4780       |\n",
      "|    policy_gradient_loss | -0.0223    |\n",
      "|    value_loss           | 0.0973     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 3194        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013334058 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 0.0949      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 481        |\n",
      "|    time_elapsed         | 3201       |\n",
      "|    total_timesteps      | 985088     |\n",
      "| total_reward_steps      | 97         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01315224 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.577      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0233     |\n",
      "|    n_updates            | 4800       |\n",
      "|    policy_gradient_loss | -0.00859   |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3207        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012365659 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.309       |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.531       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 3213        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015458669 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.944      |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00889    |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 0.0954      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 484        |\n",
      "|    time_elapsed         | 3220       |\n",
      "|    total_timesteps      | 991232     |\n",
      "| total_reward_steps      | 92         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01886842 |\n",
      "|    clip_fraction        | 0.404      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.994     |\n",
      "|    explained_variance   | 0.752      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0352     |\n",
      "|    n_updates            | 4830       |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 485        |\n",
      "|    time_elapsed         | 3227       |\n",
      "|    total_timesteps      | 993280     |\n",
      "| total_reward_steps      | 96         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01222191 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.827      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.02      |\n",
      "|    n_updates            | 4840       |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.0766     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 3233        |\n",
      "|    total_timesteps      | 995328      |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014074959 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 3240        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| total_reward_steps      | 182         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014639885 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.0887      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 307        |\n",
      "|    iterations           | 488        |\n",
      "|    time_elapsed         | 3247       |\n",
      "|    total_timesteps      | 999424     |\n",
      "| total_reward_steps      | 71         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06159685 |\n",
      "|    clip_fraction        | 0.492      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.903     |\n",
      "|    explained_variance   | 0.0144     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.337      |\n",
      "|    n_updates            | 4870       |\n",
      "|    policy_gradient_loss | 0.00665    |\n",
      "|    value_loss           | 19.3       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=87.23 +/- 25.19\n",
      "Episode length: 1159.60 +/- 197.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | 87.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015227033 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00356    |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    value_loss           | 0.449       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 303      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 3296     |\n",
      "|    total_timesteps | 1001472  |\n",
      "| total_reward_steps | 67       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 3303        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042736143 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | -0.106      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | 0.019       |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 491        |\n",
      "|    time_elapsed         | 3310       |\n",
      "|    total_timesteps      | 1005568    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02433611 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.77      |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 4900       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 0.168      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 3316        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| total_reward_steps      | 237         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021106105 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 3323        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030133795 |\n",
      "|    clip_fraction        | 0.484       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.0597      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.433       |\n",
      "|    n_updates            | 4920        |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 9.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 494         |\n",
      "|    time_elapsed         | 3330        |\n",
      "|    total_timesteps      | 1011712     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018338393 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 3337        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015390918 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0277      |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 3344        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014831563 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 3350        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015025491 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 3357        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015680268 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.0978      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 499         |\n",
      "|    time_elapsed         | 3364        |\n",
      "|    total_timesteps      | 1021952     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015853917 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    value_loss           | 0.515       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 3371        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| total_reward_steps      | 164         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014227571 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.405       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 501         |\n",
      "|    time_elapsed         | 3377        |\n",
      "|    total_timesteps      | 1026048     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017745448 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.068       |\n",
      "|    n_updates            | 5000        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 3384        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| total_reward_steps      | 144         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016597096 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.921      |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0028      |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 503        |\n",
      "|    time_elapsed         | 3391       |\n",
      "|    total_timesteps      | 1030144    |\n",
      "| total_reward_steps      | 227        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01778272 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | 0.427      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.157      |\n",
      "|    n_updates            | 5020       |\n",
      "|    policy_gradient_loss | -0.00862   |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 3398        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064000584 |\n",
      "|    clip_fraction        | 0.517       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.0329      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | 0.0233      |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 303       |\n",
      "|    iterations           | 505       |\n",
      "|    time_elapsed         | 3404      |\n",
      "|    total_timesteps      | 1034240   |\n",
      "| total_reward_steps      | 74        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0248015 |\n",
      "|    clip_fraction        | 0.421     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.836    |\n",
      "|    explained_variance   | 0.539     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0252    |\n",
      "|    n_updates            | 5040      |\n",
      "|    policy_gradient_loss | -0.0162   |\n",
      "|    value_loss           | 0.169     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 3411        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018802116 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 3418        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020950273 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 2.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 508         |\n",
      "|    time_elapsed         | 3425        |\n",
      "|    total_timesteps      | 1040384     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017995786 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00802    |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 509        |\n",
      "|    time_elapsed         | 3431       |\n",
      "|    total_timesteps      | 1042432    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06140277 |\n",
      "|    clip_fraction        | 0.561      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.861     |\n",
      "|    explained_variance   | -0.108     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.5        |\n",
      "|    n_updates            | 5080       |\n",
      "|    policy_gradient_loss | 0.0529     |\n",
      "|    value_loss           | 46.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 3438        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021358013 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 5090        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 511         |\n",
      "|    time_elapsed         | 3444        |\n",
      "|    total_timesteps      | 1046528     |\n",
      "| total_reward_steps      | 243         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020575866 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 512        |\n",
      "|    time_elapsed         | 3450       |\n",
      "|    total_timesteps      | 1048576    |\n",
      "| total_reward_steps      | 96         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04423875 |\n",
      "|    clip_fraction        | 0.497      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.826     |\n",
      "|    explained_variance   | -0.0246    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.422      |\n",
      "|    n_updates            | 5110       |\n",
      "|    policy_gradient_loss | 0.0151     |\n",
      "|    value_loss           | 7.67       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 513         |\n",
      "|    time_elapsed         | 3457        |\n",
      "|    total_timesteps      | 1050624     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024457337 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0778      |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 3463        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020894628 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0043      |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.252       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 3469        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015784042 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00498     |\n",
      "|    n_updates            | 5140        |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 3475        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019512556 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0094     |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 517        |\n",
      "|    time_elapsed         | 3480       |\n",
      "|    total_timesteps      | 1058816    |\n",
      "| total_reward_steps      | 75         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01929349 |\n",
      "|    clip_fraction        | 0.425      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.952     |\n",
      "|    explained_variance   | 0.78       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0125    |\n",
      "|    n_updates            | 5160       |\n",
      "|    policy_gradient_loss | -0.0247    |\n",
      "|    value_loss           | 0.0976     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 518         |\n",
      "|    time_elapsed         | 3486        |\n",
      "|    total_timesteps      | 1060864     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014085183 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 0.463       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 3491        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016999152 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0914      |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    value_loss           | 0.712       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 3497        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026195783 |\n",
      "|    clip_fraction        | 0.507       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.96        |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    value_loss           | 10.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 3503        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020086467 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0564      |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 3508        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019661266 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.73       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 523         |\n",
      "|    time_elapsed         | 3515        |\n",
      "|    total_timesteps      | 1071104     |\n",
      "| total_reward_steps      | 188         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015675087 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 3522        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015348632 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02        |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 3528        |\n",
      "|    total_timesteps      | 1075200     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012915034 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00761     |\n",
      "|    n_updates            | 5240        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.432       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 3535        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016353833 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.629       |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 3542        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015601691 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.93       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 528         |\n",
      "|    time_elapsed         | 3549        |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014000209 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 3555        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| total_reward_steps      | 231         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013401413 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.794      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0102      |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 3562        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018449645 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    value_loss           | 7.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 3569        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016751558 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.784      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 3576        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022045735 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00923     |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 533         |\n",
      "|    time_elapsed         | 3582        |\n",
      "|    total_timesteps      | 1091584     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014077177 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0736      |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 0.0931      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 3589        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| total_reward_steps      | 145         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019642826 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 535         |\n",
      "|    time_elapsed         | 3596        |\n",
      "|    total_timesteps      | 1095680     |\n",
      "| total_reward_steps      | 135         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020269353 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 3603        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018084869 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.841      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00536     |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.333       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 537        |\n",
      "|    time_elapsed         | 3610       |\n",
      "|    total_timesteps      | 1099776    |\n",
      "| total_reward_steps      | 146        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02034805 |\n",
      "|    clip_fraction        | 0.424      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.903     |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00174   |\n",
      "|    n_updates            | 5360       |\n",
      "|    policy_gradient_loss | -0.00468   |\n",
      "|    value_loss           | 1.2        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=95.00 +/- 37.74\n",
      "Episode length: 1053.17 +/- 188.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.05e+03   |\n",
      "|    mean_reward          | 95         |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04732385 |\n",
      "|    clip_fraction        | 0.446      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.136      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.32       |\n",
      "|    n_updates            | 5370       |\n",
      "|    policy_gradient_loss | 0.018      |\n",
      "|    value_loss           | 7.41       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 301      |\n",
      "|    iterations      | 538      |\n",
      "|    time_elapsed    | 3655     |\n",
      "|    total_timesteps | 1101824  |\n",
      "| total_reward_steps | 111      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 539         |\n",
      "|    time_elapsed         | 3662        |\n",
      "|    total_timesteps      | 1103872     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018936083 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.784      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 3669        |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021550361 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0583      |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.266       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 3676        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| total_reward_steps      | 160         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024894929 |\n",
      "|    clip_fraction        | 0.451       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.0983      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 542         |\n",
      "|    time_elapsed         | 3682        |\n",
      "|    total_timesteps      | 1110016     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054213803 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.0846      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.141       |\n",
      "|    n_updates            | 5410        |\n",
      "|    policy_gradient_loss | 0.017       |\n",
      "|    value_loss           | 5           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 3689        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| total_reward_steps      | 157         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023865124 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 3696        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018682532 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 3703        |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022984326 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0585      |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 3709        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017092872 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00784    |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 547         |\n",
      "|    time_elapsed         | 3716        |\n",
      "|    total_timesteps      | 1120256     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015765361 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0364     |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.0928      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 301       |\n",
      "|    iterations           | 548       |\n",
      "|    time_elapsed         | 3723      |\n",
      "|    total_timesteps      | 1122304   |\n",
      "| total_reward_steps      | 111       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0161658 |\n",
      "|    clip_fraction        | 0.35      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.809    |\n",
      "|    explained_variance   | 0.66      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.00757   |\n",
      "|    n_updates            | 5470      |\n",
      "|    policy_gradient_loss | -0.0139   |\n",
      "|    value_loss           | 0.243     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 3729        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015161008 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.791      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.425       |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 1.77        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 301          |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 3736         |\n",
      "|    total_timesteps      | 1126400      |\n",
      "| total_reward_steps      | 91           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153839765 |\n",
      "|    clip_fraction        | 0.384        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.855       |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0159      |\n",
      "|    n_updates            | 5490         |\n",
      "|    policy_gradient_loss | -0.0245      |\n",
      "|    value_loss           | 0.086        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 3742        |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012450116 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 552         |\n",
      "|    time_elapsed         | 3748        |\n",
      "|    total_timesteps      | 1130496     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012908951 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 3755        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015242066 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00531     |\n",
      "|    n_updates            | 5520        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 3761        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016714903 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0301     |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 3767        |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012946233 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.0889      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 3774        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013244469 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00594    |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 557         |\n",
      "|    time_elapsed         | 3780        |\n",
      "|    total_timesteps      | 1140736     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015326677 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.0824      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 3786        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016598472 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0349     |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 3793        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012844009 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.81       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.0823      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 3798        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016064119 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0482     |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.0725      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 301        |\n",
      "|    iterations           | 561        |\n",
      "|    time_elapsed         | 3804       |\n",
      "|    total_timesteps      | 1148928    |\n",
      "| total_reward_steps      | 122        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01335167 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.843     |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0188    |\n",
      "|    n_updates            | 5600       |\n",
      "|    policy_gradient_loss | -0.0191    |\n",
      "|    value_loss           | 0.0926     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 562         |\n",
      "|    time_elapsed         | 3810        |\n",
      "|    total_timesteps      | 1150976     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017291933 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0968      |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 0.0834      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 563        |\n",
      "|    time_elapsed         | 3815       |\n",
      "|    total_timesteps      | 1153024    |\n",
      "| total_reward_steps      | 122        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01807772 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.884     |\n",
      "|    explained_variance   | 0.712      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00313   |\n",
      "|    n_updates            | 5620       |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 0.153      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 564        |\n",
      "|    time_elapsed         | 3821       |\n",
      "|    total_timesteps      | 1155072    |\n",
      "| total_reward_steps      | 95         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01419021 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.718     |\n",
      "|    explained_variance   | 0.833      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00137    |\n",
      "|    n_updates            | 5630       |\n",
      "|    policy_gradient_loss | -0.016     |\n",
      "|    value_loss           | 0.176      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 3828        |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018587308 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.0957      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 3835        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021225099 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 0.473       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 567         |\n",
      "|    time_elapsed         | 3842        |\n",
      "|    total_timesteps      | 1161216     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016350985 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00833     |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.412       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 3848        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017633338 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000566    |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.091       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 569        |\n",
      "|    time_elapsed         | 3855       |\n",
      "|    total_timesteps      | 1165312    |\n",
      "| total_reward_steps      | 192        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01554838 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.889     |\n",
      "|    explained_variance   | 0.605      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.046      |\n",
      "|    n_updates            | 5680       |\n",
      "|    policy_gradient_loss | -0.00865   |\n",
      "|    value_loss           | 0.34       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 3862       |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| total_reward_steps      | 118        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03211931 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.822     |\n",
      "|    explained_variance   | 0.141      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.181      |\n",
      "|    n_updates            | 5690       |\n",
      "|    policy_gradient_loss | 0.00207    |\n",
      "|    value_loss           | 3.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 3869        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| total_reward_steps      | 128         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021055564 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.456       |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 572        |\n",
      "|    time_elapsed         | 3876       |\n",
      "|    total_timesteps      | 1171456    |\n",
      "| total_reward_steps      | 52         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01860683 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.894     |\n",
      "|    explained_variance   | 0.513      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0163    |\n",
      "|    n_updates            | 5710       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 3882        |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021410402 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0731      |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 574         |\n",
      "|    time_elapsed         | 3889        |\n",
      "|    total_timesteps      | 1175552     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015750078 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 5730        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 0.0779      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 3896        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012350613 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00709     |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 0.0794      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 3903        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015045675 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 0.0756      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 577         |\n",
      "|    time_elapsed         | 3909        |\n",
      "|    total_timesteps      | 1181696     |\n",
      "| total_reward_steps      | 147         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021789756 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 5760        |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 0.0987      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 578        |\n",
      "|    time_elapsed         | 3916       |\n",
      "|    total_timesteps      | 1183744    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01864604 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.737     |\n",
      "|    explained_variance   | 0.434      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 5770       |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    value_loss           | 1.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 3923        |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013889418 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00805    |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.0889      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 3930        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| total_reward_steps      | 164         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016067835 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.092       |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.0917      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 3936        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| total_reward_steps      | 193         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.078367084 |\n",
      "|    clip_fraction        | 0.463       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.269       |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    value_loss           | 3.38        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 302        |\n",
      "|    iterations           | 582        |\n",
      "|    time_elapsed         | 3943       |\n",
      "|    total_timesteps      | 1191936    |\n",
      "| total_reward_steps      | 102        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04569427 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | 0.0249     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00277    |\n",
      "|    n_updates            | 5810       |\n",
      "|    policy_gradient_loss | 0.0127     |\n",
      "|    value_loss           | 5.97       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 3950        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021760762 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | -0.101      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 584         |\n",
      "|    time_elapsed         | 3957        |\n",
      "|    total_timesteps      | 1196032     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019757807 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00609     |\n",
      "|    n_updates            | 5830        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 3964        |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026124228 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    value_loss           | 2.36        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=117.50 +/- 19.81\n",
      "Episode length: 1347.67 +/- 115.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | 118         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024576502 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 5850        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 298     |\n",
      "|    iterations      | 586     |\n",
      "|    time_elapsed    | 4020    |\n",
      "|    total_timesteps | 1200128 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 4027        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019979272 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0354      |\n",
      "|    n_updates            | 5860        |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.0888      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 4033        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024808628 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0225     |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 4040        |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021414548 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00703    |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 4046        |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023452265 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0355      |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.347       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 591         |\n",
      "|    time_elapsed         | 4052        |\n",
      "|    total_timesteps      | 1210368     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026858399 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.791      |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 1.54        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 592        |\n",
      "|    time_elapsed         | 4059       |\n",
      "|    total_timesteps      | 1212416    |\n",
      "| total_reward_steps      | 120        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02298378 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.67      |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00201    |\n",
      "|    n_updates            | 5910       |\n",
      "|    policy_gradient_loss | 0.000708   |\n",
      "|    value_loss           | 0.613      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 4065        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| total_reward_steps      | 120         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045610666 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.2         |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | 0.00669     |\n",
      "|    value_loss           | 9.28        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 594        |\n",
      "|    time_elapsed         | 4071       |\n",
      "|    total_timesteps      | 1216512    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04319223 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.722     |\n",
      "|    explained_variance   | 0.595      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0937     |\n",
      "|    n_updates            | 5930       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 0.419      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 4077        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022882096 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 596         |\n",
      "|    time_elapsed         | 4083        |\n",
      "|    total_timesteps      | 1220608     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022207446 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0024     |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 4090        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021273758 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.0974      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 598        |\n",
      "|    time_elapsed         | 4097       |\n",
      "|    total_timesteps      | 1224704    |\n",
      "| total_reward_steps      | 154        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08599768 |\n",
      "|    clip_fraction        | 0.483      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.714     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.21       |\n",
      "|    n_updates            | 5970       |\n",
      "|    policy_gradient_loss | 0.0296     |\n",
      "|    value_loss           | 11.7       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 599       |\n",
      "|    time_elapsed         | 4104      |\n",
      "|    total_timesteps      | 1226752   |\n",
      "| total_reward_steps      | 113       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0500884 |\n",
      "|    clip_fraction        | 0.381     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.612    |\n",
      "|    explained_variance   | 0.268     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.103     |\n",
      "|    n_updates            | 5980      |\n",
      "|    policy_gradient_loss | 0.00171   |\n",
      "|    value_loss           | 1.67      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 4110        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034420878 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.653      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0351      |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 601        |\n",
      "|    time_elapsed         | 4117       |\n",
      "|    total_timesteps      | 1230848    |\n",
      "| total_reward_steps      | 86         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03149364 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.766     |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00969    |\n",
      "|    n_updates            | 6000       |\n",
      "|    policy_gradient_loss | -0.00365   |\n",
      "|    value_loss           | 2.73       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 4124        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019690376 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.762      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.011       |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 4131        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029377082 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0636      |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 0.696       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 604        |\n",
      "|    time_elapsed         | 4137       |\n",
      "|    total_timesteps      | 1236992    |\n",
      "| total_reward_steps      | 109        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01912542 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.797     |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0582     |\n",
      "|    n_updates            | 6030       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 4144        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021543527 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.0826      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 606         |\n",
      "|    time_elapsed         | 4151        |\n",
      "|    total_timesteps      | 1241088     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019238994 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00159    |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 4158        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| total_reward_steps      | 120         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023737716 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 4164        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030077672 |\n",
      "|    clip_fraction        | 0.435       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0715      |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | 0.00947     |\n",
      "|    value_loss           | 9.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 4171        |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035665557 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.24        |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | 0.00646     |\n",
      "|    value_loss           | 1.97        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 298        |\n",
      "|    iterations           | 610        |\n",
      "|    time_elapsed         | 4178       |\n",
      "|    total_timesteps      | 1249280    |\n",
      "| total_reward_steps      | 116        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965316 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.645     |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0657     |\n",
      "|    n_updates            | 6090       |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    value_loss           | 0.342      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 611         |\n",
      "|    time_elapsed         | 4185        |\n",
      "|    total_timesteps      | 1251328     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020071134 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 4191        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014712451 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.00962    |\n",
      "|    value_loss           | 0.403       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 613        |\n",
      "|    time_elapsed         | 4198       |\n",
      "|    total_timesteps      | 1255424    |\n",
      "| total_reward_steps      | 99         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02097797 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.756     |\n",
      "|    explained_variance   | 0.628      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.243      |\n",
      "|    n_updates            | 6120       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    value_loss           | 0.495      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 614        |\n",
      "|    time_elapsed         | 4205       |\n",
      "|    total_timesteps      | 1257472    |\n",
      "| total_reward_steps      | 106        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03644854 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.86       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0212    |\n",
      "|    n_updates            | 6130       |\n",
      "|    policy_gradient_loss | -0.0229    |\n",
      "|    value_loss           | 0.0919     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 4212        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| total_reward_steps      | 135         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025210658 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.0815      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 616         |\n",
      "|    time_elapsed         | 4219        |\n",
      "|    total_timesteps      | 1261568     |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024172086 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.705      |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    value_loss           | 0.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 4225        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| total_reward_steps      | 130         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017963408 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 618         |\n",
      "|    time_elapsed         | 4232        |\n",
      "|    total_timesteps      | 1265664     |\n",
      "| total_reward_steps      | 130         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025767371 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0694      |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 4239        |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020226963 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00581    |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 4246        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| total_reward_steps      | 180         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038540624 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0961      |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | 0.000409    |\n",
      "|    value_loss           | 2.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 621         |\n",
      "|    time_elapsed         | 4253        |\n",
      "|    total_timesteps      | 1271808     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031565476 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0579      |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    value_loss           | 2.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 4259        |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024358684 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.096       |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 4266        |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| total_reward_steps      | 159         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035709742 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.0718      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 8.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 4273        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026384465 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0822      |\n",
      "|    n_updates            | 6230        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 625         |\n",
      "|    time_elapsed         | 4280        |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026724923 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    value_loss           | 6.53        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 626        |\n",
      "|    time_elapsed         | 4286       |\n",
      "|    total_timesteps      | 1282048    |\n",
      "| total_reward_steps      | 102        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02519281 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.841     |\n",
      "|    explained_variance   | -0.452     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.1        |\n",
      "|    n_updates            | 6250       |\n",
      "|    policy_gradient_loss | -0.00477   |\n",
      "|    value_loss           | 0.589      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 627        |\n",
      "|    time_elapsed         | 4293       |\n",
      "|    total_timesteps      | 1284096    |\n",
      "| total_reward_steps      | 234        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02238375 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.729     |\n",
      "|    explained_variance   | 0.702      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0457     |\n",
      "|    n_updates            | 6260       |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 0.245      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 4300        |\n",
      "|    total_timesteps      | 1286144     |\n",
      "| total_reward_steps      | 222         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025442217 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | 0.0156      |\n",
      "|    value_loss           | 7.54        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 629        |\n",
      "|    time_elapsed         | 4306       |\n",
      "|    total_timesteps      | 1288192    |\n",
      "| total_reward_steps      | 77         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02968311 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | 0.599      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0117     |\n",
      "|    n_updates            | 6280       |\n",
      "|    policy_gradient_loss | 0.00515    |\n",
      "|    value_loss           | 6.29       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 630         |\n",
      "|    time_elapsed         | 4312        |\n",
      "|    total_timesteps      | 1290240     |\n",
      "| total_reward_steps      | 173         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029067297 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | -0.684      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.623       |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | 0.000459    |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 4319        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050451502 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0713      |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | 0.022       |\n",
      "|    value_loss           | 8.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 4325        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| total_reward_steps      | 172         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025490563 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0211      |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 4331        |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| total_reward_steps      | 142         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027999142 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0576      |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    value_loss           | 2.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 299         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 4338        |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042862535 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0751      |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=138.77 +/- 54.26\n",
      "Episode length: 1399.03 +/- 105.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.4e+03    |\n",
      "|    mean_reward          | 139        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1300000    |\n",
      "| total_reward_steps      | 132        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02675672 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.796     |\n",
      "|    explained_variance   | 0.792      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0866     |\n",
      "|    n_updates            | 6340       |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 0.13       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 295      |\n",
      "|    iterations      | 635      |\n",
      "|    time_elapsed    | 4395     |\n",
      "|    total_timesteps | 1300480  |\n",
      "| total_reward_steps | 118      |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 295       |\n",
      "|    iterations           | 636       |\n",
      "|    time_elapsed         | 4402      |\n",
      "|    total_timesteps      | 1302528   |\n",
      "| total_reward_steps      | 79        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0201176 |\n",
      "|    clip_fraction        | 0.371     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.755    |\n",
      "|    explained_variance   | 0.532     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | -0.0106   |\n",
      "|    n_updates            | 6350      |\n",
      "|    policy_gradient_loss | -0.000844 |\n",
      "|    value_loss           | 0.308     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 4409        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| total_reward_steps      | 120         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019616451 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 638        |\n",
      "|    time_elapsed         | 4416       |\n",
      "|    total_timesteps      | 1306624    |\n",
      "| total_reward_steps      | 119        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02257846 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.727     |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00397   |\n",
      "|    n_updates            | 6370       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 0.29       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 4422        |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013478105 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.234       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 640         |\n",
      "|    time_elapsed         | 4429        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| total_reward_steps      | 241         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017024891 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00304    |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.289       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 295       |\n",
      "|    iterations           | 641       |\n",
      "|    time_elapsed         | 4436      |\n",
      "|    total_timesteps      | 1312768   |\n",
      "| total_reward_steps      | 77        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0872007 |\n",
      "|    clip_fraction        | 0.513     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.811    |\n",
      "|    explained_variance   | 0.0786    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.135     |\n",
      "|    n_updates            | 6400      |\n",
      "|    policy_gradient_loss | 0.0293    |\n",
      "|    value_loss           | 16        |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 295       |\n",
      "|    iterations           | 642       |\n",
      "|    time_elapsed         | 4443      |\n",
      "|    total_timesteps      | 1314816   |\n",
      "| total_reward_steps      | 368       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0234038 |\n",
      "|    clip_fraction        | 0.407     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.824    |\n",
      "|    explained_variance   | -0.376    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.148     |\n",
      "|    n_updates            | 6410      |\n",
      "|    policy_gradient_loss | -0.00515  |\n",
      "|    value_loss           | 0.358     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 4449        |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.084512696 |\n",
      "|    clip_fraction        | 0.514       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.277       |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | 0.0432      |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 4456        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| total_reward_steps      | 164         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032733496 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | -0.102      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | 0.00771     |\n",
      "|    value_loss           | 1.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 645         |\n",
      "|    time_elapsed         | 4463        |\n",
      "|    total_timesteps      | 1320960     |\n",
      "| total_reward_steps      | 168         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037053175 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 4470       |\n",
      "|    total_timesteps      | 1323008    |\n",
      "| total_reward_steps      | 127        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02629438 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.467     |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0685     |\n",
      "|    n_updates            | 6450       |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    value_loss           | 1.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 4477        |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032665204 |\n",
      "|    clip_fraction        | 0.493       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 648        |\n",
      "|    time_elapsed         | 4483       |\n",
      "|    total_timesteps      | 1327104    |\n",
      "| total_reward_steps      | 229        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02174303 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.656     |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.000455  |\n",
      "|    n_updates            | 6470       |\n",
      "|    policy_gradient_loss | -0.00985   |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 649        |\n",
      "|    time_elapsed         | 4490       |\n",
      "|    total_timesteps      | 1329152    |\n",
      "| total_reward_steps      | 411        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07910878 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.612     |\n",
      "|    explained_variance   | 0.136      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 45.5       |\n",
      "|    n_updates            | 6480       |\n",
      "|    policy_gradient_loss | 0.0387     |\n",
      "|    value_loss           | 15.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 650        |\n",
      "|    time_elapsed         | 4497       |\n",
      "|    total_timesteps      | 1331200    |\n",
      "| total_reward_steps      | 244        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.27074647 |\n",
      "|    clip_fraction        | 0.527      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.524     |\n",
      "|    explained_variance   | 0.0601     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.717      |\n",
      "|    n_updates            | 6490       |\n",
      "|    policy_gradient_loss | 0.0677     |\n",
      "|    value_loss           | 43.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 651        |\n",
      "|    time_elapsed         | 4504       |\n",
      "|    total_timesteps      | 1333248    |\n",
      "| total_reward_steps      | 132        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08081406 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.447     |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.255      |\n",
      "|    n_updates            | 6500       |\n",
      "|    policy_gradient_loss | 0.0362     |\n",
      "|    value_loss           | 7.42       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 4510        |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054959357 |\n",
      "|    clip_fraction        | 0.468       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | -0.341      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 0.592       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 653        |\n",
      "|    time_elapsed         | 4517       |\n",
      "|    total_timesteps      | 1337344    |\n",
      "| total_reward_steps      | 79         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03200271 |\n",
      "|    clip_fraction        | 0.397      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.675     |\n",
      "|    explained_variance   | -0.145     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00861    |\n",
      "|    n_updates            | 6520       |\n",
      "|    policy_gradient_loss | -0.00288   |\n",
      "|    value_loss           | 0.327      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 4524        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034983367 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0584      |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.000586   |\n",
      "|    value_loss           | 0.674       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 655         |\n",
      "|    time_elapsed         | 4531        |\n",
      "|    total_timesteps      | 1341440     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027902937 |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    value_loss           | 0.392       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 4537        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| total_reward_steps      | 143         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021313056 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    value_loss           | 0.568       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 4544        |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022421286 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00862     |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 4551        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025407217 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 4558        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021304686 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00668    |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 660         |\n",
      "|    time_elapsed         | 4565        |\n",
      "|    total_timesteps      | 1351680     |\n",
      "| total_reward_steps      | 127         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032364156 |\n",
      "|    clip_fraction        | 0.442       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.8        |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | 0.0195      |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 4571        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022475995 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00961    |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 4578        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016304312 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0765      |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 4584        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| total_reward_steps      | 126         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060802877 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0635      |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 4591        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017459681 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 665         |\n",
      "|    time_elapsed         | 4597        |\n",
      "|    total_timesteps      | 1361920     |\n",
      "| total_reward_steps      | 162         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016893286 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 4603        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022281248 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | 0.00241     |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019561911 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00607    |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 4616        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020412028 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 6670        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 669         |\n",
      "|    time_elapsed         | 4623        |\n",
      "|    total_timesteps      | 1370112     |\n",
      "| total_reward_steps      | 165         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015436254 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00326    |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 4630       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| total_reward_steps      | 211        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03288895 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.678     |\n",
      "|    explained_variance   | 0.13       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.262      |\n",
      "|    n_updates            | 6690       |\n",
      "|    policy_gradient_loss | 0.0139     |\n",
      "|    value_loss           | 4.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 4637        |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018970389 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | 0.00295     |\n",
      "|    value_loss           | 3.45        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 672        |\n",
      "|    time_elapsed         | 4643       |\n",
      "|    total_timesteps      | 1376256    |\n",
      "| total_reward_steps      | 88         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02411639 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.7       |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.144      |\n",
      "|    n_updates            | 6710       |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 0.142      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 4650        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018537436 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 674         |\n",
      "|    time_elapsed         | 4657        |\n",
      "|    total_timesteps      | 1380352     |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022819322 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0618      |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 4664        |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022602975 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 6740        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 4671        |\n",
      "|    total_timesteps      | 1384448     |\n",
      "| total_reward_steps      | 142         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021940228 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0261     |\n",
      "|    n_updates            | 6750        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 677         |\n",
      "|    time_elapsed         | 4677        |\n",
      "|    total_timesteps      | 1386496     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022362035 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00437     |\n",
      "|    n_updates            | 6760        |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 4684        |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020487575 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00788    |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 296       |\n",
      "|    iterations           | 679       |\n",
      "|    time_elapsed         | 4691      |\n",
      "|    total_timesteps      | 1390592   |\n",
      "| total_reward_steps      | 121       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0157561 |\n",
      "|    clip_fraction        | 0.351     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.751    |\n",
      "|    explained_variance   | 0.918     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0533    |\n",
      "|    n_updates            | 6780      |\n",
      "|    policy_gradient_loss | -0.0185   |\n",
      "|    value_loss           | 0.0883    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 4698        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024523415 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 4704        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032056585 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0918      |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | 0.00485     |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 682         |\n",
      "|    time_elapsed         | 4711        |\n",
      "|    total_timesteps      | 1396736     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014277203 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.01        |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 4718        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| total_reward_steps      | 169         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015975624 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00421     |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.0849      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=142.90 +/- 39.30\n",
      "Episode length: 2401.73 +/- 6238.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 143         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019284094 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0902      |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 291      |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 4812     |\n",
      "|    total_timesteps | 1400832  |\n",
      "| total_reward_steps | 133      |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 4819       |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| total_reward_steps      | 139        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08857654 |\n",
      "|    clip_fraction        | 0.469      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.729     |\n",
      "|    explained_variance   | -0.00194   |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 96.5       |\n",
      "|    n_updates            | 6840       |\n",
      "|    policy_gradient_loss | 0.0545     |\n",
      "|    value_loss           | 45         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 4826        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022252323 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 4832        |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032273896 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.851      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000496   |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 0.439       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 4838        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023715723 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 0.534       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 689         |\n",
      "|    time_elapsed         | 4845        |\n",
      "|    total_timesteps      | 1411072     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018363686 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00916    |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 4851        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018482592 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 691        |\n",
      "|    time_elapsed         | 4858       |\n",
      "|    total_timesteps      | 1415168    |\n",
      "| total_reward_steps      | 108        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01931082 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.813     |\n",
      "|    explained_variance   | 0.872      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0282     |\n",
      "|    n_updates            | 6900       |\n",
      "|    policy_gradient_loss | -0.021     |\n",
      "|    value_loss           | 0.0847     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 4864        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| total_reward_steps      | 168         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017186351 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0678      |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 4869        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023247441 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.058       |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | 0.000634    |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 694        |\n",
      "|    time_elapsed         | 4875       |\n",
      "|    total_timesteps      | 1421312    |\n",
      "| total_reward_steps      | 153        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01825819 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.834     |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0297     |\n",
      "|    n_updates            | 6930       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 4882        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025318112 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.5         |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 696        |\n",
      "|    time_elapsed         | 4889       |\n",
      "|    total_timesteps      | 1425408    |\n",
      "| total_reward_steps      | 415        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01678232 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.738     |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0225     |\n",
      "|    n_updates            | 6950       |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    value_loss           | 0.271      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 697        |\n",
      "|    time_elapsed         | 4895       |\n",
      "|    total_timesteps      | 1427456    |\n",
      "| total_reward_steps      | 30         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26292193 |\n",
      "|    clip_fraction        | 0.533      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.641     |\n",
      "|    explained_variance   | 0.0438     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.668      |\n",
      "|    n_updates            | 6960       |\n",
      "|    policy_gradient_loss | 0.0673     |\n",
      "|    value_loss           | 62.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 4902        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035806574 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0258      |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    value_loss           | 0.251       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 699        |\n",
      "|    time_elapsed         | 4909       |\n",
      "|    total_timesteps      | 1431552    |\n",
      "| total_reward_steps      | 114        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02891494 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.692     |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00936    |\n",
      "|    n_updates            | 6980       |\n",
      "|    policy_gradient_loss | 0.00117    |\n",
      "|    value_loss           | 0.817      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 4916        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034653455 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 9.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 4922        |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037967853 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | 0.00999     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 4929        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032287512 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.205       |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 4936        |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028801061 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 704         |\n",
      "|    time_elapsed         | 4943        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023816913 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 4950        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038396426 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.178       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | 0.017       |\n",
      "|    value_loss           | 8.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 4956        |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| total_reward_steps      | 192         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021771966 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00205    |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 707        |\n",
      "|    time_elapsed         | 4963       |\n",
      "|    total_timesteps      | 1447936    |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03816826 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.722     |\n",
      "|    explained_variance   | 0.167      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0555     |\n",
      "|    n_updates            | 7060       |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    value_loss           | 2.33       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 4970        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| total_reward_steps      | 13          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025651198 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 7070        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 709         |\n",
      "|    time_elapsed         | 4977        |\n",
      "|    total_timesteps      | 1452032     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024405213 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0932      |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 0.302       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 710        |\n",
      "|    time_elapsed         | 4983       |\n",
      "|    total_timesteps      | 1454080    |\n",
      "| total_reward_steps      | 80         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01838993 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.693     |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0118    |\n",
      "|    n_updates            | 7090       |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 4990        |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026915219 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0789      |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    value_loss           | 1.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 4997        |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036671102 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | 0.00976     |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 713         |\n",
      "|    time_elapsed         | 5004        |\n",
      "|    total_timesteps      | 1460224     |\n",
      "| total_reward_steps      | 218         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021131326 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0838      |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 714        |\n",
      "|    time_elapsed         | 5011       |\n",
      "|    total_timesteps      | 1462272    |\n",
      "| total_reward_steps      | 86         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07506025 |\n",
      "|    clip_fraction        | 0.456      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.726     |\n",
      "|    explained_variance   | 0.125      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.14       |\n",
      "|    n_updates            | 7130       |\n",
      "|    policy_gradient_loss | 0.0446     |\n",
      "|    value_loss           | 15.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 5017        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026710533 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    value_loss           | 9.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 716         |\n",
      "|    time_elapsed         | 5024        |\n",
      "|    total_timesteps      | 1466368     |\n",
      "| total_reward_steps      | 243         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031577244 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 5031        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| total_reward_steps      | 164         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031642687 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.54        |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    value_loss           | 7.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 718        |\n",
      "|    time_elapsed         | 5038       |\n",
      "|    total_timesteps      | 1470464    |\n",
      "| total_reward_steps      | 12         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30961597 |\n",
      "|    clip_fraction        | 0.549      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.586     |\n",
      "|    explained_variance   | 0.0338     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.725      |\n",
      "|    n_updates            | 7170       |\n",
      "|    policy_gradient_loss | 0.0751     |\n",
      "|    value_loss           | 51.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 5044        |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044331092 |\n",
      "|    clip_fraction        | 0.434       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00235     |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 5051        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| total_reward_steps      | 209         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021450445 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00876    |\n",
      "|    n_updates            | 7190        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 721         |\n",
      "|    time_elapsed         | 5058        |\n",
      "|    total_timesteps      | 1476608     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028427672 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 7200        |\n",
      "|    policy_gradient_loss | 0.0085      |\n",
      "|    value_loss           | 5.48        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 722        |\n",
      "|    time_elapsed         | 5065       |\n",
      "|    total_timesteps      | 1478656    |\n",
      "| total_reward_steps      | 79         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01828628 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.667     |\n",
      "|    explained_variance   | 0.657      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00881   |\n",
      "|    n_updates            | 7210       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    value_loss           | 0.129      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 291        |\n",
      "|    iterations           | 723        |\n",
      "|    time_elapsed         | 5071       |\n",
      "|    total_timesteps      | 1480704    |\n",
      "| total_reward_steps      | 81         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01850221 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.757     |\n",
      "|    explained_variance   | 0.848      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.103      |\n",
      "|    n_updates            | 7220       |\n",
      "|    policy_gradient_loss | -0.0225    |\n",
      "|    value_loss           | 0.077      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 5078        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017306766 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.0637      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 5085        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017102208 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.0788      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 5091        |\n",
      "|    total_timesteps      | 1486848     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014990114 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0457      |\n",
      "|    n_updates            | 7250        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 0.0764      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 5098        |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014730008 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0503      |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 0.0801      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 728         |\n",
      "|    time_elapsed         | 5104        |\n",
      "|    total_timesteps      | 1490944     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013665715 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0385      |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.0686      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 5110        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018221065 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 7280        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.0744      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 5117        |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040302593 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 5123        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015772505 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0824      |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 292      |\n",
      "|    iterations           | 732      |\n",
      "|    time_elapsed         | 5130     |\n",
      "|    total_timesteps      | 1499136  |\n",
      "| total_reward_steps      | 96       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.029142 |\n",
      "|    clip_fraction        | 0.399    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.779   |\n",
      "|    explained_variance   | 0.599    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | -0.0108  |\n",
      "|    n_updates            | 7310     |\n",
      "|    policy_gradient_loss | -0.00614 |\n",
      "|    value_loss           | 0.822    |\n",
      "--------------------------------------\n",
      "Eval num_timesteps=1500000, episode_reward=91.60 +/- 9.46\n",
      "Episode length: 1144.03 +/- 98.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | 91.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016857313 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00288     |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.0889      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 289      |\n",
      "|    iterations      | 733      |\n",
      "|    time_elapsed    | 5178     |\n",
      "|    total_timesteps | 1501184  |\n",
      "| total_reward_steps | 105      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 5185        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| total_reward_steps      | 130         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022090713 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.308       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 735        |\n",
      "|    time_elapsed         | 5192       |\n",
      "|    total_timesteps      | 1505280    |\n",
      "| total_reward_steps      | 163        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880875 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.81      |\n",
      "|    explained_variance   | 0.637      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0081    |\n",
      "|    n_updates            | 7340       |\n",
      "|    policy_gradient_loss | -0.00723   |\n",
      "|    value_loss           | 0.708      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 736        |\n",
      "|    time_elapsed         | 5199       |\n",
      "|    total_timesteps      | 1507328    |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04469432 |\n",
      "|    clip_fraction        | 0.458      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.735     |\n",
      "|    explained_variance   | 0.27       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0302     |\n",
      "|    n_updates            | 7350       |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    value_loss           | 2.87       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 5206        |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036184415 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 738         |\n",
      "|    time_elapsed         | 5212        |\n",
      "|    total_timesteps      | 1511424     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021764318 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0142     |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0937      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 5219        |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| total_reward_steps      | 365         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028528787 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 740        |\n",
      "|    time_elapsed         | 5226       |\n",
      "|    total_timesteps      | 1515520    |\n",
      "| total_reward_steps      | 3          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16741209 |\n",
      "|    clip_fraction        | 0.53       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.633     |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.45       |\n",
      "|    n_updates            | 7390       |\n",
      "|    policy_gradient_loss | 0.0726     |\n",
      "|    value_loss           | 70.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 5233        |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056289986 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | -0.98       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 7400        |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 742        |\n",
      "|    time_elapsed         | 5239       |\n",
      "|    total_timesteps      | 1519616    |\n",
      "| total_reward_steps      | 57         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04504527 |\n",
      "|    clip_fraction        | 0.303      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.424     |\n",
      "|    explained_variance   | 0.566      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00766   |\n",
      "|    n_updates            | 7410       |\n",
      "|    policy_gradient_loss | -0.00796   |\n",
      "|    value_loss           | 0.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 743         |\n",
      "|    time_elapsed         | 5246        |\n",
      "|    total_timesteps      | 1521664     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030334977 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 5253        |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026292283 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00881    |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -2.58e-05   |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 745        |\n",
      "|    time_elapsed         | 5260       |\n",
      "|    total_timesteps      | 1525760    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04180224 |\n",
      "|    clip_fraction        | 0.431      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.0645     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.163      |\n",
      "|    n_updates            | 7440       |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    value_loss           | 2.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 5266        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| total_reward_steps      | 8           |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023985345 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 747        |\n",
      "|    time_elapsed         | 5273       |\n",
      "|    total_timesteps      | 1529856    |\n",
      "| total_reward_steps      | 145        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04239475 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0696     |\n",
      "|    n_updates            | 7460       |\n",
      "|    policy_gradient_loss | 0.0169     |\n",
      "|    value_loss           | 6.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 748         |\n",
      "|    time_elapsed         | 5280        |\n",
      "|    total_timesteps      | 1531904     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034946565 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.371       |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 5287        |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021796063 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.0287      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.615       |\n",
      "|    n_updates            | 7480        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 5294        |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026166499 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0.182       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0453      |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 5300        |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| total_reward_steps      | 242         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018358285 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | 0.000203    |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 752        |\n",
      "|    time_elapsed         | 5307       |\n",
      "|    total_timesteps      | 1540096    |\n",
      "| total_reward_steps      | 72         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07042251 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.611     |\n",
      "|    explained_variance   | 0.0942     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.302      |\n",
      "|    n_updates            | 7510       |\n",
      "|    policy_gradient_loss | 0.0164     |\n",
      "|    value_loss           | 19.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 5314        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028790928 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | 0.000864    |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 5321        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028404841 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0734      |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.346       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 5327        |\n",
      "|    total_timesteps      | 1546240     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034981325 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 5334        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019300144 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0941      |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 757         |\n",
      "|    time_elapsed         | 5341        |\n",
      "|    total_timesteps      | 1550336     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029061805 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.03        |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | 0.00464     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 5347        |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016799403 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0478      |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 5353        |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021965789 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00733     |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 5360        |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016058732 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 0.382       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 5366        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029290672 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.163       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    value_loss           | 6.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 762         |\n",
      "|    time_elapsed         | 5373        |\n",
      "|    total_timesteps      | 1560576     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020601638 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0313      |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.208       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 5379        |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| total_reward_steps      | 150         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017435366 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.361       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 5386        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| total_reward_steps      | 208         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018671751 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.58       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.000991   |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 5393        |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| total_reward_steps      | 450         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029129874 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    value_loss           | 6.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 766        |\n",
      "|    time_elapsed         | 5400       |\n",
      "|    total_timesteps      | 1568768    |\n",
      "| total_reward_steps      | 124        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03312561 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.652     |\n",
      "|    explained_variance   | 0.247      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.72       |\n",
      "|    n_updates            | 7650       |\n",
      "|    policy_gradient_loss | 0.0201     |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 767         |\n",
      "|    time_elapsed         | 5406        |\n",
      "|    total_timesteps      | 1570816     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029188063 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | 0.00778     |\n",
      "|    value_loss           | 1.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 5413        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033027217 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0336      |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.713       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 5420        |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| total_reward_steps      | 147         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022264108 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 0.511       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 770         |\n",
      "|    time_elapsed         | 5427        |\n",
      "|    total_timesteps      | 1576960     |\n",
      "| total_reward_steps      | 140         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022466656 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.917       |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | 0.0043      |\n",
      "|    value_loss           | 0.763       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 290       |\n",
      "|    iterations           | 771       |\n",
      "|    time_elapsed         | 5434      |\n",
      "|    total_timesteps      | 1579008   |\n",
      "| total_reward_steps      | 64        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0337269 |\n",
      "|    clip_fraction        | 0.36      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.619    |\n",
      "|    explained_variance   | 0.347     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0727    |\n",
      "|    n_updates            | 7700      |\n",
      "|    policy_gradient_loss | -0.000217 |\n",
      "|    value_loss           | 0.899     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 772         |\n",
      "|    time_elapsed         | 5440        |\n",
      "|    total_timesteps      | 1581056     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023455335 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0295      |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.000137   |\n",
      "|    value_loss           | 0.851       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 5447        |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021155242 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0691      |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.547       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 5454        |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029108752 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00425    |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.47        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 775        |\n",
      "|    time_elapsed         | 5461       |\n",
      "|    total_timesteps      | 1587200    |\n",
      "| total_reward_steps      | 127        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02091336 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.634     |\n",
      "|    explained_variance   | 0.823      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0143    |\n",
      "|    n_updates            | 7740       |\n",
      "|    policy_gradient_loss | -0.0069    |\n",
      "|    value_loss           | 0.171      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 5468        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029535217 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32        |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 777        |\n",
      "|    time_elapsed         | 5474       |\n",
      "|    total_timesteps      | 1591296    |\n",
      "| total_reward_steps      | 94         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15698595 |\n",
      "|    clip_fraction        | 0.477      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.575     |\n",
      "|    explained_variance   | 0.0417     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 56.4       |\n",
      "|    n_updates            | 7760       |\n",
      "|    policy_gradient_loss | 0.0711     |\n",
      "|    value_loss           | 42.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 778        |\n",
      "|    time_elapsed         | 5481       |\n",
      "|    total_timesteps      | 1593344    |\n",
      "| total_reward_steps      | 135        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03619255 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.542     |\n",
      "|    explained_variance   | -0.0255    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.315      |\n",
      "|    n_updates            | 7770       |\n",
      "|    policy_gradient_loss | 0.0142     |\n",
      "|    value_loss           | 7.93       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 5488        |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| total_reward_steps      | 248         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033065964 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0491      |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | 6.18e-05    |\n",
      "|    value_loss           | 0.75        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 5495        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025731778 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 9.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 290         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 5501        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| total_reward_steps      | 233         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042075366 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.13        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=123.23 +/- 51.04\n",
      "Episode length: 1092.20 +/- 111.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.09e+03   |\n",
      "|    mean_reward          | 123        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02653144 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.608     |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 9.22       |\n",
      "|    n_updates            | 7810       |\n",
      "|    policy_gradient_loss | 0.00549    |\n",
      "|    value_loss           | 8.12       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 5548     |\n",
      "|    total_timesteps | 1601536  |\n",
      "| total_reward_steps | 90       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 5555        |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019457025 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0132      |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 5562        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| total_reward_steps      | 378         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027180137 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 7830        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.377       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 5569        |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044021644 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.101       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 750         |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | 0.0288      |\n",
      "|    value_loss           | 54.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 5576        |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029086342 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | -0.227      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | 0.00253     |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 787         |\n",
      "|    time_elapsed         | 5582        |\n",
      "|    total_timesteps      | 1611776     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029234834 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.574      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0234      |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.398       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 5589        |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047705628 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0907      |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | 0.00795     |\n",
      "|    value_loss           | 0.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 5595        |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030088268 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.651       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | 0.00242     |\n",
      "|    value_loss           | 0.568       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 5602        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024040125 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 791       |\n",
      "|    time_elapsed         | 5608      |\n",
      "|    total_timesteps      | 1619968   |\n",
      "| total_reward_steps      | 71        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0207575 |\n",
      "|    clip_fraction        | 0.327     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.6      |\n",
      "|    explained_variance   | 0.522     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 18.1      |\n",
      "|    n_updates            | 7900      |\n",
      "|    policy_gradient_loss | 0.00125   |\n",
      "|    value_loss           | 1.65      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 792         |\n",
      "|    time_elapsed         | 5614        |\n",
      "|    total_timesteps      | 1622016     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024801549 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 5621        |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023667507 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.000834   |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 5628        |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| total_reward_steps      | 234         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028845828 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0603      |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 1.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 5634        |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| total_reward_steps      | 209         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027043313 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.434       |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | 0.00598     |\n",
      "|    value_loss           | 9.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 796         |\n",
      "|    time_elapsed         | 5641        |\n",
      "|    total_timesteps      | 1630208     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037766226 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.653       |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | 0.0289      |\n",
      "|    value_loss           | 8.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 5648        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| total_reward_steps      | 20          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045375686 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.0887      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 7960        |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 2.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 5655        |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| total_reward_steps      | 219         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033287123 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0503      |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 5662        |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040264692 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.469      |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.92        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | 0.0208      |\n",
      "|    value_loss           | 7.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 800         |\n",
      "|    time_elapsed         | 5668        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044075206 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 7990        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 801         |\n",
      "|    time_elapsed         | 5675        |\n",
      "|    total_timesteps      | 1640448     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018715646 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 5682        |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035832718 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.476       |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    value_loss           | 5.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 5689        |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017767387 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    value_loss           | 0.253       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 804         |\n",
      "|    time_elapsed         | 5696        |\n",
      "|    total_timesteps      | 1646592     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018192912 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 5702        |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| total_reward_steps      | 147         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015377424 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0692      |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 806         |\n",
      "|    time_elapsed         | 5709        |\n",
      "|    total_timesteps      | 1650688     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018852789 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0517      |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 1.8         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 807        |\n",
      "|    time_elapsed         | 5716       |\n",
      "|    total_timesteps      | 1652736    |\n",
      "| total_reward_steps      | 79         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05328258 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00309   |\n",
      "|    n_updates            | 8060       |\n",
      "|    policy_gradient_loss | -0.0268    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 808        |\n",
      "|    time_elapsed         | 5723       |\n",
      "|    total_timesteps      | 1654784    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02476858 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0.601      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0231     |\n",
      "|    n_updates            | 8070       |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    value_loss           | 0.349      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 809         |\n",
      "|    time_elapsed         | 5730        |\n",
      "|    total_timesteps      | 1656832     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016665528 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.606      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 5736        |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021018647 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0287      |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 811         |\n",
      "|    time_elapsed         | 5743        |\n",
      "|    total_timesteps      | 1660928     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015085973 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0088      |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 5750        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016794255 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00766    |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00709    |\n",
      "|    value_loss           | 0.419       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 5757        |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| total_reward_steps      | 139         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019400898 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.0935      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 5764        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021482628 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0513      |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 1.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 5770        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013761482 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0262      |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 816         |\n",
      "|    time_elapsed         | 5777        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| total_reward_steps      | 138         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014578449 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.622      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00919    |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 0.0893      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 5784        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034732934 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | 0.00956     |\n",
      "|    value_loss           | 2.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 5791        |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| total_reward_steps      | 365         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017028484 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.641       |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 819        |\n",
      "|    time_elapsed         | 5797       |\n",
      "|    total_timesteps      | 1677312    |\n",
      "| total_reward_steps      | 8          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22555304 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.342     |\n",
      "|    explained_variance   | 0.12       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 91.4       |\n",
      "|    n_updates            | 8180       |\n",
      "|    policy_gradient_loss | 0.0536     |\n",
      "|    value_loss           | 60.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 5804        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057705127 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.0736      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    value_loss           | 37.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 821        |\n",
      "|    time_elapsed         | 5811       |\n",
      "|    total_timesteps      | 1681408    |\n",
      "| total_reward_steps      | 22         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03250477 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.546     |\n",
      "|    explained_variance   | -0.331     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 8200       |\n",
      "|    policy_gradient_loss | 0.00577    |\n",
      "|    value_loss           | 0.379      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 5818        |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042119633 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | -0.0702     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | 0.00188     |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 823        |\n",
      "|    time_elapsed         | 5825       |\n",
      "|    total_timesteps      | 1685504    |\n",
      "| total_reward_steps      | 74         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02778369 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.638     |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 8220       |\n",
      "|    policy_gradient_loss | -0.00203   |\n",
      "|    value_loss           | 0.283      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 824        |\n",
      "|    time_elapsed         | 5831       |\n",
      "|    total_timesteps      | 1687552    |\n",
      "| total_reward_steps      | 57         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02145587 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.576     |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00981   |\n",
      "|    n_updates            | 8230       |\n",
      "|    policy_gradient_loss | -0.0062    |\n",
      "|    value_loss           | 0.0972     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 825        |\n",
      "|    time_elapsed         | 5838       |\n",
      "|    total_timesteps      | 1689600    |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01469499 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.593     |\n",
      "|    explained_variance   | 0.897      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.000101   |\n",
      "|    n_updates            | 8240       |\n",
      "|    policy_gradient_loss | -0.00946   |\n",
      "|    value_loss           | 0.0946     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 826         |\n",
      "|    time_elapsed         | 5844        |\n",
      "|    total_timesteps      | 1691648     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029089699 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0846      |\n",
      "|    n_updates            | 8250        |\n",
      "|    policy_gradient_loss | 0.000441    |\n",
      "|    value_loss           | 0.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 5850        |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| total_reward_steps      | 396         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032376304 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 828        |\n",
      "|    time_elapsed         | 5857       |\n",
      "|    total_timesteps      | 1695744    |\n",
      "| total_reward_steps      | 20         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18321252 |\n",
      "|    clip_fraction        | 0.459      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.455     |\n",
      "|    explained_variance   | 0.0174     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 120        |\n",
      "|    n_updates            | 8270       |\n",
      "|    policy_gradient_loss | 0.0803     |\n",
      "|    value_loss           | 60.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 5863        |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| total_reward_steps      | 23          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029699203 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.448      |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | 0.00361     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 5870        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023626678 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0607      |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=20.30 +/- 7.43\n",
      "Episode length: 560.10 +/- 67.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 560         |\n",
      "|    mean_reward          | 20.3        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023969159 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00477     |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 831      |\n",
      "|    time_elapsed    | 5896     |\n",
      "|    total_timesteps | 1701888  |\n",
      "| total_reward_steps | 35       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 5902        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| total_reward_steps      | 30          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026842669 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.543      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0881      |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 5908        |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021650124 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00144     |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 5914        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019901225 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 835         |\n",
      "|    time_elapsed         | 5920        |\n",
      "|    total_timesteps      | 1710080     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024249677 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.574      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 0.402       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 5927        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041965686 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.229       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    value_loss           | 5.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 5934        |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023587545 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0541      |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 838        |\n",
      "|    time_elapsed         | 5941       |\n",
      "|    total_timesteps      | 1716224    |\n",
      "| total_reward_steps      | 37         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03557439 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.601     |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0748     |\n",
      "|    n_updates            | 8370       |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 0.0952     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 839       |\n",
      "|    time_elapsed         | 5947      |\n",
      "|    total_timesteps      | 1718272   |\n",
      "| total_reward_steps      | 42        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0317282 |\n",
      "|    clip_fraction        | 0.394     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.691    |\n",
      "|    explained_variance   | 0.139     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 6.08      |\n",
      "|    n_updates            | 8380      |\n",
      "|    policy_gradient_loss | 0.0148    |\n",
      "|    value_loss           | 6.77      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 840         |\n",
      "|    time_elapsed         | 5954        |\n",
      "|    total_timesteps      | 1720320     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022522267 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 5961        |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027062494 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 5968        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030779723 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.634       |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    value_loss           | 7.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 5975        |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020808969 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0182      |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 5981        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019102504 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 8430        |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 845         |\n",
      "|    time_elapsed         | 5988        |\n",
      "|    total_timesteps      | 1730560     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016651278 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0307      |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 0.314       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 5995        |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022754338 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 6002        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| total_reward_steps      | 130         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025889099 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00483     |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.151       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 289      |\n",
      "|    iterations           | 848      |\n",
      "|    time_elapsed         | 6009     |\n",
      "|    total_timesteps      | 1736704  |\n",
      "| total_reward_steps      | 50       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.100364 |\n",
      "|    clip_fraction        | 0.476    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.671   |\n",
      "|    explained_variance   | 0.0185   |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.861    |\n",
      "|    n_updates            | 8470     |\n",
      "|    policy_gradient_loss | 0.0222   |\n",
      "|    value_loss           | 4.71     |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 6016        |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| total_reward_steps      | 134         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032685272 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.228       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 850       |\n",
      "|    time_elapsed         | 6022      |\n",
      "|    total_timesteps      | 1740800   |\n",
      "| total_reward_steps      | 37        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0384541 |\n",
      "|    clip_fraction        | 0.386     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.65     |\n",
      "|    explained_variance   | 0.0961    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0552    |\n",
      "|    n_updates            | 8490      |\n",
      "|    policy_gradient_loss | 0.0277    |\n",
      "|    value_loss           | 1.79      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 6029        |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027696636 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 8.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 6036        |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027686702 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.754      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00861    |\n",
      "|    n_updates            | 8510        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 6043        |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022751952 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00024     |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 854        |\n",
      "|    time_elapsed         | 6049       |\n",
      "|    total_timesteps      | 1748992    |\n",
      "| total_reward_steps      | 41         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01901152 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.796     |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0477     |\n",
      "|    n_updates            | 8530       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.323      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 855         |\n",
      "|    time_elapsed         | 6056        |\n",
      "|    total_timesteps      | 1751040     |\n",
      "| total_reward_steps      | 236         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022562739 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    value_loss           | 0.483       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 856        |\n",
      "|    time_elapsed         | 6063       |\n",
      "|    total_timesteps      | 1753088    |\n",
      "| total_reward_steps      | 71         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03451944 |\n",
      "|    clip_fraction        | 0.408      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.798     |\n",
      "|    explained_variance   | 0.124      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.064      |\n",
      "|    n_updates            | 8550       |\n",
      "|    policy_gradient_loss | 0.0215     |\n",
      "|    value_loss           | 10.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 6070        |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022007508 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0851      |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 6077        |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016895466 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.847      |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    value_loss           | 0.595       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 859        |\n",
      "|    time_elapsed         | 6083       |\n",
      "|    total_timesteps      | 1759232    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08871704 |\n",
      "|    clip_fraction        | 0.427      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.661     |\n",
      "|    explained_variance   | 0.0848     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.256      |\n",
      "|    n_updates            | 8580       |\n",
      "|    policy_gradient_loss | 0.0305     |\n",
      "|    value_loss           | 39.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 860        |\n",
      "|    time_elapsed         | 6090       |\n",
      "|    total_timesteps      | 1761280    |\n",
      "| total_reward_steps      | 125        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07442527 |\n",
      "|    clip_fraction        | 0.497      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.679     |\n",
      "|    explained_variance   | -0.0454    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0635     |\n",
      "|    n_updates            | 8590       |\n",
      "|    policy_gradient_loss | 0.0358     |\n",
      "|    value_loss           | 8.32       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 6097        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023756497 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.155       |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | 0.00842     |\n",
      "|    value_loss           | 2.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 6104        |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| total_reward_steps      | 222         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024170348 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0715      |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 863        |\n",
      "|    time_elapsed         | 6111       |\n",
      "|    total_timesteps      | 1767424    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03162813 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.642     |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.77       |\n",
      "|    n_updates            | 8620       |\n",
      "|    policy_gradient_loss | 0.0253     |\n",
      "|    value_loss           | 7.63       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 864        |\n",
      "|    time_elapsed         | 6118       |\n",
      "|    total_timesteps      | 1769472    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02121594 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0266     |\n",
      "|    n_updates            | 8630       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    value_loss           | 0.207      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 865         |\n",
      "|    time_elapsed         | 6124        |\n",
      "|    total_timesteps      | 1771520     |\n",
      "| total_reward_steps      | 224         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017042711 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.283       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 6131        |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024181781 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07        |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    value_loss           | 3.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 6137        |\n",
      "|    total_timesteps      | 1775616     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026744608 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00592    |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 0.454       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 6144        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021312421 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00944    |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 6150        |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022115529 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00988     |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 870         |\n",
      "|    time_elapsed         | 6156        |\n",
      "|    total_timesteps      | 1781760     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019139152 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 8690        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 289          |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 6163         |\n",
      "|    total_timesteps      | 1783808      |\n",
      "| total_reward_steps      | 82           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150411315 |\n",
      "|    clip_fraction        | 0.314        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.743       |\n",
      "|    explained_variance   | 0.867        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0754       |\n",
      "|    n_updates            | 8700         |\n",
      "|    policy_gradient_loss | -0.0162      |\n",
      "|    value_loss           | 0.105        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 6170        |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016558625 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.295       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 873        |\n",
      "|    time_elapsed         | 6176       |\n",
      "|    total_timesteps      | 1787904    |\n",
      "| total_reward_steps      | 214        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01522423 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.76      |\n",
      "|    explained_variance   | 0.632      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.102      |\n",
      "|    n_updates            | 8720       |\n",
      "|    policy_gradient_loss | -0.00957   |\n",
      "|    value_loss           | 0.683      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 6183        |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022374593 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.79        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | 0.00905     |\n",
      "|    value_loss           | 5.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 875        |\n",
      "|    time_elapsed         | 6190       |\n",
      "|    total_timesteps      | 1792000    |\n",
      "| total_reward_steps      | 31         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01475006 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.75      |\n",
      "|    explained_variance   | 0.687      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0727     |\n",
      "|    n_updates            | 8740       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.37       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 6197        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030089015 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0475      |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    value_loss           | 0.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 877         |\n",
      "|    time_elapsed         | 6204        |\n",
      "|    total_timesteps      | 1796096     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020317547 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | -0.000268   |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 6210        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017968128 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0154     |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=86.73 +/- 34.04\n",
      "Episode length: 1014.83 +/- 130.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | 86.7         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1800000      |\n",
      "| total_reward_steps      | 86           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148352375 |\n",
      "|    clip_fraction        | 0.308        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.715       |\n",
      "|    explained_variance   | 0.735        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0803       |\n",
      "|    n_updates            | 8780         |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 0.396        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 287      |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 6255     |\n",
      "|    total_timesteps | 1800192  |\n",
      "| total_reward_steps | 77       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 6262        |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| total_reward_steps      | 138         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017847948 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 8790        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 881        |\n",
      "|    time_elapsed         | 6268       |\n",
      "|    total_timesteps      | 1804288    |\n",
      "| total_reward_steps      | 91         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04830776 |\n",
      "|    clip_fraction        | 0.485      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.827     |\n",
      "|    explained_variance   | -0.235     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 8800       |\n",
      "|    policy_gradient_loss | 0.0263     |\n",
      "|    value_loss           | 1.12       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 6275        |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| total_reward_steps      | 141         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018923875 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.873      |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0263      |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 6282        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024609864 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    value_loss           | 0.571       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 884         |\n",
      "|    time_elapsed         | 6289        |\n",
      "|    total_timesteps      | 1810432     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016235292 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.089       |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 6295        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017668897 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0183     |\n",
      "|    n_updates            | 8840        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 6302        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018351456 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00849    |\n",
      "|    n_updates            | 8850        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 6309        |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| total_reward_steps      | 159         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030547768 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | 0.0054      |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 6316        |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| total_reward_steps      | 139         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022917837 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | 0.000258    |\n",
      "|    value_loss           | 2.11        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 889        |\n",
      "|    time_elapsed         | 6322       |\n",
      "|    total_timesteps      | 1820672    |\n",
      "| total_reward_steps      | 118        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01511133 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.64      |\n",
      "|    explained_variance   | 0.457      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.311      |\n",
      "|    n_updates            | 8880       |\n",
      "|    policy_gradient_loss | -0.00553   |\n",
      "|    value_loss           | 0.572      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 890        |\n",
      "|    time_elapsed         | 6329       |\n",
      "|    total_timesteps      | 1822720    |\n",
      "| total_reward_steps      | 112        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05230922 |\n",
      "|    clip_fraction        | 0.427      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.0175     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.185      |\n",
      "|    n_updates            | 8890       |\n",
      "|    policy_gradient_loss | 0.0209     |\n",
      "|    value_loss           | 45.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 891        |\n",
      "|    time_elapsed         | 6336       |\n",
      "|    total_timesteps      | 1824768    |\n",
      "| total_reward_steps      | 179        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02615938 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.653     |\n",
      "|    explained_variance   | 0.547      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 35.2       |\n",
      "|    n_updates            | 8900       |\n",
      "|    policy_gradient_loss | 0.00604    |\n",
      "|    value_loss           | 7.62       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 6343        |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| total_reward_steps      | 173         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039772484 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | 0.00451     |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 6350        |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| total_reward_steps      | 179         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020595955 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.96        |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | 0.0192      |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 894        |\n",
      "|    time_elapsed         | 6356       |\n",
      "|    total_timesteps      | 1830912    |\n",
      "| total_reward_steps      | 40         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08115923 |\n",
      "|    clip_fraction        | 0.504      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.772     |\n",
      "|    explained_variance   | 0.157      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.203      |\n",
      "|    n_updates            | 8930       |\n",
      "|    policy_gradient_loss | 0.0498     |\n",
      "|    value_loss           | 32.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 895         |\n",
      "|    time_elapsed         | 6363        |\n",
      "|    total_timesteps      | 1832960     |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037765693 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00022     |\n",
      "|    n_updates            | 8940        |\n",
      "|    policy_gradient_loss | 0.000326    |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 896        |\n",
      "|    time_elapsed         | 6370       |\n",
      "|    total_timesteps      | 1835008    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02413851 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.71      |\n",
      "|    explained_variance   | 0.273      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00816   |\n",
      "|    n_updates            | 8950       |\n",
      "|    policy_gradient_loss | -0.00913   |\n",
      "|    value_loss           | 0.349      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 897       |\n",
      "|    time_elapsed         | 6376      |\n",
      "|    total_timesteps      | 1837056   |\n",
      "| total_reward_steps      | 107       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0198025 |\n",
      "|    clip_fraction        | 0.368     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.733    |\n",
      "|    explained_variance   | 0.688     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.085     |\n",
      "|    n_updates            | 8960      |\n",
      "|    policy_gradient_loss | -0.0108   |\n",
      "|    value_loss           | 0.286     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 6383        |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016127046 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.174       |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    value_loss           | 0.705       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 899         |\n",
      "|    time_elapsed         | 6389        |\n",
      "|    total_timesteps      | 1841152     |\n",
      "| total_reward_steps      | 247         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015242076 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 8980        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 0.366       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 900        |\n",
      "|    time_elapsed         | 6395       |\n",
      "|    total_timesteps      | 1843200    |\n",
      "| total_reward_steps      | 89         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04470396 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.753     |\n",
      "|    explained_variance   | 0.112      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.74       |\n",
      "|    n_updates            | 8990       |\n",
      "|    policy_gradient_loss | 0.046      |\n",
      "|    value_loss           | 9.94       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 6402        |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| total_reward_steps      | 335         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028144747 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.188       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 6408        |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039200004 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56        |\n",
      "|    n_updates            | 9010        |\n",
      "|    policy_gradient_loss | 0.0372      |\n",
      "|    value_loss           | 20.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 6415        |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024635777 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.136       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    value_loss           | 2.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 904         |\n",
      "|    time_elapsed         | 6422        |\n",
      "|    total_timesteps      | 1851392     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028195217 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 6429        |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025759827 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 6435        |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017848458 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 907        |\n",
      "|    time_elapsed         | 6442       |\n",
      "|    total_timesteps      | 1857536    |\n",
      "| total_reward_steps      | 213        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01208806 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.1        |\n",
      "|    n_updates            | 9060       |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    value_loss           | 0.328      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 6449        |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025336394 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68        |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    value_loss           | 5.99        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 909         |\n",
      "|    time_elapsed         | 6456        |\n",
      "|    total_timesteps      | 1861632     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015201841 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00819     |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 6462        |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015272484 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00371     |\n",
      "|    n_updates            | 9090        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 6469        |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019802175 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -3.43e-05   |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.0942      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 6476        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020570703 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.818      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    value_loss           | 0.658       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 6483        |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| total_reward_steps      | 130         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018504083 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    value_loss           | 0.584       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 914         |\n",
      "|    time_elapsed         | 6489        |\n",
      "|    total_timesteps      | 1871872     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015026807 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 9130        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.623       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 6496        |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013385921 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 6503        |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022365361 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.0815      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    value_loss           | 6.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 917         |\n",
      "|    time_elapsed         | 6510        |\n",
      "|    total_timesteps      | 1878016     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023030508 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0096      |\n",
      "|    n_updates            | 9160        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 918        |\n",
      "|    time_elapsed         | 6517       |\n",
      "|    total_timesteps      | 1880064    |\n",
      "| total_reward_steps      | 145        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02218503 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.808     |\n",
      "|    explained_variance   | -0.816     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.25       |\n",
      "|    n_updates            | 9170       |\n",
      "|    policy_gradient_loss | -0.00266   |\n",
      "|    value_loss           | 1.89       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 919        |\n",
      "|    time_elapsed         | 6523       |\n",
      "|    total_timesteps      | 1882112    |\n",
      "| total_reward_steps      | 151        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02113822 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.709     |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.155      |\n",
      "|    n_updates            | 9180       |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    value_loss           | 0.466      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 6530        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| total_reward_steps      | 190         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017736081 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 6537        |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| total_reward_steps      | 236         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017344382 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 2.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 6544        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026268478 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    value_loss           | 6.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 923         |\n",
      "|    time_elapsed         | 6550        |\n",
      "|    total_timesteps      | 1890304     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024474869 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.028       |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | 0.00474     |\n",
      "|    value_loss           | 3.88        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 924        |\n",
      "|    time_elapsed         | 6557       |\n",
      "|    total_timesteps      | 1892352    |\n",
      "| total_reward_steps      | 87         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01578189 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.732     |\n",
      "|    explained_variance   | 0.739      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.191      |\n",
      "|    n_updates            | 9230       |\n",
      "|    policy_gradient_loss | -0.00328   |\n",
      "|    value_loss           | 0.348      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 6564        |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| total_reward_steps      | 143         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017270086 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 6571        |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021214288 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    value_loss           | 0.478       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 6577        |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| total_reward_steps      | 143         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022489663 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.126       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | 0.00698     |\n",
      "|    value_loss           | 6.65        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=107.63 +/- 18.66\n",
      "Episode length: 1048.47 +/- 131.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.05e+03     |\n",
      "|    mean_reward          | 108          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1900000      |\n",
      "| total_reward_steps      | 104          |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151343215 |\n",
      "|    clip_fraction        | 0.328        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0584       |\n",
      "|    n_updates            | 9270         |\n",
      "|    policy_gradient_loss | -0.0121      |\n",
      "|    value_loss           | 0.348        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 286      |\n",
      "|    iterations      | 928      |\n",
      "|    time_elapsed    | 6622     |\n",
      "|    total_timesteps | 1900544  |\n",
      "| total_reward_steps | 128      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 6629        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012445107 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.209       |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 6635        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013390045 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00384     |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.306       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 6641        |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| total_reward_steps      | 419         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014644996 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00734     |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 932        |\n",
      "|    time_elapsed         | 6648       |\n",
      "|    total_timesteps      | 1908736    |\n",
      "| total_reward_steps      | 106        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07354029 |\n",
      "|    clip_fraction        | 0.521      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.837     |\n",
      "|    explained_variance   | 0.0441     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 8.21       |\n",
      "|    n_updates            | 9310       |\n",
      "|    policy_gradient_loss | 0.0342     |\n",
      "|    value_loss           | 60.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 933        |\n",
      "|    time_elapsed         | 6654       |\n",
      "|    total_timesteps      | 1910784    |\n",
      "| total_reward_steps      | 98         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02759118 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.485     |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 9320       |\n",
      "|    policy_gradient_loss | 0.0019     |\n",
      "|    value_loss           | 0.766      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 6660        |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| total_reward_steps      | 127         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025903355 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.622      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 9330        |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 6666        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021141516 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0673      |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -7.41e-05   |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 6672        |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| total_reward_steps      | 208         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029698804 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 7.05        |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | 0.00856     |\n",
      "|    value_loss           | 6.6         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 937        |\n",
      "|    time_elapsed         | 6679       |\n",
      "|    total_timesteps      | 1918976    |\n",
      "| total_reward_steps      | 41         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03087966 |\n",
      "|    clip_fraction        | 0.384      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.727     |\n",
      "|    explained_variance   | 0.474      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.279      |\n",
      "|    n_updates            | 9360       |\n",
      "|    policy_gradient_loss | 0.00719    |\n",
      "|    value_loss           | 1.96       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 938         |\n",
      "|    time_elapsed         | 6686        |\n",
      "|    total_timesteps      | 1921024     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025210097 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 6693        |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017614327 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0413      |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 6699        |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015212664 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.229       |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 6706        |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033540826 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.585       |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 6713        |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| total_reward_steps      | 220         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017413009 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00304     |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 943         |\n",
      "|    time_elapsed         | 6720        |\n",
      "|    total_timesteps      | 1931264     |\n",
      "| total_reward_steps      | 396         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023234107 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0971      |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | 0.00934     |\n",
      "|    value_loss           | 4.17        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 944       |\n",
      "|    time_elapsed         | 6726      |\n",
      "|    total_timesteps      | 1933312   |\n",
      "| total_reward_steps      | 114       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0465206 |\n",
      "|    clip_fraction        | 0.394     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.585    |\n",
      "|    explained_variance   | 0.0106    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.278     |\n",
      "|    n_updates            | 9430      |\n",
      "|    policy_gradient_loss | 0.0229    |\n",
      "|    value_loss           | 37.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 945         |\n",
      "|    time_elapsed         | 6733        |\n",
      "|    total_timesteps      | 1935360     |\n",
      "| total_reward_steps      | 162         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025440965 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    value_loss           | 0.578       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 6740        |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026987318 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.75        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 6747        |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021521054 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.601      |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0636      |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 0.337       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 287          |\n",
      "|    iterations           | 948          |\n",
      "|    time_elapsed         | 6754         |\n",
      "|    total_timesteps      | 1941504      |\n",
      "| total_reward_steps      | 34           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154281445 |\n",
      "|    clip_fraction        | 0.353        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.77        |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.368        |\n",
      "|    n_updates            | 9470         |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 0.176        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 949        |\n",
      "|    time_elapsed         | 6760       |\n",
      "|    total_timesteps      | 1943552    |\n",
      "| total_reward_steps      | 99         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02507767 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.666     |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0307     |\n",
      "|    n_updates            | 9480       |\n",
      "|    policy_gradient_loss | -0.00884   |\n",
      "|    value_loss           | 0.524      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 6767        |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013385279 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0775      |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 0.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 6774        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| total_reward_steps      | 171         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022660352 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0181      |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 6781        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| total_reward_steps      | 260         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016362526 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00705     |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | 0.000864    |\n",
      "|    value_loss           | 0.916       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 953         |\n",
      "|    time_elapsed         | 6788        |\n",
      "|    total_timesteps      | 1951744     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021045145 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    value_loss           | 6.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 6794        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018163718 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.647      |\n",
      "|    explained_variance   | -0.191      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 0.643       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 955        |\n",
      "|    time_elapsed         | 6801       |\n",
      "|    total_timesteps      | 1955840    |\n",
      "| total_reward_steps      | 123        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02364325 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.651     |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0285     |\n",
      "|    n_updates            | 9540       |\n",
      "|    policy_gradient_loss | -0.0083    |\n",
      "|    value_loss           | 0.359      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 956        |\n",
      "|    time_elapsed         | 6808       |\n",
      "|    total_timesteps      | 1957888    |\n",
      "| total_reward_steps      | 113        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02451489 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.614     |\n",
      "|    explained_variance   | 0.67       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0265     |\n",
      "|    n_updates            | 9550       |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 0.467      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 6815       |\n",
      "|    total_timesteps      | 1959936    |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01902804 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.736     |\n",
      "|    explained_variance   | 0.728      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.084      |\n",
      "|    n_updates            | 9560       |\n",
      "|    policy_gradient_loss | -0.00181   |\n",
      "|    value_loss           | 1.8        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 958         |\n",
      "|    time_elapsed         | 6821        |\n",
      "|    total_timesteps      | 1961984     |\n",
      "| total_reward_steps      | 224         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014901444 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.071       |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.000975   |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 959        |\n",
      "|    time_elapsed         | 6828       |\n",
      "|    total_timesteps      | 1964032    |\n",
      "| total_reward_steps      | 168        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08023943 |\n",
      "|    clip_fraction        | 0.527      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.69      |\n",
      "|    explained_variance   | 0.0307     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 21.2       |\n",
      "|    n_updates            | 9580       |\n",
      "|    policy_gradient_loss | 0.0578     |\n",
      "|    value_loss           | 39.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 960        |\n",
      "|    time_elapsed         | 6835       |\n",
      "|    total_timesteps      | 1966080    |\n",
      "| total_reward_steps      | 108        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01799881 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.583     |\n",
      "|    explained_variance   | 0.615      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.14       |\n",
      "|    n_updates            | 9590       |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    value_loss           | 1.42       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 6842        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| total_reward_steps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042730294 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | 0.0213      |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 962         |\n",
      "|    time_elapsed         | 6849        |\n",
      "|    total_timesteps      | 1970176     |\n",
      "| total_reward_steps      | 16          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056207553 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0208      |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 6856        |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028205894 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 6862        |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| total_reward_steps      | 413         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029782752 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0507      |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 0.368       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 6869        |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052450128 |\n",
      "|    clip_fraction        | 0.572       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.428       |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | 0.0593      |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 6876        |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038681045 |\n",
      "|    clip_fraction        | 0.452       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.0795      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0998      |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | 0.000382    |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 967         |\n",
      "|    time_elapsed         | 6883        |\n",
      "|    total_timesteps      | 1980416     |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035069108 |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.807      |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    value_loss           | 7.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 6889        |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| total_reward_steps      | 191         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026515812 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.221       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 6895        |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024698045 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.72        |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | 0.0069      |\n",
      "|    value_loss           | 5.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 6902        |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| total_reward_steps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017297156 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.221       |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 6908        |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030046154 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    value_loss           | 7.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 972         |\n",
      "|    time_elapsed         | 6914        |\n",
      "|    total_timesteps      | 1990656     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020807099 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.146       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.255       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 6921        |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| total_reward_steps      | 178         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012739461 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.788      |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00882    |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 6927        |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015316037 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 975         |\n",
      "|    time_elapsed         | 6934        |\n",
      "|    total_timesteps      | 1996800     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019046681 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0173      |\n",
      "|    n_updates            | 9740        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.407       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 6940        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015631609 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00331     |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=99.90 +/- 9.06\n",
      "Episode length: 1206.30 +/- 43.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | 99.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2000000     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019546445 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0145      |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 286      |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 6988     |\n",
      "|    total_timesteps | 2000896  |\n",
      "| total_reward_steps | 101      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 6995        |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013864991 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.00994    |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 7001        |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| total_reward_steps      | 16          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035609335 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.02        |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | 0.00657     |\n",
      "|    value_loss           | 2.74        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 980        |\n",
      "|    time_elapsed         | 7007       |\n",
      "|    total_timesteps      | 2007040    |\n",
      "| total_reward_steps      | 158        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06563287 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.478     |\n",
      "|    explained_variance   | 0.278      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.596      |\n",
      "|    n_updates            | 9790       |\n",
      "|    policy_gradient_loss | -0.00504   |\n",
      "|    value_loss           | 0.353      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 981        |\n",
      "|    time_elapsed         | 7014       |\n",
      "|    total_timesteps      | 2009088    |\n",
      "| total_reward_steps      | 96         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02310833 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.93      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0736     |\n",
      "|    n_updates            | 9800       |\n",
      "|    policy_gradient_loss | 0.00848    |\n",
      "|    value_loss           | 1.51       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 982         |\n",
      "|    time_elapsed         | 7020        |\n",
      "|    total_timesteps      | 2011136     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021915033 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00101     |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 7027        |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043991912 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00574    |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 7033        |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| total_reward_steps      | 247         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020934839 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.422       |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 985        |\n",
      "|    time_elapsed         | 7039       |\n",
      "|    total_timesteps      | 2017280    |\n",
      "| total_reward_steps      | 241        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06648638 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.782     |\n",
      "|    explained_variance   | 0.0132     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.16       |\n",
      "|    n_updates            | 9840       |\n",
      "|    policy_gradient_loss | 0.024      |\n",
      "|    value_loss           | 4.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 7046        |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024244558 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.479       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | 0.00944     |\n",
      "|    value_loss           | 6.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 987        |\n",
      "|    time_elapsed         | 7052       |\n",
      "|    total_timesteps      | 2021376    |\n",
      "| total_reward_steps      | 135        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02800481 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.85      |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0718     |\n",
      "|    n_updates            | 9860       |\n",
      "|    policy_gradient_loss | 0.00707    |\n",
      "|    value_loss           | 2.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 7059        |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| total_reward_steps      | 396         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023245089 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 7065        |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| total_reward_steps      | 155         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082880974 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.0821      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.95        |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | 0.0876      |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 286       |\n",
      "|    iterations           | 990       |\n",
      "|    time_elapsed         | 7071      |\n",
      "|    total_timesteps      | 2027520   |\n",
      "| total_reward_steps      | 397       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0500154 |\n",
      "|    clip_fraction        | 0.402     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.766    |\n",
      "|    explained_variance   | 0.159     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 1.05      |\n",
      "|    n_updates            | 9890      |\n",
      "|    policy_gradient_loss | 0.0238    |\n",
      "|    value_loss           | 7.8       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 7078        |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| total_reward_steps      | 187         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020473842 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 33.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 992         |\n",
      "|    time_elapsed         | 7084        |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| total_reward_steps      | 178         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025579657 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0568      |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 7091        |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| total_reward_steps      | 133         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024348535 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    value_loss           | 2.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 7097        |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| total_reward_steps      | 178         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039827134 |\n",
      "|    clip_fraction        | 0.411       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 7103        |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023235943 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | 0.00655     |\n",
      "|    value_loss           | 2.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 7110        |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| total_reward_steps      | 14          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017241782 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.019      |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.277       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 286       |\n",
      "|    iterations           | 997       |\n",
      "|    time_elapsed         | 7116      |\n",
      "|    total_timesteps      | 2041856   |\n",
      "| total_reward_steps      | 116       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0348011 |\n",
      "|    clip_fraction        | 0.358     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.748    |\n",
      "|    explained_variance   | 0.785     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0922    |\n",
      "|    n_updates            | 9960      |\n",
      "|    policy_gradient_loss | -0.0141   |\n",
      "|    value_loss           | 0.267     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 7123        |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| total_reward_steps      | 240         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030696929 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00739     |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 0.433       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 7129        |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| total_reward_steps      | 180         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028419254 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.0716      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | 0.00327     |\n",
      "|    value_loss           | 8.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 7135        |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| total_reward_steps      | 135         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017154368 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0737      |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1001        |\n",
      "|    time_elapsed         | 7142        |\n",
      "|    total_timesteps      | 2050048     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024111398 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0954      |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 0.609       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1002       |\n",
      "|    time_elapsed         | 7147       |\n",
      "|    total_timesteps      | 2052096    |\n",
      "| total_reward_steps      | 177        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02119049 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.677     |\n",
      "|    explained_variance   | 0.648      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0304     |\n",
      "|    n_updates            | 10010      |\n",
      "|    policy_gradient_loss | -0.00118   |\n",
      "|    value_loss           | 1.45       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1003       |\n",
      "|    time_elapsed         | 7153       |\n",
      "|    total_timesteps      | 2054144    |\n",
      "| total_reward_steps      | 176        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01713781 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.707     |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.84       |\n",
      "|    n_updates            | 10020      |\n",
      "|    policy_gradient_loss | 0.00347    |\n",
      "|    value_loss           | 1.43       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 7160        |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017104784 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48        |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 7166        |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| total_reward_steps      | 183         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014984673 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1006        |\n",
      "|    time_elapsed         | 7173        |\n",
      "|    total_timesteps      | 2060288     |\n",
      "| total_reward_steps      | 181         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018437041 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.626       |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | 0.00644     |\n",
      "|    value_loss           | 2.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 7180        |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| total_reward_steps      | 196         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018782265 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0861      |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    value_loss           | 3.13        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1008       |\n",
      "|    time_elapsed         | 7186       |\n",
      "|    total_timesteps      | 2064384    |\n",
      "| total_reward_steps      | 112        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01646987 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.684     |\n",
      "|    explained_variance   | 0.582      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.762      |\n",
      "|    n_updates            | 10070      |\n",
      "|    policy_gradient_loss | -0.00137   |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1009       |\n",
      "|    time_elapsed         | 7193       |\n",
      "|    total_timesteps      | 2066432    |\n",
      "| total_reward_steps      | 180        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03132158 |\n",
      "|    clip_fraction        | 0.354      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0367     |\n",
      "|    n_updates            | 10080      |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    value_loss           | 0.454      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 7200        |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| total_reward_steps      | 269         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015741546 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1011        |\n",
      "|    time_elapsed         | 7207        |\n",
      "|    total_timesteps      | 2070528     |\n",
      "| total_reward_steps      | 251         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039317027 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.0499      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    value_loss           | 8.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 7213        |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039232153 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | 0.0173      |\n",
      "|    value_loss           | 9.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 7220        |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| total_reward_steps      | 259         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024355607 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 10120       |\n",
      "|    policy_gradient_loss | -0.000315   |\n",
      "|    value_loss           | 0.498       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 7227        |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| total_reward_steps      | 418         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015604425 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.48        |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | 0.00397     |\n",
      "|    value_loss           | 5.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 7234        |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.107003346 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.718       |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | 0.0624      |\n",
      "|    value_loss           | 38.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1016       |\n",
      "|    time_elapsed         | 7240       |\n",
      "|    total_timesteps      | 2080768    |\n",
      "| total_reward_steps      | 136        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02681854 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.695     |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0649     |\n",
      "|    n_updates            | 10150      |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.355      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 7247        |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| total_reward_steps      | 178         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016807789 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    value_loss           | 0.76        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 1018       |\n",
      "|    time_elapsed         | 7254       |\n",
      "|    total_timesteps      | 2084864    |\n",
      "| total_reward_steps      | 109        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01844851 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.778     |\n",
      "|    explained_variance   | 0.324      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.157      |\n",
      "|    n_updates            | 10170      |\n",
      "|    policy_gradient_loss | 0.00484    |\n",
      "|    value_loss           | 1.84       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 7261        |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| total_reward_steps      | 186         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036608897 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05        |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | 0.0262      |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 7268        |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| total_reward_steps      | 185         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022238364 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1021        |\n",
      "|    time_elapsed         | 7274        |\n",
      "|    total_timesteps      | 2091008     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015634798 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0381      |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.00857    |\n",
      "|    value_loss           | 0.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 7281        |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| total_reward_steps      | 411         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016961291 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.307       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 7288        |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| total_reward_steps      | 258         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070545614 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.0775      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | 0.0582      |\n",
      "|    value_loss           | 46.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 1024      |\n",
      "|    time_elapsed         | 7295      |\n",
      "|    total_timesteps      | 2097152   |\n",
      "| total_reward_steps      | 120       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0267204 |\n",
      "|    clip_fraction        | 0.322     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.687    |\n",
      "|    explained_variance   | 0.507     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.09      |\n",
      "|    n_updates            | 10230     |\n",
      "|    policy_gradient_loss | 0.014     |\n",
      "|    value_loss           | 4.29      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 7302        |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034678165 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | -0.686      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 10240       |\n",
      "|    policy_gradient_loss | 0.00934     |\n",
      "|    value_loss           | 0.878       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=227.60 +/- 87.95\n",
      "Episode length: 1156.63 +/- 149.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | 228         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024599446 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0483      |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1026     |\n",
      "|    time_elapsed    | 7351     |\n",
      "|    total_timesteps | 2101248  |\n",
      "| total_reward_steps | 134      |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1027       |\n",
      "|    time_elapsed         | 7358       |\n",
      "|    total_timesteps      | 2103296    |\n",
      "| total_reward_steps      | 259        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03359977 |\n",
      "|    clip_fraction        | 0.415      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.802     |\n",
      "|    explained_variance   | 0.171      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.798      |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | 0.0201     |\n",
      "|    value_loss           | 8.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1028        |\n",
      "|    time_elapsed         | 7364        |\n",
      "|    total_timesteps      | 2105344     |\n",
      "| total_reward_steps      | 194         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026392572 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.494       |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 6.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 7371        |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014441138 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.14        |\n",
      "|    n_updates            | 10280       |\n",
      "|    policy_gradient_loss | 0.00246     |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 7377        |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| total_reward_steps      | 152         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018253393 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0616      |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1031       |\n",
      "|    time_elapsed         | 7384       |\n",
      "|    total_timesteps      | 2111488    |\n",
      "| total_reward_steps      | 106        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13477774 |\n",
      "|    clip_fraction        | 0.591      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.833     |\n",
      "|    explained_variance   | 0.0396     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 10.4       |\n",
      "|    n_updates            | 10300      |\n",
      "|    policy_gradient_loss | 0.0596     |\n",
      "|    value_loss           | 48.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 7390        |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021999406 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0642      |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 0.329       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 7396        |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025968488 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0474      |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 7403        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| total_reward_steps      | 144         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023012709 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0889      |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 7410        |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021379791 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00698     |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 0.544       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1036        |\n",
      "|    time_elapsed         | 7416        |\n",
      "|    total_timesteps      | 2121728     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017889913 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.81       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0174      |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    value_loss           | 0.275       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 7423        |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012897123 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.767      |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0816      |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 7430        |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| total_reward_steps      | 148         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012468757 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0478      |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.217       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1039       |\n",
      "|    time_elapsed         | 7437       |\n",
      "|    total_timesteps      | 2127872    |\n",
      "| total_reward_steps      | 126        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02049788 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.781     |\n",
      "|    explained_variance   | 0.515      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0414     |\n",
      "|    n_updates            | 10380      |\n",
      "|    policy_gradient_loss | 0.00128    |\n",
      "|    value_loss           | 1.82       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 7444        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014251076 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00134    |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 286      |\n",
      "|    iterations           | 1041     |\n",
      "|    time_elapsed         | 7450     |\n",
      "|    total_timesteps      | 2131968  |\n",
      "| total_reward_steps      | 124      |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.017118 |\n",
      "|    clip_fraction        | 0.347    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.913   |\n",
      "|    explained_variance   | 0.9      |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.0656   |\n",
      "|    n_updates            | 10400    |\n",
      "|    policy_gradient_loss | -0.0142  |\n",
      "|    value_loss           | 0.171    |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1042       |\n",
      "|    time_elapsed         | 7457       |\n",
      "|    total_timesteps      | 2134016    |\n",
      "| total_reward_steps      | 103        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01267289 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.739     |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0341    |\n",
      "|    n_updates            | 10410      |\n",
      "|    policy_gradient_loss | -0.0198    |\n",
      "|    value_loss           | 0.115      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1043       |\n",
      "|    time_elapsed         | 7464       |\n",
      "|    total_timesteps      | 2136064    |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01335135 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.759     |\n",
      "|    explained_variance   | 0.888      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0117    |\n",
      "|    n_updates            | 10420      |\n",
      "|    policy_gradient_loss | -0.0158    |\n",
      "|    value_loss           | 0.289      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 7470        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014715164 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.791      |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1045       |\n",
      "|    time_elapsed         | 7477       |\n",
      "|    total_timesteps      | 2140160    |\n",
      "| total_reward_steps      | 114        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01609924 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0907     |\n",
      "|    n_updates            | 10440      |\n",
      "|    policy_gradient_loss | -0.00875   |\n",
      "|    value_loss           | 0.394      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 7484        |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014386693 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 0.355       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1047       |\n",
      "|    time_elapsed         | 7491       |\n",
      "|    total_timesteps      | 2144256    |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02819714 |\n",
      "|    clip_fraction        | 0.414      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.978     |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 52.2       |\n",
      "|    n_updates            | 10460      |\n",
      "|    policy_gradient_loss | 0.0257     |\n",
      "|    value_loss           | 6.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 7498        |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014354663 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 7504        |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020939788 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0043     |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1050        |\n",
      "|    time_elapsed         | 7511        |\n",
      "|    total_timesteps      | 2150400     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016264211 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.0842      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 7518        |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018482193 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0324      |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 7525        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| total_reward_steps      | 136         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019809313 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.036       |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.62        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1053       |\n",
      "|    time_elapsed         | 7531       |\n",
      "|    total_timesteps      | 2156544    |\n",
      "| total_reward_steps      | 142        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02250403 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.836     |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0356     |\n",
      "|    n_updates            | 10520      |\n",
      "|    policy_gradient_loss | -0.00934   |\n",
      "|    value_loss           | 0.46       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1054       |\n",
      "|    time_elapsed         | 7538       |\n",
      "|    total_timesteps      | 2158592    |\n",
      "| total_reward_steps      | 172        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287269 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0133    |\n",
      "|    n_updates            | 10530      |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 0.244      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1055        |\n",
      "|    time_elapsed         | 7545        |\n",
      "|    total_timesteps      | 2160640     |\n",
      "| total_reward_steps      | 143         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020584268 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.76        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    value_loss           | 3.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1056        |\n",
      "|    time_elapsed         | 7552        |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021583864 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0435      |\n",
      "|    n_updates            | 10550       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.607       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1057       |\n",
      "|    time_elapsed         | 7559       |\n",
      "|    total_timesteps      | 2164736    |\n",
      "| total_reward_steps      | 23         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01934428 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.858     |\n",
      "|    explained_variance   | 0.703      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.177      |\n",
      "|    n_updates            | 10560      |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    value_loss           | 0.312      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 7565        |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| total_reward_steps      | 23          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049294036 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | 0.00988     |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 7572        |\n",
      "|    total_timesteps      | 2168832     |\n",
      "| total_reward_steps      | 128         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019598722 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 10580       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1060        |\n",
      "|    time_elapsed         | 7579        |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| total_reward_steps      | 164         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018739523 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0167      |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    value_loss           | 0.499       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 7586        |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029785445 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 10600       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1062       |\n",
      "|    time_elapsed         | 7592       |\n",
      "|    total_timesteps      | 2174976    |\n",
      "| total_reward_steps      | 120        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03453787 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.812     |\n",
      "|    explained_variance   | 0.831      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0321     |\n",
      "|    n_updates            | 10610      |\n",
      "|    policy_gradient_loss | -0.00849   |\n",
      "|    value_loss           | 0.409      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 7599        |\n",
      "|    total_timesteps      | 2177024     |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014368425 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 0.479       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 7606        |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| total_reward_steps      | 149         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014745655 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1065        |\n",
      "|    time_elapsed         | 7613        |\n",
      "|    total_timesteps      | 2181120     |\n",
      "| total_reward_steps      | 189         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017161788 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.349       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1066        |\n",
      "|    time_elapsed         | 7619        |\n",
      "|    total_timesteps      | 2183168     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022389498 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00778    |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 2.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1067        |\n",
      "|    time_elapsed         | 7626        |\n",
      "|    total_timesteps      | 2185216     |\n",
      "| total_reward_steps      | 143         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016876774 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0257     |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1068       |\n",
      "|    time_elapsed         | 7632       |\n",
      "|    total_timesteps      | 2187264    |\n",
      "| total_reward_steps      | 144        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01647554 |\n",
      "|    clip_fraction        | 0.382      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.903     |\n",
      "|    explained_variance   | 0.741      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00604   |\n",
      "|    n_updates            | 10670      |\n",
      "|    policy_gradient_loss | -0.00474   |\n",
      "|    value_loss           | 0.696      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 7638        |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| total_reward_steps      | 22          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017402466 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 10680       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1070       |\n",
      "|    time_elapsed         | 7645       |\n",
      "|    total_timesteps      | 2191360    |\n",
      "| total_reward_steps      | 158        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02242907 |\n",
      "|    clip_fraction        | 0.351      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.708     |\n",
      "|    explained_variance   | 0.618      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0014     |\n",
      "|    n_updates            | 10690      |\n",
      "|    policy_gradient_loss | -0.00558   |\n",
      "|    value_loss           | 0.916      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 7651        |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026120808 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | -0.139      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 10700       |\n",
      "|    policy_gradient_loss | 0.00929     |\n",
      "|    value_loss           | 0.609       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 1072       |\n",
      "|    time_elapsed         | 7658       |\n",
      "|    total_timesteps      | 2195456    |\n",
      "| total_reward_steps      | 116        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03344763 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.71      |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0607     |\n",
      "|    n_updates            | 10710      |\n",
      "|    policy_gradient_loss | -0.00951   |\n",
      "|    value_loss           | 0.462      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 7665        |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023119915 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.166       |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 7672        |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019101756 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0166      |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.00886    |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=111.83 +/- 50.22\n",
      "Episode length: 1118.67 +/- 206.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.12e+03    |\n",
      "|    mean_reward          | 112         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017448869 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00165    |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 285      |\n",
      "|    iterations      | 1075     |\n",
      "|    time_elapsed    | 7720     |\n",
      "|    total_timesteps | 2201600  |\n",
      "| total_reward_steps | 144      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 7726        |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019282266 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 10750       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 285       |\n",
      "|    iterations           | 1077      |\n",
      "|    time_elapsed         | 7733      |\n",
      "|    total_timesteps      | 2205696   |\n",
      "| total_reward_steps      | 17        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318468 |\n",
      "|    clip_fraction        | 0.386     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.722    |\n",
      "|    explained_variance   | 0.577     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | -0.0173   |\n",
      "|    n_updates            | 10760     |\n",
      "|    policy_gradient_loss | -0.0138   |\n",
      "|    value_loss           | 0.105     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 7740        |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| total_reward_steps      | 27          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024828963 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 10770       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 7747        |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016454047 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0337      |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1080        |\n",
      "|    time_elapsed         | 7753        |\n",
      "|    total_timesteps      | 2211840     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029195853 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0018     |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 0.139       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 7760        |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014877541 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0448      |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.0975      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 7767        |\n",
      "|    total_timesteps      | 2215936     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015566678 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 7774        |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| total_reward_steps      | 162         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014784377 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1084        |\n",
      "|    time_elapsed         | 7780        |\n",
      "|    total_timesteps      | 2220032     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020284615 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.624       |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    value_loss           | 1.94        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 7787        |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| total_reward_steps      | 191         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013637208 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000457   |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00038    |\n",
      "|    value_loss           | 1.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 7794        |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020792926 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0802      |\n",
      "|    n_updates            | 10850       |\n",
      "|    policy_gradient_loss | 0.0157      |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 7801        |\n",
      "|    total_timesteps      | 2226176     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015916405 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.849      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0074     |\n",
      "|    n_updates            | 10860       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 7807        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026996233 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00983    |\n",
      "|    n_updates            | 10870       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1089        |\n",
      "|    time_elapsed         | 7814        |\n",
      "|    total_timesteps      | 2230272     |\n",
      "| total_reward_steps      | 127         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021461815 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0165      |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1090       |\n",
      "|    time_elapsed         | 7821       |\n",
      "|    total_timesteps      | 2232320    |\n",
      "| total_reward_steps      | 138        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01450662 |\n",
      "|    clip_fraction        | 0.387      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.971     |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0236    |\n",
      "|    n_updates            | 10890      |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 0.0813     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 7828        |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| total_reward_steps      | 206         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022137739 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0743      |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    value_loss           | 0.498       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 7834        |\n",
      "|    total_timesteps      | 2236416     |\n",
      "| total_reward_steps      | 177         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020653486 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 10910       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 1.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 7841        |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024732355 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.347       |\n",
      "|    n_updates            | 10920       |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 0.636       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1094       |\n",
      "|    time_elapsed         | 7848       |\n",
      "|    total_timesteps      | 2240512    |\n",
      "| total_reward_steps      | 172        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02351595 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.799     |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.102      |\n",
      "|    n_updates            | 10930      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.36       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 7855        |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023947993 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.191       |\n",
      "|    n_updates            | 10940       |\n",
      "|    policy_gradient_loss | 0.00664     |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 7862        |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015484192 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 10950       |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.098       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1097        |\n",
      "|    time_elapsed         | 7868        |\n",
      "|    total_timesteps      | 2246656     |\n",
      "| total_reward_steps      | 285         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023561243 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.24        |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 0.9         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1098       |\n",
      "|    time_elapsed         | 7874       |\n",
      "|    total_timesteps      | 2248704    |\n",
      "| total_reward_steps      | 70         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08924184 |\n",
      "|    clip_fraction        | 0.517      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.853     |\n",
      "|    explained_variance   | 0.194      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 10970      |\n",
      "|    policy_gradient_loss | 0.0426     |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1099        |\n",
      "|    time_elapsed         | 7881        |\n",
      "|    total_timesteps      | 2250752     |\n",
      "| total_reward_steps      | 22          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041914955 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.372       |\n",
      "|    n_updates            | 10980       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 7887        |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044039406 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0253      |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 7894        |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025316494 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 7900        |\n",
      "|    total_timesteps      | 2256896     |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019590938 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0459      |\n",
      "|    n_updates            | 11010       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    value_loss           | 0.287       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 7907        |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027939925 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1104        |\n",
      "|    time_elapsed         | 7914        |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022618383 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 7920        |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| total_reward_steps      | 23          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022852223 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | 0.00011     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1106        |\n",
      "|    time_elapsed         | 7927        |\n",
      "|    total_timesteps      | 2265088     |\n",
      "| total_reward_steps      | 167         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018676624 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 11050       |\n",
      "|    policy_gradient_loss | -0.000868   |\n",
      "|    value_loss           | 1.51        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1107       |\n",
      "|    time_elapsed         | 7934       |\n",
      "|    total_timesteps      | 2267136    |\n",
      "| total_reward_steps      | 42         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01703788 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.66      |\n",
      "|    explained_variance   | 0.534      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.05       |\n",
      "|    n_updates            | 11060      |\n",
      "|    policy_gradient_loss | 0.00536    |\n",
      "|    value_loss           | 2.03       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1108       |\n",
      "|    time_elapsed         | 7941       |\n",
      "|    total_timesteps      | 2269184    |\n",
      "| total_reward_steps      | 36         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03733749 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.739     |\n",
      "|    explained_variance   | 0.45       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.27       |\n",
      "|    n_updates            | 11070      |\n",
      "|    policy_gradient_loss | 0.0097     |\n",
      "|    value_loss           | 1.74       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1109        |\n",
      "|    time_elapsed         | 7948        |\n",
      "|    total_timesteps      | 2271232     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025184093 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1110       |\n",
      "|    time_elapsed         | 7954       |\n",
      "|    total_timesteps      | 2273280    |\n",
      "| total_reward_steps      | 90         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02903083 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.777     |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0303     |\n",
      "|    n_updates            | 11090      |\n",
      "|    policy_gradient_loss | -0.00691   |\n",
      "|    value_loss           | 0.678      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1111       |\n",
      "|    time_elapsed         | 7961       |\n",
      "|    total_timesteps      | 2275328    |\n",
      "| total_reward_steps      | 116        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01846717 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.789     |\n",
      "|    explained_variance   | 0.847      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 11100      |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.119      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 7968        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| total_reward_steps      | 139         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029427646 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.125       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.615       |\n",
      "|    n_updates            | 11110       |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    value_loss           | 5           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 7975        |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| total_reward_steps      | 150         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030305866 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.724      |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.275       |\n",
      "|    n_updates            | 11120       |\n",
      "|    policy_gradient_loss | 0.0165      |\n",
      "|    value_loss           | 4.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1114        |\n",
      "|    time_elapsed         | 7981        |\n",
      "|    total_timesteps      | 2281472     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031808097 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.395       |\n",
      "|    n_updates            | 11130       |\n",
      "|    policy_gradient_loss | -0.000455   |\n",
      "|    value_loss           | 0.674       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1115       |\n",
      "|    time_elapsed         | 7988       |\n",
      "|    total_timesteps      | 2283520    |\n",
      "| total_reward_steps      | 127        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02226365 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | 0.773      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00738    |\n",
      "|    n_updates            | 11140      |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1116        |\n",
      "|    time_elapsed         | 7995        |\n",
      "|    total_timesteps      | 2285568     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017513353 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0566      |\n",
      "|    n_updates            | 11150       |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 8002        |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015178695 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.17        |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 285       |\n",
      "|    iterations           | 1118      |\n",
      "|    time_elapsed         | 8009      |\n",
      "|    total_timesteps      | 2289664   |\n",
      "| total_reward_steps      | 127       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0233584 |\n",
      "|    clip_fraction        | 0.356     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.751    |\n",
      "|    explained_variance   | 0.373     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0895    |\n",
      "|    n_updates            | 11170     |\n",
      "|    policy_gradient_loss | -0.00382  |\n",
      "|    value_loss           | 0.441     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1119        |\n",
      "|    time_elapsed         | 8015        |\n",
      "|    total_timesteps      | 2291712     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022395093 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.244       |\n",
      "|    n_updates            | 11180       |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    value_loss           | 0.394       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 8022        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029025225 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.371       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1121        |\n",
      "|    time_elapsed         | 8029        |\n",
      "|    total_timesteps      | 2295808     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018797632 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0887      |\n",
      "|    n_updates            | 11200       |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 8036        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019530263 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.00789    |\n",
      "|    value_loss           | 0.586       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 8043        |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012355423 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.178       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=138.20 +/- 46.36\n",
      "Episode length: 1091.87 +/- 138.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.09e+03    |\n",
      "|    mean_reward          | 138         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014362081 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00126    |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 0.449       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 1124     |\n",
      "|    time_elapsed    | 8090     |\n",
      "|    total_timesteps | 2301952  |\n",
      "| total_reward_steps | 258      |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1125       |\n",
      "|    time_elapsed         | 8096       |\n",
      "|    total_timesteps      | 2304000    |\n",
      "| total_reward_steps      | 112        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03861078 |\n",
      "|    clip_fraction        | 0.445      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.864     |\n",
      "|    explained_variance   | 0.154      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.202      |\n",
      "|    n_updates            | 11240      |\n",
      "|    policy_gradient_loss | 0.0181     |\n",
      "|    value_loss           | 6.08       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1126        |\n",
      "|    time_elapsed         | 8103        |\n",
      "|    total_timesteps      | 2306048     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032527447 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0127      |\n",
      "|    n_updates            | 11250       |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 1.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1127        |\n",
      "|    time_elapsed         | 8110        |\n",
      "|    total_timesteps      | 2308096     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027229905 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 11260       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1128        |\n",
      "|    time_elapsed         | 8116        |\n",
      "|    total_timesteps      | 2310144     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015113607 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.864      |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0282     |\n",
      "|    n_updates            | 11270       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.276       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 8123        |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015344808 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 8129        |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| total_reward_steps      | 129         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026582427 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.251       |\n",
      "|    n_updates            | 11290       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 2.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1131        |\n",
      "|    time_elapsed         | 8135        |\n",
      "|    total_timesteps      | 2316288     |\n",
      "| total_reward_steps      | 157         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017263634 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.606       |\n",
      "|    n_updates            | 11300       |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    value_loss           | 0.411       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 8142        |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035703354 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    value_loss           | 11.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1133        |\n",
      "|    time_elapsed         | 8148        |\n",
      "|    total_timesteps      | 2320384     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044602603 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000873   |\n",
      "|    n_updates            | 11320       |\n",
      "|    policy_gradient_loss | -0.00956    |\n",
      "|    value_loss           | 0.0871      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 8155        |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033026997 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0821      |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 8162        |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038550206 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 11340       |\n",
      "|    policy_gradient_loss | -0.00174    |\n",
      "|    value_loss           | 0.467       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1136       |\n",
      "|    time_elapsed         | 8169       |\n",
      "|    total_timesteps      | 2326528    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03122138 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.661     |\n",
      "|    explained_variance   | 0.314      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 11350      |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 0.434      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 8176        |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034333404 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 11360       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    value_loss           | 0.424       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1138        |\n",
      "|    time_elapsed         | 8182        |\n",
      "|    total_timesteps      | 2330624     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025116697 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -6.58e-05   |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1139       |\n",
      "|    time_elapsed         | 8189       |\n",
      "|    total_timesteps      | 2332672    |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02168058 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.166      |\n",
      "|    n_updates            | 11380      |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 8196        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025379067 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00459    |\n",
      "|    n_updates            | 11390       |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1141        |\n",
      "|    time_elapsed         | 8203        |\n",
      "|    total_timesteps      | 2336768     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034465306 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0233      |\n",
      "|    n_updates            | 11400       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    value_loss           | 0.498       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 8210        |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023875657 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0463      |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1143        |\n",
      "|    time_elapsed         | 8216        |\n",
      "|    total_timesteps      | 2340864     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027327478 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00645     |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    value_loss           | 0.359       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 8223        |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027231794 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.645      |\n",
      "|    explained_variance   | 0.485       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0358      |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1145       |\n",
      "|    time_elapsed         | 8230       |\n",
      "|    total_timesteps      | 2344960    |\n",
      "| total_reward_steps      | 48         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02423599 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.77      |\n",
      "|    explained_variance   | 0.646      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0214     |\n",
      "|    n_updates            | 11440      |\n",
      "|    policy_gradient_loss | -0.0169    |\n",
      "|    value_loss           | 0.0899     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1146        |\n",
      "|    time_elapsed         | 8237        |\n",
      "|    total_timesteps      | 2347008     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020505494 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 11450       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 0.0944      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1147        |\n",
      "|    time_elapsed         | 8244        |\n",
      "|    total_timesteps      | 2349056     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026110811 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0449      |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 0.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1148        |\n",
      "|    time_elapsed         | 8250        |\n",
      "|    total_timesteps      | 2351104     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021848565 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 11470       |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0863      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 8257        |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015663613 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0211      |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.093       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 8264        |\n",
      "|    total_timesteps      | 2355200     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015965924 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0908      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 8271        |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014651055 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 8278        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021050014 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0773      |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.0885      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1153        |\n",
      "|    time_elapsed         | 8284        |\n",
      "|    total_timesteps      | 2361344     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035748918 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.278       |\n",
      "|    n_updates            | 11520       |\n",
      "|    policy_gradient_loss | 0.00642     |\n",
      "|    value_loss           | 2.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 8291        |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023187451 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0178     |\n",
      "|    n_updates            | 11530       |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.0824      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1155        |\n",
      "|    time_elapsed         | 8298        |\n",
      "|    total_timesteps      | 2365440     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024926096 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 11540       |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 8305        |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017496249 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0967      |\n",
      "|    n_updates            | 11550       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.096       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 8311        |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021176567 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0952      |\n",
      "|    n_updates            | 11560       |\n",
      "|    policy_gradient_loss | 0.000394    |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1158        |\n",
      "|    time_elapsed         | 8318        |\n",
      "|    total_timesteps      | 2371584     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030346205 |\n",
      "|    clip_fraction        | 0.431       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.02        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 0.343       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 8325        |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026829053 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1160        |\n",
      "|    time_elapsed         | 8332        |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| total_reward_steps      | 173         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177003 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0386      |\n",
      "|    n_updates            | 11590       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 8339        |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056435272 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00528     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.318       |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 8345        |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030563891 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00317    |\n",
      "|    n_updates            | 11610       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.149       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1163        |\n",
      "|    time_elapsed         | 8352        |\n",
      "|    total_timesteps      | 2381824     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019828599 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.054       |\n",
      "|    n_updates            | 11620       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1164        |\n",
      "|    time_elapsed         | 8359        |\n",
      "|    total_timesteps      | 2383872     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020635635 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00651     |\n",
      "|    n_updates            | 11630       |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 285       |\n",
      "|    iterations           | 1165      |\n",
      "|    time_elapsed         | 8365      |\n",
      "|    total_timesteps      | 2385920   |\n",
      "| total_reward_steps      | 68        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0186788 |\n",
      "|    clip_fraction        | 0.344     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.732    |\n",
      "|    explained_variance   | 0.435     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0203    |\n",
      "|    n_updates            | 11640     |\n",
      "|    policy_gradient_loss | -0.00756  |\n",
      "|    value_loss           | 0.449     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1166       |\n",
      "|    time_elapsed         | 8372       |\n",
      "|    total_timesteps      | 2387968    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01800482 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.499      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.134      |\n",
      "|    n_updates            | 11650      |\n",
      "|    policy_gradient_loss | -0.00754   |\n",
      "|    value_loss           | 0.482      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1167        |\n",
      "|    time_elapsed         | 8378        |\n",
      "|    total_timesteps      | 2390016     |\n",
      "| total_reward_steps      | 183         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024384445 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6           |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | 0.00259     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1168       |\n",
      "|    time_elapsed         | 8385       |\n",
      "|    total_timesteps      | 2392064    |\n",
      "| total_reward_steps      | 38         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02867958 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.714     |\n",
      "|    explained_variance   | 0.229      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.877      |\n",
      "|    n_updates            | 11670      |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    value_loss           | 12.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 8391        |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| total_reward_steps      | 183         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030826999 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.233       |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | 0.0249      |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1170        |\n",
      "|    time_elapsed         | 8398        |\n",
      "|    total_timesteps      | 2396160     |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057938263 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.365       |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | 0.019       |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 8404        |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028841378 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 0.65        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=41.70 +/- 14.02\n",
      "Episode length: 781.63 +/- 99.94\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 782        |\n",
      "|    mean_reward          | 41.7       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2400000    |\n",
      "| total_reward_steps      | 25         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03700692 |\n",
      "|    clip_fraction        | 0.471      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.807     |\n",
      "|    explained_variance   | -0.54      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00792   |\n",
      "|    n_updates            | 11710      |\n",
      "|    policy_gradient_loss | 0.00389    |\n",
      "|    value_loss           | 0.221      |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 284     |\n",
      "|    iterations      | 1172    |\n",
      "|    time_elapsed    | 8440    |\n",
      "|    total_timesteps | 2400256 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 8447        |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021437498 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0393      |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    value_loss           | 0.642       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 8454        |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059226118 |\n",
      "|    clip_fraction        | 0.444       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.672      |\n",
      "|    explained_variance   | -0.000561   |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | 0.027       |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 8460        |\n",
      "|    total_timesteps      | 2406400     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028866831 |\n",
      "|    clip_fraction        | 0.441       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 11740       |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    value_loss           | 0.79        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1176        |\n",
      "|    time_elapsed         | 8467        |\n",
      "|    total_timesteps      | 2408448     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014847979 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | -0.698      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 11750       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1177        |\n",
      "|    time_elapsed         | 8474        |\n",
      "|    total_timesteps      | 2410496     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021120276 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0407     |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 8481        |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016599093 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0696      |\n",
      "|    n_updates            | 11770       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 8488        |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017561786 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00844     |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.0781      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1180        |\n",
      "|    time_elapsed         | 8494        |\n",
      "|    total_timesteps      | 2416640     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014849288 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 11790       |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.0841      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 8501        |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049167573 |\n",
      "|    clip_fraction        | 0.503       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.937       |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | 0.0226      |\n",
      "|    value_loss           | 14.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1182        |\n",
      "|    time_elapsed         | 8508        |\n",
      "|    total_timesteps      | 2420736     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022256467 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0201      |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    value_loss           | 0.782       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 8515        |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| total_reward_steps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017424626 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0575      |\n",
      "|    n_updates            | 11820       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 8521        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019558093 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00529     |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 8528        |\n",
      "|    total_timesteps      | 2426880     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017259726 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.296       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0129     |\n",
      "|    n_updates            | 11840       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 0.227       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 8535        |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| total_reward_steps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026031397 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.5         |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 7.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1187        |\n",
      "|    time_elapsed         | 8542        |\n",
      "|    total_timesteps      | 2430976     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022789188 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0115     |\n",
      "|    n_updates            | 11860       |\n",
      "|    policy_gradient_loss | -0.00904    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 8549        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032775976 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | -0.0288     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 8555        |\n",
      "|    total_timesteps      | 2435072     |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029290475 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.705      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0757      |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | 0.0041      |\n",
      "|    value_loss           | 0.676       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 8562        |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029415932 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 11890       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 8569        |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017383903 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.597      |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.014      |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1192        |\n",
      "|    time_elapsed         | 8576        |\n",
      "|    total_timesteps      | 2441216     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029693177 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.706      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00511    |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | 0.000957    |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1193       |\n",
      "|    time_elapsed         | 8583       |\n",
      "|    total_timesteps      | 2443264    |\n",
      "| total_reward_steps      | 350        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01893436 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.65      |\n",
      "|    explained_variance   | 0.377      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0985     |\n",
      "|    n_updates            | 11920      |\n",
      "|    policy_gradient_loss | 0.00421    |\n",
      "|    value_loss           | 0.598      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1194       |\n",
      "|    time_elapsed         | 8589       |\n",
      "|    total_timesteps      | 2445312    |\n",
      "| total_reward_steps      | 42         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06894496 |\n",
      "|    clip_fraction        | 0.462      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.698     |\n",
      "|    explained_variance   | 0.201      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.457      |\n",
      "|    n_updates            | 11930      |\n",
      "|    policy_gradient_loss | 0.0374     |\n",
      "|    value_loss           | 54.8       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 1195      |\n",
      "|    time_elapsed         | 8596      |\n",
      "|    total_timesteps      | 2447360   |\n",
      "| total_reward_steps      | 48        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0265904 |\n",
      "|    clip_fraction        | 0.314     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.491    |\n",
      "|    explained_variance   | 0.202     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.000496  |\n",
      "|    n_updates            | 11940     |\n",
      "|    policy_gradient_loss | -0.00782  |\n",
      "|    value_loss           | 0.159     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1196        |\n",
      "|    time_elapsed         | 8603        |\n",
      "|    total_timesteps      | 2449408     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030848848 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.00425     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.767       |\n",
      "|    n_updates            | 11950       |\n",
      "|    policy_gradient_loss | 0.0076      |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1197        |\n",
      "|    time_elapsed         | 8609        |\n",
      "|    total_timesteps      | 2451456     |\n",
      "| total_reward_steps      | 209         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040261686 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.606      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | 0.0192      |\n",
      "|    value_loss           | 9.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 8616        |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027625281 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.248       |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 8622        |\n",
      "|    total_timesteps      | 2455552     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022827268 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.761      |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1200       |\n",
      "|    time_elapsed         | 8629       |\n",
      "|    total_timesteps      | 2457600    |\n",
      "| total_reward_steps      | 80         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02574027 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.557     |\n",
      "|    explained_variance   | 0.213      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.277      |\n",
      "|    n_updates            | 11990      |\n",
      "|    policy_gradient_loss | 0.000109   |\n",
      "|    value_loss           | 1.61       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 8635        |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022815578 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.113       |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 0.329       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1202        |\n",
      "|    time_elapsed         | 8641        |\n",
      "|    total_timesteps      | 2461696     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032312118 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0592      |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 8648        |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| total_reward_steps      | 27          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054012284 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.71        |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | 0.0188      |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1204        |\n",
      "|    time_elapsed         | 8654        |\n",
      "|    total_timesteps      | 2465792     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028594065 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | 0.0018      |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 8661        |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021076087 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1206       |\n",
      "|    time_elapsed         | 8667       |\n",
      "|    total_timesteps      | 2469888    |\n",
      "| total_reward_steps      | 194        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14163968 |\n",
      "|    clip_fraction        | 0.523      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0.062      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.511      |\n",
      "|    n_updates            | 12050      |\n",
      "|    policy_gradient_loss | 0.0472     |\n",
      "|    value_loss           | 41.9       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1207       |\n",
      "|    time_elapsed         | 8673       |\n",
      "|    total_timesteps      | 2471936    |\n",
      "| total_reward_steps      | 49         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02875486 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.597     |\n",
      "|    explained_variance   | 0.276      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 45.9       |\n",
      "|    n_updates            | 12060      |\n",
      "|    policy_gradient_loss | 0.0253     |\n",
      "|    value_loss           | 11.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 8679        |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| total_reward_steps      | 354         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028497335 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | -0.0356     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0207      |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 0.168       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1209        |\n",
      "|    time_elapsed         | 8686        |\n",
      "|    total_timesteps      | 2476032     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059632972 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | 0.033       |\n",
      "|    value_loss           | 42.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 8692        |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031826578 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.15        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | 0.00278     |\n",
      "|    value_loss           | 0.722       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1211        |\n",
      "|    time_elapsed         | 8698        |\n",
      "|    total_timesteps      | 2480128     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021993471 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00304     |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | 0.00349     |\n",
      "|    value_loss           | 0.328       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 8705        |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018653143 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00812    |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 0.0879      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 8712        |\n",
      "|    total_timesteps      | 2484224     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022535134 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00895     |\n",
      "|    n_updates            | 12120       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    value_loss           | 0.573       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1214        |\n",
      "|    time_elapsed         | 8718        |\n",
      "|    total_timesteps      | 2486272     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759299 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0449      |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.0915      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 8725        |\n",
      "|    total_timesteps      | 2488320     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057822496 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.27        |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | 0.0326      |\n",
      "|    value_loss           | 6.71        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1216        |\n",
      "|    time_elapsed         | 8732        |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057902493 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 8739        |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022440756 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 8745        |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017071076 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0234      |\n",
      "|    n_updates            | 12170       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.0908      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 1219       |\n",
      "|    time_elapsed         | 8752       |\n",
      "|    total_timesteps      | 2496512    |\n",
      "| total_reward_steps      | 50         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01797926 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.628     |\n",
      "|    explained_variance   | 0.879      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0561     |\n",
      "|    n_updates            | 12180      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.0838     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 8759        |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014495888 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0373      |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.0782      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2500000, episode_reward=68.47 +/- 43.80\n",
      "Episode length: 951.13 +/- 115.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 951         |\n",
      "|    mean_reward          | 68.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2500000     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019595604 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0172     |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.0897      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 284      |\n",
      "|    iterations      | 1221     |\n",
      "|    time_elapsed    | 8801     |\n",
      "|    total_timesteps | 2500608  |\n",
      "| total_reward_steps | 52       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 8808        |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020656684 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0842      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 8815        |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019527126 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 12220       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0895      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1224       |\n",
      "|    time_elapsed         | 8821       |\n",
      "|    total_timesteps      | 2506752    |\n",
      "| total_reward_steps      | 90         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880615 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.85       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0182     |\n",
      "|    n_updates            | 12230      |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    value_loss           | 0.0992     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 8828        |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025494184 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | 0.00687     |\n",
      "|    value_loss           | 1.56        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1226        |\n",
      "|    time_elapsed         | 8835        |\n",
      "|    total_timesteps      | 2510848     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022458248 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 12250       |\n",
      "|    policy_gradient_loss | 0.00782     |\n",
      "|    value_loss           | 1.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 8842        |\n",
      "|    total_timesteps      | 2512896     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016556805 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0663      |\n",
      "|    n_updates            | 12260       |\n",
      "|    policy_gradient_loss | 0.00406     |\n",
      "|    value_loss           | 0.788       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1228       |\n",
      "|    time_elapsed         | 8849       |\n",
      "|    total_timesteps      | 2514944    |\n",
      "| total_reward_steps      | 59         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10877741 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.653     |\n",
      "|    explained_variance   | 0.108      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.53       |\n",
      "|    n_updates            | 12270      |\n",
      "|    policy_gradient_loss | 0.0284     |\n",
      "|    value_loss           | 12.8       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 1229      |\n",
      "|    time_elapsed         | 8855      |\n",
      "|    total_timesteps      | 2516992   |\n",
      "| total_reward_steps      | 112       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0726013 |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.536    |\n",
      "|    explained_variance   | 0.0529    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 23.4      |\n",
      "|    n_updates            | 12280     |\n",
      "|    policy_gradient_loss | 0.0361    |\n",
      "|    value_loss           | 38.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1230        |\n",
      "|    time_elapsed         | 8862        |\n",
      "|    total_timesteps      | 2519040     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044769917 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 12290       |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1231       |\n",
      "|    time_elapsed         | 8869       |\n",
      "|    total_timesteps      | 2521088    |\n",
      "| total_reward_steps      | 50         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07166283 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.481     |\n",
      "|    explained_variance   | 0.0741     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.147      |\n",
      "|    n_updates            | 12300      |\n",
      "|    policy_gradient_loss | 0.00293    |\n",
      "|    value_loss           | 0.578      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 8876        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029237228 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.599      |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0544      |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 0.318       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 8883        |\n",
      "|    total_timesteps      | 2525184     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020981513 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0245      |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 1234      |\n",
      "|    time_elapsed         | 8890      |\n",
      "|    total_timesteps      | 2527232   |\n",
      "| total_reward_steps      | 53        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0238805 |\n",
      "|    clip_fraction        | 0.343     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.689    |\n",
      "|    explained_variance   | 0.823     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.00088   |\n",
      "|    n_updates            | 12330     |\n",
      "|    policy_gradient_loss | -0.0117   |\n",
      "|    value_loss           | 0.102     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 8896        |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018381553 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0356      |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.0825      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1236        |\n",
      "|    time_elapsed         | 8903        |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025046676 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.211       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0065      |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1237        |\n",
      "|    time_elapsed         | 8910        |\n",
      "|    total_timesteps      | 2533376     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018185535 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 12360       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1238       |\n",
      "|    time_elapsed         | 8916       |\n",
      "|    total_timesteps      | 2535424    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01730994 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.722     |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.000415   |\n",
      "|    n_updates            | 12370      |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.0954     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 8922        |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025128601 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | 0.00933     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1240       |\n",
      "|    time_elapsed         | 8929       |\n",
      "|    total_timesteps      | 2539520    |\n",
      "| total_reward_steps      | 45         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04010286 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.749     |\n",
      "|    explained_variance   | 0.405      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0058     |\n",
      "|    n_updates            | 12390      |\n",
      "|    policy_gradient_loss | 0.0161     |\n",
      "|    value_loss           | 0.683      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1241        |\n",
      "|    time_elapsed         | 8935        |\n",
      "|    total_timesteps      | 2541568     |\n",
      "| total_reward_steps      | 208         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021994755 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.41        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | 0.00635     |\n",
      "|    value_loss           | 0.766       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 8941        |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033186175 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0877      |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | 0.00688     |\n",
      "|    value_loss           | 4.86        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1243        |\n",
      "|    time_elapsed         | 8948        |\n",
      "|    total_timesteps      | 2545664     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019910151 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0959      |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 8955        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025832117 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.203       |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.000116   |\n",
      "|    value_loss           | 0.581       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 8962        |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021540688 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.0964      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1246        |\n",
      "|    time_elapsed         | 8969        |\n",
      "|    total_timesteps      | 2551808     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021658443 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00846     |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.091       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 8975        |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023265373 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00601    |\n",
      "|    n_updates            | 12460       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1248        |\n",
      "|    time_elapsed         | 8982        |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016952613 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0849      |\n",
      "|    n_updates            | 12470       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.0846      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 8989        |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015159991 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.189       |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1250        |\n",
      "|    time_elapsed         | 8996        |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020293739 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0666      |\n",
      "|    n_updates            | 12490       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 9003        |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025474338 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.787      |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00974     |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.0914      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1252        |\n",
      "|    time_elapsed         | 9009        |\n",
      "|    total_timesteps      | 2564096     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024162602 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 12510       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.587       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1253       |\n",
      "|    time_elapsed         | 9016       |\n",
      "|    total_timesteps      | 2566144    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06510198 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.714     |\n",
      "|    explained_variance   | 0.158      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.327      |\n",
      "|    n_updates            | 12520      |\n",
      "|    policy_gradient_loss | 0.0232     |\n",
      "|    value_loss           | 3.31       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1254       |\n",
      "|    time_elapsed         | 9023       |\n",
      "|    total_timesteps      | 2568192    |\n",
      "| total_reward_steps      | 43         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02967984 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.842     |\n",
      "|    explained_variance   | -0.287     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0731     |\n",
      "|    n_updates            | 12530      |\n",
      "|    policy_gradient_loss | -0.00437   |\n",
      "|    value_loss           | 0.17       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1255        |\n",
      "|    time_elapsed         | 9030        |\n",
      "|    total_timesteps      | 2570240     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023114081 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1256       |\n",
      "|    time_elapsed         | 9036       |\n",
      "|    total_timesteps      | 2572288    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11682807 |\n",
      "|    clip_fraction        | 0.604      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.865     |\n",
      "|    explained_variance   | -0.0128    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 43.7       |\n",
      "|    n_updates            | 12550      |\n",
      "|    policy_gradient_loss | 0.0389     |\n",
      "|    value_loss           | 23.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 9043        |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039412364 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1258       |\n",
      "|    time_elapsed         | 9050       |\n",
      "|    total_timesteps      | 2576384    |\n",
      "| total_reward_steps      | 89         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03191316 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.595      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0264    |\n",
      "|    n_updates            | 12570      |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 0.124      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 9057        |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055387013 |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1260        |\n",
      "|    time_elapsed         | 9064        |\n",
      "|    total_timesteps      | 2580480     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028577127 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    value_loss           | 0.543       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 9070        |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027649466 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 9077        |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033404604 |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 9084        |\n",
      "|    total_timesteps      | 2586624     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020587418 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00773     |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | 0.000114    |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 9091        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022741286 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0465      |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1265        |\n",
      "|    time_elapsed         | 9098        |\n",
      "|    total_timesteps      | 2590720     |\n",
      "| total_reward_steps      | 145         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018527154 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0251      |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -4.31e-05   |\n",
      "|    value_loss           | 0.914       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 9104        |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021164859 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | 0.000295    |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 9111        |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019252362 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0921      |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 0.612       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1268        |\n",
      "|    time_elapsed         | 9118        |\n",
      "|    total_timesteps      | 2596864     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014769545 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00525     |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.222       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 9125        |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| total_reward_steps      | 203         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018602218 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0398      |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 0.466       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=60.00 +/- 23.29\n",
      "Episode length: 899.13 +/- 180.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 899         |\n",
      "|    mean_reward          | 60          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2600000     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026306901 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.332       |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | 0.00922     |\n",
      "|    value_loss           | 4.74        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 1270     |\n",
      "|    time_elapsed    | 9164     |\n",
      "|    total_timesteps | 2600960  |\n",
      "| total_reward_steps | 95       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1271        |\n",
      "|    time_elapsed         | 9171        |\n",
      "|    total_timesteps      | 2603008     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027531635 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | -0.0538     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0867      |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | 0.01        |\n",
      "|    value_loss           | 0.573       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1272        |\n",
      "|    time_elapsed         | 9177        |\n",
      "|    total_timesteps      | 2605056     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021909699 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0391      |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    value_loss           | 0.367       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 9184        |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022858972 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 12720       |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 9190        |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017850425 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.723      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0532      |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.00944    |\n",
      "|    value_loss           | 0.409       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1275        |\n",
      "|    time_elapsed         | 9197        |\n",
      "|    total_timesteps      | 2611200     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028627593 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.247       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 9203        |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018626017 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.762      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 9210        |\n",
      "|    total_timesteps      | 2615296     |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021080779 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0819      |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | -0.00849    |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1278        |\n",
      "|    time_elapsed         | 9217        |\n",
      "|    total_timesteps      | 2617344     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019404452 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0013      |\n",
      "|    n_updates            | 12770       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.27        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 9224        |\n",
      "|    total_timesteps      | 2619392     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019036204 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 12780       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1280        |\n",
      "|    time_elapsed         | 9231        |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019345775 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1281        |\n",
      "|    time_elapsed         | 9237        |\n",
      "|    total_timesteps      | 2623488     |\n",
      "| total_reward_steps      | 213         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016908608 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0461     |\n",
      "|    n_updates            | 12800       |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1282        |\n",
      "|    time_elapsed         | 9244        |\n",
      "|    total_timesteps      | 2625536     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031946696 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.28        |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 7.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 9251        |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| total_reward_steps      | 126         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016472895 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0518      |\n",
      "|    n_updates            | 12820       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 9258        |\n",
      "|    total_timesteps      | 2629632     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016089924 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.985      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0395     |\n",
      "|    n_updates            | 12830       |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.084       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1285        |\n",
      "|    time_elapsed         | 9265        |\n",
      "|    total_timesteps      | 2631680     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022655204 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0893      |\n",
      "|    n_updates            | 12840       |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 9271        |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020700376 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | -0.183      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0834      |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    value_loss           | 0.548       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1287        |\n",
      "|    time_elapsed         | 9278        |\n",
      "|    total_timesteps      | 2635776     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023479614 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | 0.00202     |\n",
      "|    value_loss           | 0.535       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 9285        |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017017322 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.01        |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 9292        |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016435407 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00541    |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1290        |\n",
      "|    time_elapsed         | 9299        |\n",
      "|    total_timesteps      | 2641920     |\n",
      "| total_reward_steps      | 368         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024428127 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.204       |\n",
      "|    n_updates            | 12890       |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 0.845       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 1291      |\n",
      "|    time_elapsed         | 9305      |\n",
      "|    total_timesteps      | 2643968   |\n",
      "| total_reward_steps      | 77        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0408277 |\n",
      "|    clip_fraction        | 0.465     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.787    |\n",
      "|    explained_variance   | 0.0403    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.117     |\n",
      "|    n_updates            | 12900     |\n",
      "|    policy_gradient_loss | 0.0318    |\n",
      "|    value_loss           | 32.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1292        |\n",
      "|    time_elapsed         | 9312        |\n",
      "|    total_timesteps      | 2646016     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018538244 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0858      |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1293       |\n",
      "|    time_elapsed         | 9319       |\n",
      "|    total_timesteps      | 2648064    |\n",
      "| total_reward_steps      | 47         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10332945 |\n",
      "|    clip_fraction        | 0.481      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.848     |\n",
      "|    explained_variance   | -0.217     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 8.63       |\n",
      "|    n_updates            | 12920      |\n",
      "|    policy_gradient_loss | 0.0402     |\n",
      "|    value_loss           | 2.1        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1294        |\n",
      "|    time_elapsed         | 9326        |\n",
      "|    total_timesteps      | 2650112     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020291375 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00873    |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 9332        |\n",
      "|    total_timesteps      | 2652160     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021616716 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 9339        |\n",
      "|    total_timesteps      | 2654208     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013562733 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.785      |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 12950       |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1297        |\n",
      "|    time_elapsed         | 9346        |\n",
      "|    total_timesteps      | 2656256     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015744314 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00252    |\n",
      "|    n_updates            | 12960       |\n",
      "|    policy_gradient_loss | -0.00912    |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 9353        |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014801621 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0354      |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1299        |\n",
      "|    time_elapsed         | 9360        |\n",
      "|    total_timesteps      | 2660352     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017719641 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.905      |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.0962      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 9367        |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015336225 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00398     |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    value_loss           | 0.468       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 9373        |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013846582 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0023     |\n",
      "|    n_updates            | 13000       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0881      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1302        |\n",
      "|    time_elapsed         | 9380        |\n",
      "|    total_timesteps      | 2666496     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018598352 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0071     |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 0.0869      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 9387        |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015546961 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.0933      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1304        |\n",
      "|    time_elapsed         | 9394        |\n",
      "|    total_timesteps      | 2670592     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015216244 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0304      |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 9401        |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016297996 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 0.0779      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 9407        |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020259535 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 13050       |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0877      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 9413        |\n",
      "|    total_timesteps      | 2676736     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013803974 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0285      |\n",
      "|    n_updates            | 13060       |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 0.0938      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1308       |\n",
      "|    time_elapsed         | 9420       |\n",
      "|    total_timesteps      | 2678784    |\n",
      "| total_reward_steps      | 78         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01761614 |\n",
      "|    clip_fraction        | 0.406      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.987     |\n",
      "|    explained_variance   | 0.502      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.04       |\n",
      "|    n_updates            | 13070      |\n",
      "|    policy_gradient_loss | -0.00768   |\n",
      "|    value_loss           | 0.314      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1309        |\n",
      "|    time_elapsed         | 9426        |\n",
      "|    total_timesteps      | 2680832     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017569862 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.876      |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 13080       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 9433        |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015514507 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00419    |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    value_loss           | 0.36        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 9439        |\n",
      "|    total_timesteps      | 2684928     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015895482 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 13100       |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1312        |\n",
      "|    time_elapsed         | 9446        |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012028034 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 13110       |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 0.0957      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1313        |\n",
      "|    time_elapsed         | 9453        |\n",
      "|    total_timesteps      | 2689024     |\n",
      "| total_reward_steps      | 124         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021486077 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.926      |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 13120       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1314        |\n",
      "|    time_elapsed         | 9459        |\n",
      "|    total_timesteps      | 2691072     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022490993 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | 0.00616     |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1315        |\n",
      "|    time_elapsed         | 9466        |\n",
      "|    total_timesteps      | 2693120     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019723378 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.564       |\n",
      "|    n_updates            | 13140       |\n",
      "|    policy_gradient_loss | 0.000158    |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1316        |\n",
      "|    time_elapsed         | 9473        |\n",
      "|    total_timesteps      | 2695168     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016711833 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0628      |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0913      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 9480        |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| total_reward_steps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015123212 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.067       |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.0954      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 9487        |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015489381 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=99.53 +/- 45.70\n",
      "Episode length: 961.57 +/- 165.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 962         |\n",
      "|    mean_reward          | 99.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2700000     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015148204 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 13180       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0917      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 1319     |\n",
      "|    time_elapsed    | 9529     |\n",
      "|    total_timesteps | 2701312  |\n",
      "| total_reward_steps | 59       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 9536        |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019440603 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0931      |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.659       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1321       |\n",
      "|    time_elapsed         | 9542       |\n",
      "|    total_timesteps      | 2705408    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01447553 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.879     |\n",
      "|    explained_variance   | 0.834      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00182    |\n",
      "|    n_updates            | 13200      |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    value_loss           | 0.0866     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 9549        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017451368 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.837      |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.0786      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 9556        |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021408211 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00794     |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.318       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1324        |\n",
      "|    time_elapsed         | 9563        |\n",
      "|    total_timesteps      | 2711552     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017559519 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0489      |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1325       |\n",
      "|    time_elapsed         | 9570       |\n",
      "|    total_timesteps      | 2713600    |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01959256 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.77      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0126     |\n",
      "|    n_updates            | 13240      |\n",
      "|    policy_gradient_loss | -0.0085    |\n",
      "|    value_loss           | 0.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 9576        |\n",
      "|    total_timesteps      | 2715648     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014948631 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00349    |\n",
      "|    n_updates            | 13250       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0803      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 9583        |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017026294 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.0882      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 9590        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011140228 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.0803      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1329        |\n",
      "|    time_elapsed         | 9597        |\n",
      "|    total_timesteps      | 2721792     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012012521 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 13280       |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.0917      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 9604        |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020258633 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.894      |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.591       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1331        |\n",
      "|    time_elapsed         | 9611        |\n",
      "|    total_timesteps      | 2725888     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021462038 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 13300       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 9617        |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019469572 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.105       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 9624        |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017703898 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.365       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1334        |\n",
      "|    time_elapsed         | 9631        |\n",
      "|    total_timesteps      | 2732032     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012065038 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0268     |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0911      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 9638        |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015757833 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1336        |\n",
      "|    time_elapsed         | 9644        |\n",
      "|    total_timesteps      | 2736128     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014348971 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.0825      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 9651        |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027051192 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.049       |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1338        |\n",
      "|    time_elapsed         | 9658        |\n",
      "|    total_timesteps      | 2740224     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013454597 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00952    |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.0827      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 9664        |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629459 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.105       |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.0793      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 9670        |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013927011 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 13390       |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 0.0749      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1341       |\n",
      "|    time_elapsed         | 9677       |\n",
      "|    total_timesteps      | 2746368    |\n",
      "| total_reward_steps      | 63         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03363499 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.851     |\n",
      "|    explained_variance   | 0.575      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00446    |\n",
      "|    n_updates            | 13400      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    value_loss           | 0.425      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1342       |\n",
      "|    time_elapsed         | 9683       |\n",
      "|    total_timesteps      | 2748416    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01590355 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.847     |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.204      |\n",
      "|    n_updates            | 13410      |\n",
      "|    policy_gradient_loss | -0.0168    |\n",
      "|    value_loss           | 0.0881     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1343        |\n",
      "|    time_elapsed         | 9690        |\n",
      "|    total_timesteps      | 2750464     |\n",
      "| total_reward_steps      | 163         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015420667 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.891      |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 13420       |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.0862      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 9696        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033925366 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0915      |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    value_loss           | 11.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 9703        |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043556307 |\n",
      "|    clip_fraction        | 0.519       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.873      |\n",
      "|    explained_variance   | 0.00153     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 13440       |\n",
      "|    policy_gradient_loss | 0.0299      |\n",
      "|    value_loss           | 29.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1346       |\n",
      "|    time_elapsed         | 9710       |\n",
      "|    total_timesteps      | 2756608    |\n",
      "| total_reward_steps      | 96         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02045761 |\n",
      "|    clip_fraction        | 0.392      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.804     |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00492    |\n",
      "|    n_updates            | 13450      |\n",
      "|    policy_gradient_loss | -0.00239   |\n",
      "|    value_loss           | 0.362      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 9717        |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022616645 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0244      |\n",
      "|    n_updates            | 13460       |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1348        |\n",
      "|    time_elapsed         | 9724        |\n",
      "|    total_timesteps      | 2760704     |\n",
      "| total_reward_steps      | 139         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023295153 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0559      |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 0.393       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1349       |\n",
      "|    time_elapsed         | 9730       |\n",
      "|    total_timesteps      | 2762752    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03452329 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.869     |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0943     |\n",
      "|    n_updates            | 13480      |\n",
      "|    policy_gradient_loss | 0.00795    |\n",
      "|    value_loss           | 1.37       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 9737        |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022224646 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00276     |\n",
      "|    n_updates            | 13490       |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    value_loss           | 0.513       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1351       |\n",
      "|    time_elapsed         | 9744       |\n",
      "|    total_timesteps      | 2766848    |\n",
      "| total_reward_steps      | 39         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02402908 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0544     |\n",
      "|    n_updates            | 13500      |\n",
      "|    policy_gradient_loss | -0.00505   |\n",
      "|    value_loss           | 0.296      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 9751        |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020004954 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1353        |\n",
      "|    time_elapsed         | 9758        |\n",
      "|    total_timesteps      | 2770944     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016111955 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000503    |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.0874      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1354       |\n",
      "|    time_elapsed         | 9764       |\n",
      "|    total_timesteps      | 2772992    |\n",
      "| total_reward_steps      | 56         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01620391 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.873      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0943     |\n",
      "|    n_updates            | 13530      |\n",
      "|    policy_gradient_loss | -0.017     |\n",
      "|    value_loss           | 0.098      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1355        |\n",
      "|    time_elapsed         | 9771        |\n",
      "|    total_timesteps      | 2775040     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015642252 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00341     |\n",
      "|    n_updates            | 13540       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 9778        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015177658 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0252     |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.0921      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 9785        |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016182203 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0427      |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.00975    |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1358        |\n",
      "|    time_elapsed         | 9792        |\n",
      "|    total_timesteps      | 2781184     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020325104 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0353      |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 9798        |\n",
      "|    total_timesteps      | 2783232     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028106872 |\n",
      "|    clip_fraction        | 0.442       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.0721      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 13580       |\n",
      "|    policy_gradient_loss | 0.00992     |\n",
      "|    value_loss           | 3.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1360        |\n",
      "|    time_elapsed         | 9805        |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| total_reward_steps      | 132         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021532606 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | 0.00555     |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 9812        |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044314064 |\n",
      "|    clip_fraction        | 0.468       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.227       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.93        |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | 0.0145      |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 9819        |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025903612 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.732      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1363        |\n",
      "|    time_elapsed         | 9826        |\n",
      "|    total_timesteps      | 2791424     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016898122 |\n",
      "|    clip_fraction        | 0.401       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0216      |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1364       |\n",
      "|    time_elapsed         | 9833       |\n",
      "|    total_timesteps      | 2793472    |\n",
      "| total_reward_steps      | 81         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01686603 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.754     |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.118      |\n",
      "|    n_updates            | 13630      |\n",
      "|    policy_gradient_loss | -0.00808   |\n",
      "|    value_loss           | 0.631      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1365        |\n",
      "|    time_elapsed         | 9839        |\n",
      "|    total_timesteps      | 2795520     |\n",
      "| total_reward_steps      | 184         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025666585 |\n",
      "|    clip_fraction        | 0.457       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0674      |\n",
      "|    n_updates            | 13640       |\n",
      "|    policy_gradient_loss | -0.00116    |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 1366       |\n",
      "|    time_elapsed         | 9846       |\n",
      "|    total_timesteps      | 2797568    |\n",
      "| total_reward_steps      | 48         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03061015 |\n",
      "|    clip_fraction        | 0.42       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.778     |\n",
      "|    explained_variance   | 0.155      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0499     |\n",
      "|    n_updates            | 13650      |\n",
      "|    policy_gradient_loss | 0.0185     |\n",
      "|    value_loss           | 2.65       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 9853        |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023971688 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0382      |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    value_loss           | 2.31        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=74.13 +/- 18.89\n",
      "Episode length: 981.70 +/- 129.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 982         |\n",
      "|    mean_reward          | 74.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027720023 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | 0.000497    |\n",
      "|    value_loss           | 0.513       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 283      |\n",
      "|    iterations      | 1368     |\n",
      "|    time_elapsed    | 9896     |\n",
      "|    total_timesteps | 2801664  |\n",
      "| total_reward_steps | 75       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 9903        |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016613523 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00999    |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1370        |\n",
      "|    time_elapsed         | 9909        |\n",
      "|    total_timesteps      | 2805760     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021405684 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 13690       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 9915        |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023430414 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.129       |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 9922        |\n",
      "|    total_timesteps      | 2809856     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018577276 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 13710       |\n",
      "|    policy_gradient_loss | -0.000712   |\n",
      "|    value_loss           | 1.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1373        |\n",
      "|    time_elapsed         | 9928        |\n",
      "|    total_timesteps      | 2811904     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025788562 |\n",
      "|    clip_fraction        | 0.459       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0017      |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.635       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1374       |\n",
      "|    time_elapsed         | 9934       |\n",
      "|    total_timesteps      | 2813952    |\n",
      "| total_reward_steps      | 194        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03297858 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.848     |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0515     |\n",
      "|    n_updates            | 13730      |\n",
      "|    policy_gradient_loss | -0.00099   |\n",
      "|    value_loss           | 0.677      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1375        |\n",
      "|    time_elapsed         | 9941        |\n",
      "|    total_timesteps      | 2816000     |\n",
      "| total_reward_steps      | 353         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034061812 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | 0.0339      |\n",
      "|    value_loss           | 15          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 9948        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.084669024 |\n",
      "|    clip_fraction        | 0.474       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.0702      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | 0.0228      |\n",
      "|    value_loss           | 37.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1377       |\n",
      "|    time_elapsed         | 9954       |\n",
      "|    total_timesteps      | 2820096    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06315222 |\n",
      "|    clip_fraction        | 0.439      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.751     |\n",
      "|    explained_variance   | 0.0731     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0678     |\n",
      "|    n_updates            | 13760      |\n",
      "|    policy_gradient_loss | 0.00155    |\n",
      "|    value_loss           | 0.384      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 9961        |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022487096 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 9968        |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025269246 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0707      |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 0.41        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1380       |\n",
      "|    time_elapsed         | 9975       |\n",
      "|    total_timesteps      | 2826240    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03336694 |\n",
      "|    clip_fraction        | 0.42       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.786     |\n",
      "|    explained_variance   | 0.0812     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.99       |\n",
      "|    n_updates            | 13790      |\n",
      "|    policy_gradient_loss | 0.00981    |\n",
      "|    value_loss           | 0.811      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 9981        |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| total_reward_steps      | 133         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025065102 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 0.285       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1382       |\n",
      "|    time_elapsed         | 9988       |\n",
      "|    total_timesteps      | 2830336    |\n",
      "| total_reward_steps      | 87         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03351873 |\n",
      "|    clip_fraction        | 0.477      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.802     |\n",
      "|    explained_variance   | 0.196      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.32       |\n",
      "|    n_updates            | 13810      |\n",
      "|    policy_gradient_loss | 0.00788    |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1383        |\n",
      "|    time_elapsed         | 9995        |\n",
      "|    total_timesteps      | 2832384     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030549739 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 13820       |\n",
      "|    policy_gradient_loss | 0.00116     |\n",
      "|    value_loss           | 1.82        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1384        |\n",
      "|    time_elapsed         | 10002       |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036327448 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 13830       |\n",
      "|    policy_gradient_loss | 0.00658     |\n",
      "|    value_loss           | 0.881       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1385        |\n",
      "|    time_elapsed         | 10009       |\n",
      "|    total_timesteps      | 2836480     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050428595 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1386        |\n",
      "|    time_elapsed         | 10015       |\n",
      "|    total_timesteps      | 2838528     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027770497 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.217       |\n",
      "|    n_updates            | 13850       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1387       |\n",
      "|    time_elapsed         | 10022      |\n",
      "|    total_timesteps      | 2840576    |\n",
      "| total_reward_steps      | 116        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02912832 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.618     |\n",
      "|    explained_variance   | 0.151      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.92       |\n",
      "|    n_updates            | 13860      |\n",
      "|    policy_gradient_loss | 0.00924    |\n",
      "|    value_loss           | 7.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 10029       |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038970858 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0987      |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | 0.0091      |\n",
      "|    value_loss           | 2.64        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1389        |\n",
      "|    time_elapsed         | 10036       |\n",
      "|    total_timesteps      | 2844672     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020332254 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00326     |\n",
      "|    n_updates            | 13880       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1390        |\n",
      "|    time_elapsed         | 10043       |\n",
      "|    total_timesteps      | 2846720     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017017944 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0149      |\n",
      "|    n_updates            | 13890       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 10049       |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016564995 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.737      |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00452    |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1392        |\n",
      "|    time_elapsed         | 10056       |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016349858 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.013       |\n",
      "|    n_updates            | 13910       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 10063       |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022935966 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | 0.000687    |\n",
      "|    value_loss           | 0.316       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 10070       |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020967282 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00887     |\n",
      "|    n_updates            | 13930       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1395        |\n",
      "|    time_elapsed         | 10077       |\n",
      "|    total_timesteps      | 2856960     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017460175 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0899      |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1396       |\n",
      "|    time_elapsed         | 10083      |\n",
      "|    total_timesteps      | 2859008    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01255645 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.809     |\n",
      "|    explained_variance   | 0.802      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.024     |\n",
      "|    n_updates            | 13950      |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1397        |\n",
      "|    time_elapsed         | 10090       |\n",
      "|    total_timesteps      | 2861056     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014661434 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 13960       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.0955      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 10097       |\n",
      "|    total_timesteps      | 2863104     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017369282 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.0905      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00486     |\n",
      "|    n_updates            | 13970       |\n",
      "|    policy_gradient_loss | 0.000211    |\n",
      "|    value_loss           | 4.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1399        |\n",
      "|    time_elapsed         | 10104       |\n",
      "|    total_timesteps      | 2865152     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015770132 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00278     |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1400       |\n",
      "|    time_elapsed         | 10111      |\n",
      "|    total_timesteps      | 2867200    |\n",
      "| total_reward_steps      | 63         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01491159 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.76      |\n",
      "|    explained_variance   | 0.442      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0641     |\n",
      "|    n_updates            | 13990      |\n",
      "|    policy_gradient_loss | -0.00992   |\n",
      "|    value_loss           | 0.148      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 10117       |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013342169 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.077       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1402        |\n",
      "|    time_elapsed         | 10124       |\n",
      "|    total_timesteps      | 2871296     |\n",
      "| total_reward_steps      | 166         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040099412 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.188       |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | 0.0177      |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1403       |\n",
      "|    time_elapsed         | 10131      |\n",
      "|    total_timesteps      | 2873344    |\n",
      "| total_reward_steps      | 76         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02007372 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.823     |\n",
      "|    explained_variance   | 0.473      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.121      |\n",
      "|    n_updates            | 14020      |\n",
      "|    policy_gradient_loss | 0.00228    |\n",
      "|    value_loss           | 1.28       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1404       |\n",
      "|    time_elapsed         | 10138      |\n",
      "|    total_timesteps      | 2875392    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01281568 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.841     |\n",
      "|    explained_variance   | 0.822      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0202     |\n",
      "|    n_updates            | 14030      |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 10145       |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017288327 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 10151       |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016755499 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00278     |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.132       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1407        |\n",
      "|    time_elapsed         | 10158       |\n",
      "|    total_timesteps      | 2881536     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018504757 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 14060       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1408       |\n",
      "|    time_elapsed         | 10165      |\n",
      "|    total_timesteps      | 2883584    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01732637 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.838     |\n",
      "|    explained_variance   | 0.841      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.013     |\n",
      "|    n_updates            | 14070      |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 0.105      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1409        |\n",
      "|    time_elapsed         | 10171       |\n",
      "|    total_timesteps      | 2885632     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014904752 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.818       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0056     |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0994      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 10177       |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015120048 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.931      |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.0949      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1411        |\n",
      "|    time_elapsed         | 10184       |\n",
      "|    total_timesteps      | 2889728     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016108733 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.097       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 1412       |\n",
      "|    time_elapsed         | 10190      |\n",
      "|    total_timesteps      | 2891776    |\n",
      "| total_reward_steps      | 88         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02172864 |\n",
      "|    clip_fraction        | 0.422      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.395      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0216     |\n",
      "|    n_updates            | 14110      |\n",
      "|    policy_gradient_loss | -0.00871   |\n",
      "|    value_loss           | 0.59       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 10197       |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039309926 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0025      |\n",
      "|    n_updates            | 14120       |\n",
      "|    policy_gradient_loss | 0.00323     |\n",
      "|    value_loss           | 0.643       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1414        |\n",
      "|    time_elapsed         | 10204       |\n",
      "|    total_timesteps      | 2895872     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021187656 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0557      |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.098       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 10211       |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021670736 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.888      |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0767      |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 10218       |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026488053 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=76.63 +/- 20.22\n",
      "Episode length: 1226.17 +/- 93.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.23e+03    |\n",
      "|    mean_reward          | 76.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027800072 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0117     |\n",
      "|    n_updates            | 14160       |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 282      |\n",
      "|    iterations      | 1417     |\n",
      "|    time_elapsed    | 10271    |\n",
      "|    total_timesteps | 2902016  |\n",
      "| total_reward_steps | 57       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 10278       |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033511847 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 14170       |\n",
      "|    policy_gradient_loss | 0.00686     |\n",
      "|    value_loss           | 0.628       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1419        |\n",
      "|    time_elapsed         | 10286       |\n",
      "|    total_timesteps      | 2906112     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041851245 |\n",
      "|    clip_fraction        | 0.446       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | 0.00861     |\n",
      "|    value_loss           | 3.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 10293       |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033947866 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.918      |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0512      |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    value_loss           | 0.748       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1421        |\n",
      "|    time_elapsed         | 10300       |\n",
      "|    total_timesteps      | 2910208     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016839772 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 10307       |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020950891 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 10314       |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| total_reward_steps      | 189         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035185073 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | 0.196       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1424        |\n",
      "|    time_elapsed         | 10323       |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027004436 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.0807      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | 0.0219      |\n",
      "|    value_loss           | 5.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 10331       |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028771535 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.253       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 14240       |\n",
      "|    policy_gradient_loss | 0.00774     |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1426        |\n",
      "|    time_elapsed         | 10339       |\n",
      "|    total_timesteps      | 2920448     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015352345 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0123      |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | 0.00457     |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 10348       |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018021286 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00253    |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00914    |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 10356       |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035720088 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00643    |\n",
      "|    n_updates            | 14270       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    value_loss           | 0.367       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1429       |\n",
      "|    time_elapsed         | 10364      |\n",
      "|    total_timesteps      | 2926592    |\n",
      "| total_reward_steps      | 38         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23128048 |\n",
      "|    clip_fraction        | 0.64       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.994     |\n",
      "|    explained_variance   | 0.0305     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 14280      |\n",
      "|    policy_gradient_loss | 0.0667     |\n",
      "|    value_loss           | 55.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1430       |\n",
      "|    time_elapsed         | 10372      |\n",
      "|    total_timesteps      | 2928640    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.45052212 |\n",
      "|    clip_fraction        | 0.617      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.614     |\n",
      "|    explained_variance   | 0.169      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.25       |\n",
      "|    n_updates            | 14290      |\n",
      "|    policy_gradient_loss | 0.0789     |\n",
      "|    value_loss           | 42.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1431        |\n",
      "|    time_elapsed         | 10380       |\n",
      "|    total_timesteps      | 2930688     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061085984 |\n",
      "|    clip_fraction        | 0.477       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | -0.298      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | 0.0186      |\n",
      "|    value_loss           | 0.475       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 10389       |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024542263 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 14310       |\n",
      "|    policy_gradient_loss | 0.0027      |\n",
      "|    value_loss           | 0.268       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1433       |\n",
      "|    time_elapsed         | 10397      |\n",
      "|    total_timesteps      | 2934784    |\n",
      "| total_reward_steps      | 67         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06016331 |\n",
      "|    clip_fraction        | 0.461      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.684     |\n",
      "|    explained_variance   | -0.347     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.335      |\n",
      "|    n_updates            | 14320      |\n",
      "|    policy_gradient_loss | 0.0267     |\n",
      "|    value_loss           | 2.79       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1434        |\n",
      "|    time_elapsed         | 10405       |\n",
      "|    total_timesteps      | 2936832     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023798719 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0805      |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | 0.0032      |\n",
      "|    value_loss           | 0.192       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 10414       |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026739545 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0956      |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1436        |\n",
      "|    time_elapsed         | 10422       |\n",
      "|    total_timesteps      | 2940928     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020082155 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1437       |\n",
      "|    time_elapsed         | 10430      |\n",
      "|    total_timesteps      | 2942976    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03275886 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.803     |\n",
      "|    explained_variance   | 0.168      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.165      |\n",
      "|    n_updates            | 14360      |\n",
      "|    policy_gradient_loss | -0.00134   |\n",
      "|    value_loss           | 0.598      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1438        |\n",
      "|    time_elapsed         | 10438       |\n",
      "|    total_timesteps      | 2945024     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014964917 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1439        |\n",
      "|    time_elapsed         | 10446       |\n",
      "|    total_timesteps      | 2947072     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014517285 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0193      |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 10454       |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014274117 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0971      |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1441        |\n",
      "|    time_elapsed         | 10461       |\n",
      "|    total_timesteps      | 2951168     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015562606 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 10469       |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018548885 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0644      |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1443        |\n",
      "|    time_elapsed         | 10477       |\n",
      "|    total_timesteps      | 2955264     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030156031 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0755      |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 10485       |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017173504 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 1445       |\n",
      "|    time_elapsed         | 10493      |\n",
      "|    total_timesteps      | 2959360    |\n",
      "| total_reward_steps      | 43         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02079221 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.866     |\n",
      "|    explained_variance   | 0.133      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.182      |\n",
      "|    n_updates            | 14440      |\n",
      "|    policy_gradient_loss | 0.00154    |\n",
      "|    value_loss           | 0.918      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1446        |\n",
      "|    time_elapsed         | 10501       |\n",
      "|    total_timesteps      | 2961408     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015048025 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.027       |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 10509       |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017880283 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0159     |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1448        |\n",
      "|    time_elapsed         | 10518       |\n",
      "|    total_timesteps      | 2965504     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021162467 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.201       |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    value_loss           | 0.733       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 10526       |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014530803 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.922      |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0652      |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1450        |\n",
      "|    time_elapsed         | 10534       |\n",
      "|    total_timesteps      | 2969600     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019370716 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.077       |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    value_loss           | 0.718       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1451        |\n",
      "|    time_elapsed         | 10542       |\n",
      "|    total_timesteps      | 2971648     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016462002 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 10550       |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016330931 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.084       |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    value_loss           | 0.397       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1453        |\n",
      "|    time_elapsed         | 10558       |\n",
      "|    total_timesteps      | 2975744     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015069881 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0823      |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 1454       |\n",
      "|    time_elapsed         | 10567      |\n",
      "|    total_timesteps      | 2977792    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01604557 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.965     |\n",
      "|    explained_variance   | 0.811      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.012      |\n",
      "|    n_updates            | 14530      |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 10575       |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017794026 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.818      |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 14540       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 1456       |\n",
      "|    time_elapsed         | 10583      |\n",
      "|    total_timesteps      | 2981888    |\n",
      "| total_reward_steps      | 52         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01201029 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.953     |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00966   |\n",
      "|    n_updates            | 14550      |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 0.109      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 10591       |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016052747 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 10600       |\n",
      "|    total_timesteps      | 2985984     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016677584 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 0.0959      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 10608       |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014817283 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0197      |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1460        |\n",
      "|    time_elapsed         | 10617       |\n",
      "|    total_timesteps      | 2990080     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019082084 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0288      |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 10625       |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012507653 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00604     |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 10634       |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014955435 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 1463        |\n",
      "|    time_elapsed         | 10642       |\n",
      "|    total_timesteps      | 2996224     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013547516 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 14620       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 1464       |\n",
      "|    time_elapsed         | 10650      |\n",
      "|    total_timesteps      | 2998272    |\n",
      "| total_reward_steps      | 92         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01669882 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.937     |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00733   |\n",
      "|    n_updates            | 14630      |\n",
      "|    policy_gradient_loss | -0.0133    |\n",
      "|    value_loss           | 0.127      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=68.40 +/- 10.13\n",
      "Episode length: 1003.23 +/- 154.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | 68.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000000     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020742856 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 14640       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    value_loss           | 0.667       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 280     |\n",
      "|    iterations      | 1465    |\n",
      "|    time_elapsed    | 10701   |\n",
      "|    total_timesteps | 3000320 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 10710       |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020481303 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000243   |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 10717       |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016458824 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00929     |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.428       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1468        |\n",
      "|    time_elapsed         | 10724       |\n",
      "|    total_timesteps      | 3006464     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020755824 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.856      |\n",
      "|    explained_variance   | 0.575       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 10733       |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018776227 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000514   |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1470       |\n",
      "|    time_elapsed         | 10741      |\n",
      "|    total_timesteps      | 3010560    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01870453 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.867     |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0578     |\n",
      "|    n_updates            | 14690      |\n",
      "|    policy_gradient_loss | -0.00704   |\n",
      "|    value_loss           | 0.656      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 10748       |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013619231 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0348     |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 10756       |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| total_reward_steps      | 216         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017051015 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00274     |\n",
      "|    n_updates            | 14710       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.523       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1473        |\n",
      "|    time_elapsed         | 10764       |\n",
      "|    total_timesteps      | 3016704     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.114075646 |\n",
      "|    clip_fraction        | 0.505       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | 0.08        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 14720       |\n",
      "|    policy_gradient_loss | 0.0344      |\n",
      "|    value_loss           | 12.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1474       |\n",
      "|    time_elapsed         | 10772      |\n",
      "|    total_timesteps      | 3018752    |\n",
      "| total_reward_steps      | 42         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03015246 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.758     |\n",
      "|    explained_variance   | 0.488      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0277     |\n",
      "|    n_updates            | 14730      |\n",
      "|    policy_gradient_loss | -0.00045   |\n",
      "|    value_loss           | 0.196      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1475        |\n",
      "|    time_elapsed         | 10781       |\n",
      "|    total_timesteps      | 3020800     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021013588 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.849      |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 10789       |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021452695 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0439      |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    value_loss           | 0.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 10797       |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017731957 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.148       |\n",
      "|    n_updates            | 14760       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1478       |\n",
      "|    time_elapsed         | 10805      |\n",
      "|    total_timesteps      | 3026944    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06895106 |\n",
      "|    clip_fraction        | 0.49       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.807     |\n",
      "|    explained_variance   | 0.144      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 18.8       |\n",
      "|    n_updates            | 14770      |\n",
      "|    policy_gradient_loss | 0.0196     |\n",
      "|    value_loss           | 3.21       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1479       |\n",
      "|    time_elapsed         | 10814      |\n",
      "|    total_timesteps      | 3028992    |\n",
      "| total_reward_steps      | 49         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03158854 |\n",
      "|    clip_fraction        | 0.471      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | 0.0649     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0378     |\n",
      "|    n_updates            | 14780      |\n",
      "|    policy_gradient_loss | 0.00321    |\n",
      "|    value_loss           | 0.198      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 1480        |\n",
      "|    time_elapsed         | 10822       |\n",
      "|    total_timesteps      | 3031040     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017142415 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.164       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 14790       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 0.171       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 280        |\n",
      "|    iterations           | 1481       |\n",
      "|    time_elapsed         | 10830      |\n",
      "|    total_timesteps      | 3033088    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01970263 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.811     |\n",
      "|    explained_variance   | 0.706      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00818    |\n",
      "|    n_updates            | 14800      |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 1482      |\n",
      "|    time_elapsed         | 10838     |\n",
      "|    total_timesteps      | 3035136   |\n",
      "| total_reward_steps      | 68        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0228531 |\n",
      "|    clip_fraction        | 0.356     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.847    |\n",
      "|    explained_variance   | 0.714     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | -0.00365  |\n",
      "|    n_updates            | 14810     |\n",
      "|    policy_gradient_loss | -0.00929  |\n",
      "|    value_loss           | 0.12      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1483        |\n",
      "|    time_elapsed         | 10847       |\n",
      "|    total_timesteps      | 3037184     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014371449 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.72       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0048      |\n",
      "|    n_updates            | 14820       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1484       |\n",
      "|    time_elapsed         | 10855      |\n",
      "|    total_timesteps      | 3039232    |\n",
      "| total_reward_steps      | 60         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01605066 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.837     |\n",
      "|    explained_variance   | 0.682      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0331     |\n",
      "|    n_updates            | 14830      |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    value_loss           | 0.117      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 279          |\n",
      "|    iterations           | 1485         |\n",
      "|    time_elapsed         | 10863        |\n",
      "|    total_timesteps      | 3041280      |\n",
      "| total_reward_steps      | 57           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0141530465 |\n",
      "|    clip_fraction        | 0.336        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.907       |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00595     |\n",
      "|    n_updates            | 14840        |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    value_loss           | 0.0968       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1486        |\n",
      "|    time_elapsed         | 10872       |\n",
      "|    total_timesteps      | 3043328     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375463 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.06        |\n",
      "|    n_updates            | 14850       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    value_loss           | 0.662       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1487        |\n",
      "|    time_elapsed         | 10880       |\n",
      "|    total_timesteps      | 3045376     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015933951 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0129      |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 10888       |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019103285 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 10896       |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012686153 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.81       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0658      |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1490       |\n",
      "|    time_elapsed         | 10905      |\n",
      "|    total_timesteps      | 3051520    |\n",
      "| total_reward_steps      | 87         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09943154 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.739     |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.4        |\n",
      "|    n_updates            | 14890      |\n",
      "|    policy_gradient_loss | 0.0167     |\n",
      "|    value_loss           | 3.21       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 1491      |\n",
      "|    time_elapsed         | 10913     |\n",
      "|    total_timesteps      | 3053568   |\n",
      "| total_reward_steps      | 61        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0321035 |\n",
      "|    clip_fraction        | 0.394     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.709    |\n",
      "|    explained_variance   | 0.0635    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.113     |\n",
      "|    n_updates            | 14900     |\n",
      "|    policy_gradient_loss | 0.0122    |\n",
      "|    value_loss           | 0.612     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1492        |\n",
      "|    time_elapsed         | 10921       |\n",
      "|    total_timesteps      | 3055616     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027309824 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | -0.404      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 14910       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    value_loss           | 0.557       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 10930       |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022932857 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.291       |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 0.48        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1494       |\n",
      "|    time_elapsed         | 10938      |\n",
      "|    total_timesteps      | 3059712    |\n",
      "| total_reward_steps      | 78         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02349546 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.58      |\n",
      "|    explained_variance   | 0.0673     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.255      |\n",
      "|    n_updates            | 14930      |\n",
      "|    policy_gradient_loss | 0.00933    |\n",
      "|    value_loss           | 2.38       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1495        |\n",
      "|    time_elapsed         | 10946       |\n",
      "|    total_timesteps      | 3061760     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018153438 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 10955       |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032156006 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.23        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    value_loss           | 1.79        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1497       |\n",
      "|    time_elapsed         | 10963      |\n",
      "|    total_timesteps      | 3065856    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02241881 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0504     |\n",
      "|    n_updates            | 14960      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1498       |\n",
      "|    time_elapsed         | 10972      |\n",
      "|    total_timesteps      | 3067904    |\n",
      "| total_reward_steps      | 47         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10027073 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.461     |\n",
      "|    explained_variance   | 0.0771     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.12       |\n",
      "|    n_updates            | 14970      |\n",
      "|    policy_gradient_loss | 0.0291     |\n",
      "|    value_loss           | 12.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 10980       |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029755786 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0451      |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 0.249       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1500        |\n",
      "|    time_elapsed         | 10988       |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026381377 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0357      |\n",
      "|    n_updates            | 14990       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 10997       |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029469628 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.708      |\n",
      "|    explained_variance   | 0.343       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00598     |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | -0.00884    |\n",
      "|    value_loss           | 0.145       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 11005       |\n",
      "|    total_timesteps      | 3076096     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046215147 |\n",
      "|    clip_fraction        | 0.44        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.17        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.74        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | 0.00762     |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 11013       |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028637938 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.0793      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.758       |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    value_loss           | 7.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1504        |\n",
      "|    time_elapsed         | 11022       |\n",
      "|    total_timesteps      | 3080192     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025510568 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.248       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.000366   |\n",
      "|    value_loss           | 0.517       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 11030       |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015310839 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.144       |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 11038       |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021568269 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.607      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.00878    |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1507        |\n",
      "|    time_elapsed         | 11046       |\n",
      "|    total_timesteps      | 3086336     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019367848 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0565      |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 11054       |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| total_reward_steps      | 113         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019087791 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0908      |\n",
      "|    n_updates            | 15070       |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1509       |\n",
      "|    time_elapsed         | 11060      |\n",
      "|    total_timesteps      | 3090432    |\n",
      "| total_reward_steps      | 215        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19202125 |\n",
      "|    clip_fraction        | 0.451      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.516     |\n",
      "|    explained_variance   | -0.324     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.238      |\n",
      "|    n_updates            | 15080      |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    value_loss           | 2.71       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1510       |\n",
      "|    time_elapsed         | 11067      |\n",
      "|    total_timesteps      | 3092480    |\n",
      "| total_reward_steps      | 27         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08197061 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.474     |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 78.7       |\n",
      "|    n_updates            | 15090      |\n",
      "|    policy_gradient_loss | 0.0306     |\n",
      "|    value_loss           | 9.52       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 11074       |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028682502 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 14.6        |\n",
      "|    n_updates            | 15100       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1512       |\n",
      "|    time_elapsed         | 11081      |\n",
      "|    total_timesteps      | 3096576    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04815997 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.486     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.837      |\n",
      "|    n_updates            | 15110      |\n",
      "|    policy_gradient_loss | 0.0151     |\n",
      "|    value_loss           | 7.49       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1513       |\n",
      "|    time_elapsed         | 11088      |\n",
      "|    total_timesteps      | 3098624    |\n",
      "| total_reward_steps      | 117        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04083749 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.538     |\n",
      "|    explained_variance   | -0.192     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0981     |\n",
      "|    n_updates            | 15120      |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    value_loss           | 1.02       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=48.53 +/- 15.37\n",
      "Episode length: 711.60 +/- 90.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 712         |\n",
      "|    mean_reward          | 48.5        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3100000     |\n",
      "| total_reward_steps      | 121         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045555107 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.4        |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.402       |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | 0.00951     |\n",
      "|    value_loss           | 1.7         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1514     |\n",
      "|    time_elapsed    | 11122    |\n",
      "|    total_timesteps | 3100672  |\n",
      "| total_reward_steps | 45       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 11129       |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019037465 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 0.434       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1516        |\n",
      "|    time_elapsed         | 11136       |\n",
      "|    total_timesteps      | 3104768     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049633563 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 15150       |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1517        |\n",
      "|    time_elapsed         | 11143       |\n",
      "|    total_timesteps      | 3106816     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013688687 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.292       |\n",
      "|    n_updates            | 15160       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1518        |\n",
      "|    time_elapsed         | 11150       |\n",
      "|    total_timesteps      | 3108864     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024384271 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 15170       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 0.528       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1519        |\n",
      "|    time_elapsed         | 11157       |\n",
      "|    total_timesteps      | 3110912     |\n",
      "| total_reward_steps      | 152         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022781841 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0016     |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | 0.00627     |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 11164       |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031171959 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 15190       |\n",
      "|    policy_gradient_loss | 0.00451     |\n",
      "|    value_loss           | 2.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1521        |\n",
      "|    time_elapsed         | 11171       |\n",
      "|    total_timesteps      | 3115008     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018849421 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.493      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0833      |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.000772   |\n",
      "|    value_loss           | 0.646       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 11178       |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| total_reward_steps      | 118         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018542051 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0593      |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 0.342       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1523       |\n",
      "|    time_elapsed         | 11185      |\n",
      "|    total_timesteps      | 3119104    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05063746 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.391     |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.106      |\n",
      "|    n_updates            | 15220      |\n",
      "|    policy_gradient_loss | 0.00243    |\n",
      "|    value_loss           | 1.32       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1524        |\n",
      "|    time_elapsed         | 11192       |\n",
      "|    total_timesteps      | 3121152     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024152279 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0607      |\n",
      "|    n_updates            | 15230       |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1525        |\n",
      "|    time_elapsed         | 11199       |\n",
      "|    total_timesteps      | 3123200     |\n",
      "| total_reward_steps      | 159         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014670462 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0777      |\n",
      "|    n_updates            | 15240       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1526       |\n",
      "|    time_elapsed         | 11206      |\n",
      "|    total_timesteps      | 3125248    |\n",
      "| total_reward_steps      | 124        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03194916 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.423     |\n",
      "|    explained_variance   | 0.589      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.45       |\n",
      "|    n_updates            | 15250      |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    value_loss           | 2.2        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 11213       |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019026913 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.75        |\n",
      "|    n_updates            | 15260       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1528        |\n",
      "|    time_elapsed         | 11219       |\n",
      "|    total_timesteps      | 3129344     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030904448 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.601      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00131    |\n",
      "|    n_updates            | 15270       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1529        |\n",
      "|    time_elapsed         | 11226       |\n",
      "|    total_timesteps      | 3131392     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015988315 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 11233       |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| total_reward_steps      | 205         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024172308 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.527      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0507      |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    value_loss           | 0.86        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1531       |\n",
      "|    time_elapsed         | 11240      |\n",
      "|    total_timesteps      | 3135488    |\n",
      "| total_reward_steps      | 89         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08008227 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.617     |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.864      |\n",
      "|    n_updates            | 15300      |\n",
      "|    policy_gradient_loss | 0.0188     |\n",
      "|    value_loss           | 8.72       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1532       |\n",
      "|    time_elapsed         | 11247      |\n",
      "|    total_timesteps      | 3137536    |\n",
      "| total_reward_steps      | 45         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05843176 |\n",
      "|    clip_fraction        | 0.423      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.607     |\n",
      "|    explained_variance   | -0.00233   |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0779     |\n",
      "|    n_updates            | 15310      |\n",
      "|    policy_gradient_loss | 0.0177     |\n",
      "|    value_loss           | 2.33       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 11254       |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035160087 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.000768    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0656      |\n",
      "|    n_updates            | 15320       |\n",
      "|    policy_gradient_loss | 0.00263     |\n",
      "|    value_loss           | 0.237       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1534        |\n",
      "|    time_elapsed         | 11261       |\n",
      "|    total_timesteps      | 3141632     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023373127 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.553      |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 15330       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    value_loss           | 0.193       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 11268       |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| total_reward_steps      | 376         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033593364 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.609      |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | -0.00823    |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1536       |\n",
      "|    time_elapsed         | 11274      |\n",
      "|    total_timesteps      | 3145728    |\n",
      "| total_reward_steps      | 29         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18693893 |\n",
      "|    clip_fraction        | 0.437      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.407     |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.458      |\n",
      "|    n_updates            | 15350      |\n",
      "|    policy_gradient_loss | 0.0465     |\n",
      "|    value_loss           | 42         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 11281       |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027470764 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 15360       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 0.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 11288       |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019208066 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1539        |\n",
      "|    time_elapsed         | 11294       |\n",
      "|    total_timesteps      | 3151872     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023040246 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1540        |\n",
      "|    time_elapsed         | 11301       |\n",
      "|    total_timesteps      | 3153920     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026124243 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00864     |\n",
      "|    n_updates            | 15390       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 0.451       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1541        |\n",
      "|    time_elapsed         | 11307       |\n",
      "|    total_timesteps      | 3155968     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028838445 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.1         |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 0.153       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1542        |\n",
      "|    time_elapsed         | 11314       |\n",
      "|    total_timesteps      | 3158016     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019413058 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 15410       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1543       |\n",
      "|    time_elapsed         | 11320      |\n",
      "|    total_timesteps      | 3160064    |\n",
      "| total_reward_steps      | 355        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03047134 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.504     |\n",
      "|    explained_variance   | -0.133     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.135      |\n",
      "|    n_updates            | 15420      |\n",
      "|    policy_gradient_loss | 0.0178     |\n",
      "|    value_loss           | 2.13       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1544       |\n",
      "|    time_elapsed         | 11327      |\n",
      "|    total_timesteps      | 3162112    |\n",
      "| total_reward_steps      | 70         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12031865 |\n",
      "|    clip_fraction        | 0.426      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.465     |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.47       |\n",
      "|    n_updates            | 15430      |\n",
      "|    policy_gradient_loss | 0.0479     |\n",
      "|    value_loss           | 43.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1545        |\n",
      "|    time_elapsed         | 11334       |\n",
      "|    total_timesteps      | 3164160     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040420048 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0984      |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | 0.00461     |\n",
      "|    value_loss           | 0.765       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1546        |\n",
      "|    time_elapsed         | 11341       |\n",
      "|    total_timesteps      | 3166208     |\n",
      "| total_reward_steps      | 365         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035874747 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.541      |\n",
      "|    explained_variance   | -0.124      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 11347       |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055794094 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 15460       |\n",
      "|    policy_gradient_loss | 0.0168      |\n",
      "|    value_loss           | 29.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 1548      |\n",
      "|    time_elapsed         | 11354     |\n",
      "|    total_timesteps      | 3170304   |\n",
      "| total_reward_steps      | 42        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2721296 |\n",
      "|    clip_fraction        | 0.414     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.398    |\n",
      "|    explained_variance   | -0.209    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.437     |\n",
      "|    n_updates            | 15470     |\n",
      "|    policy_gradient_loss | 0.0325    |\n",
      "|    value_loss           | 12.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 11361       |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| total_reward_steps      | 364         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027035259 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    value_loss           | 0.182       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 11368       |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047356844 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    value_loss           | 28.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1551       |\n",
      "|    time_elapsed         | 11375      |\n",
      "|    total_timesteps      | 3176448    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07038484 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.351     |\n",
      "|    explained_variance   | -0.137     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.69       |\n",
      "|    n_updates            | 15500      |\n",
      "|    policy_gradient_loss | -0.00077   |\n",
      "|    value_loss           | 1.99       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 11381       |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017671049 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1553        |\n",
      "|    time_elapsed         | 11388       |\n",
      "|    total_timesteps      | 3180544     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029288065 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.78        |\n",
      "|    n_updates            | 15520       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 4.55        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 1554      |\n",
      "|    time_elapsed         | 11395     |\n",
      "|    total_timesteps      | 3182592   |\n",
      "| total_reward_steps      | 50        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0671872 |\n",
      "|    clip_fraction        | 0.272     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.431    |\n",
      "|    explained_variance   | 0.187     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.416     |\n",
      "|    n_updates            | 15530     |\n",
      "|    policy_gradient_loss | -0.00316  |\n",
      "|    value_loss           | 1.54      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 11402       |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026000261 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0664      |\n",
      "|    n_updates            | 15540       |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1556        |\n",
      "|    time_elapsed         | 11409       |\n",
      "|    total_timesteps      | 3186688     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024728244 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.097       |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 0.489       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1557        |\n",
      "|    time_elapsed         | 11415       |\n",
      "|    total_timesteps      | 3188736     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018457113 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.644      |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00544    |\n",
      "|    n_updates            | 15560       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1558       |\n",
      "|    time_elapsed         | 11422      |\n",
      "|    total_timesteps      | 3190784    |\n",
      "| total_reward_steps      | 119        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01838063 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.65      |\n",
      "|    explained_variance   | 0.794      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.182      |\n",
      "|    n_updates            | 15570      |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 0.0997     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 11429       |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057732888 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | -0.00163    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.208       |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    value_loss           | 8.65        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 11436       |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022315647 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 11443       |\n",
      "|    total_timesteps      | 3196928     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021472074 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.000619   |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 11449       |\n",
      "|    total_timesteps      | 3198976     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033561617 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.0102      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 15610       |\n",
      "|    policy_gradient_loss | 0.00834     |\n",
      "|    value_loss           | 0.508       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=77.03 +/- 51.48\n",
      "Episode length: 817.37 +/- 104.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 817         |\n",
      "|    mean_reward          | 77          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3200000     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017744325 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 15620       |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1563     |\n",
      "|    time_elapsed    | 11487    |\n",
      "|    total_timesteps | 3201024  |\n",
      "| total_reward_steps | 69       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 11494       |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| total_reward_steps      | 465         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018508743 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1565       |\n",
      "|    time_elapsed         | 11501      |\n",
      "|    total_timesteps      | 3205120    |\n",
      "| total_reward_steps      | 35         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.29335213 |\n",
      "|    clip_fraction        | 0.556      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.565     |\n",
      "|    explained_variance   | 0.0369     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 269        |\n",
      "|    n_updates            | 15640      |\n",
      "|    policy_gradient_loss | 0.0919     |\n",
      "|    value_loss           | 67.7       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1566       |\n",
      "|    time_elapsed         | 11507      |\n",
      "|    total_timesteps      | 3207168    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04810689 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.442     |\n",
      "|    explained_variance   | 0.067      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.301      |\n",
      "|    n_updates            | 15650      |\n",
      "|    policy_gradient_loss | 0.0304     |\n",
      "|    value_loss           | 2.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 11514       |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049775936 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | -0.000728   |\n",
      "|    value_loss           | 0.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1568        |\n",
      "|    time_elapsed         | 11521       |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| total_reward_steps      | 119         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052159406 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | -0.0204     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.104       |\n",
      "|    n_updates            | 15670       |\n",
      "|    policy_gradient_loss | 0.0018      |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 11528       |\n",
      "|    total_timesteps      | 3213312     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029489286 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.274       |\n",
      "|    n_updates            | 15680       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    value_loss           | 2.24        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1570       |\n",
      "|    time_elapsed         | 11535      |\n",
      "|    total_timesteps      | 3215360    |\n",
      "| total_reward_steps      | 22         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03139521 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.508     |\n",
      "|    explained_variance   | 0.495      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0854     |\n",
      "|    n_updates            | 15690      |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    value_loss           | 1.06       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1571       |\n",
      "|    time_elapsed         | 11541      |\n",
      "|    total_timesteps      | 3217408    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02000019 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.468     |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0924     |\n",
      "|    n_updates            | 15700      |\n",
      "|    policy_gradient_loss | -0.00222   |\n",
      "|    value_loss           | 0.25       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1572        |\n",
      "|    time_elapsed         | 11548       |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029643696 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.794      |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 15710       |\n",
      "|    policy_gradient_loss | 0.00882     |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1573        |\n",
      "|    time_elapsed         | 11554       |\n",
      "|    total_timesteps      | 3221504     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029340256 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00743     |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1574        |\n",
      "|    time_elapsed         | 11560       |\n",
      "|    total_timesteps      | 3223552     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017319992 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.774      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0502      |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00876    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1575       |\n",
      "|    time_elapsed         | 11567      |\n",
      "|    total_timesteps      | 3225600    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03195216 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.677     |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 15740      |\n",
      "|    policy_gradient_loss | 0.00609    |\n",
      "|    value_loss           | 0.44       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 11573       |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| total_reward_steps      | 21          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020031558 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00498     |\n",
      "|    n_updates            | 15750       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 0.161       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1577        |\n",
      "|    time_elapsed         | 11580       |\n",
      "|    total_timesteps      | 3229696     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022978105 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1578        |\n",
      "|    time_elapsed         | 11587       |\n",
      "|    total_timesteps      | 3231744     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016911756 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00105     |\n",
      "|    n_updates            | 15770       |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    value_loss           | 0.686       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1579        |\n",
      "|    time_elapsed         | 11594       |\n",
      "|    total_timesteps      | 3233792     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019513994 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0624      |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1580       |\n",
      "|    time_elapsed         | 11600      |\n",
      "|    total_timesteps      | 3235840    |\n",
      "| total_reward_steps      | 80         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09408994 |\n",
      "|    clip_fraction        | 0.505      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.639     |\n",
      "|    explained_variance   | 0.0195     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 9.27       |\n",
      "|    n_updates            | 15790      |\n",
      "|    policy_gradient_loss | 0.0278     |\n",
      "|    value_loss           | 31.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 11607       |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029498838 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0794      |\n",
      "|    n_updates            | 15800       |\n",
      "|    policy_gradient_loss | -0.000149   |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 11614       |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026294816 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 15810       |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1583       |\n",
      "|    time_elapsed         | 11621      |\n",
      "|    total_timesteps      | 3241984    |\n",
      "| total_reward_steps      | 40         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02244018 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.709     |\n",
      "|    explained_variance   | 0.53       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0501     |\n",
      "|    n_updates            | 15820      |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 0.139      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1584        |\n",
      "|    time_elapsed         | 11627       |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025308173 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.597      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0694      |\n",
      "|    n_updates            | 15830       |\n",
      "|    policy_gradient_loss | -0.00887    |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1585        |\n",
      "|    time_elapsed         | 11634       |\n",
      "|    total_timesteps      | 3246080     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025876852 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00667     |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1586        |\n",
      "|    time_elapsed         | 11641       |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015243441 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.225       |\n",
      "|    n_updates            | 15850       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1587       |\n",
      "|    time_elapsed         | 11648      |\n",
      "|    total_timesteps      | 3250176    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612113 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.733     |\n",
      "|    explained_variance   | 0.686      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0191     |\n",
      "|    n_updates            | 15860      |\n",
      "|    policy_gradient_loss | -0.00728   |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 11655       |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017950138 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00979     |\n",
      "|    n_updates            | 15870       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0984      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 11662       |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019088842 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0545      |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1590        |\n",
      "|    time_elapsed         | 11668       |\n",
      "|    total_timesteps      | 3256320     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015869062 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 11675       |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024232838 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 15900       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1592        |\n",
      "|    time_elapsed         | 11682       |\n",
      "|    total_timesteps      | 3260416     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932203 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00783     |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 0.093       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1593       |\n",
      "|    time_elapsed         | 11689      |\n",
      "|    total_timesteps      | 3262464    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01306463 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.672     |\n",
      "|    explained_variance   | 0.791      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0614     |\n",
      "|    n_updates            | 15920      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.125      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1594       |\n",
      "|    time_elapsed         | 11696      |\n",
      "|    total_timesteps      | 3264512    |\n",
      "| total_reward_steps      | 58         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01851958 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.659     |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0249    |\n",
      "|    n_updates            | 15930      |\n",
      "|    policy_gradient_loss | -0.00956   |\n",
      "|    value_loss           | 0.108      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1595        |\n",
      "|    time_elapsed         | 11702       |\n",
      "|    total_timesteps      | 3266560     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017491562 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0039      |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.0939      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 11709       |\n",
      "|    total_timesteps      | 3268608     |\n",
      "| total_reward_steps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018792935 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0267      |\n",
      "|    n_updates            | 15950       |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1597        |\n",
      "|    time_elapsed         | 11716       |\n",
      "|    total_timesteps      | 3270656     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024823405 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0236      |\n",
      "|    n_updates            | 15960       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 11723       |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022319771 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00131     |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1599       |\n",
      "|    time_elapsed         | 11730      |\n",
      "|    total_timesteps      | 3274752    |\n",
      "| total_reward_steps      | 71         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01745135 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.727     |\n",
      "|    explained_variance   | 0.812      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0792     |\n",
      "|    n_updates            | 15980      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.101      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1600        |\n",
      "|    time_elapsed         | 11736       |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017431792 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0575      |\n",
      "|    n_updates            | 15990       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1601       |\n",
      "|    time_elapsed         | 11743      |\n",
      "|    total_timesteps      | 3278848    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273983 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.615     |\n",
      "|    explained_variance   | 0.72       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0598     |\n",
      "|    n_updates            | 16000      |\n",
      "|    policy_gradient_loss | -0.00911   |\n",
      "|    value_loss           | 0.163      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1602        |\n",
      "|    time_elapsed         | 11750       |\n",
      "|    total_timesteps      | 3280896     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018839896 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0725      |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 0.471       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 11757       |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018891113 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0594      |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.0956      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 11764       |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013612635 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00802     |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.0843      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 11770       |\n",
      "|    total_timesteps      | 3287040     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023668934 |\n",
      "|    clip_fraction        | 0.407       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.58        |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    value_loss           | 7.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 11777       |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016951077 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | -0.474      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1607        |\n",
      "|    time_elapsed         | 11784       |\n",
      "|    total_timesteps      | 3291136     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011545234 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.81       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0174     |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1608       |\n",
      "|    time_elapsed         | 11790      |\n",
      "|    total_timesteps      | 3293184    |\n",
      "| total_reward_steps      | 63         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841118 |\n",
      "|    clip_fraction        | 0.298      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.702     |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0859     |\n",
      "|    n_updates            | 16070      |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    value_loss           | 0.0945     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1609        |\n",
      "|    time_elapsed         | 11797       |\n",
      "|    total_timesteps      | 3295232     |\n",
      "| total_reward_steps      | 214         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017072909 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0775      |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    value_loss           | 0.586       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1610       |\n",
      "|    time_elapsed         | 11803      |\n",
      "|    total_timesteps      | 3297280    |\n",
      "| total_reward_steps      | 139        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04305105 |\n",
      "|    clip_fraction        | 0.508      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.849     |\n",
      "|    explained_variance   | 0.0947     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.479      |\n",
      "|    n_updates            | 16090      |\n",
      "|    policy_gradient_loss | 0.0196     |\n",
      "|    value_loss           | 8.14       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1611       |\n",
      "|    time_elapsed         | 11810      |\n",
      "|    total_timesteps      | 3299328    |\n",
      "| total_reward_steps      | 45         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06926421 |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.601     |\n",
      "|    explained_variance   | 0.097      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 16100      |\n",
      "|    policy_gradient_loss | 0.0114     |\n",
      "|    value_loss           | 2.88       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=24.07 +/- 15.53\n",
      "Episode length: 562.17 +/- 178.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 562         |\n",
      "|    mean_reward          | 24.1        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3300000     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022215862 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0371      |\n",
      "|    n_updates            | 16110       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 0.157       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1612     |\n",
      "|    time_elapsed    | 11837    |\n",
      "|    total_timesteps | 3301376  |\n",
      "| total_reward_steps | 6        |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 11844       |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028908491 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 11850       |\n",
      "|    total_timesteps      | 3305472     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036482267 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0335      |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 11857       |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| total_reward_steps      | 18          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022156725 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | 0.00669     |\n",
      "|    value_loss           | 0.448       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 11864       |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020680409 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 16150       |\n",
      "|    policy_gradient_loss | -0.0091     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1617        |\n",
      "|    time_elapsed         | 11871       |\n",
      "|    total_timesteps      | 3311616     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017045137 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0516      |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.000224   |\n",
      "|    value_loss           | 0.558       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 11878       |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| total_reward_steps      | 155         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021862775 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    value_loss           | 0.144       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1619       |\n",
      "|    time_elapsed         | 11884      |\n",
      "|    total_timesteps      | 3315712    |\n",
      "| total_reward_steps      | 143        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03950822 |\n",
      "|    clip_fraction        | 0.45       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.131      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.114      |\n",
      "|    n_updates            | 16180      |\n",
      "|    policy_gradient_loss | 0.0137     |\n",
      "|    value_loss           | 2.52       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1620        |\n",
      "|    time_elapsed         | 11891       |\n",
      "|    total_timesteps      | 3317760     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059597388 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.549      |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 16190       |\n",
      "|    policy_gradient_loss | 0.0232      |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1621        |\n",
      "|    time_elapsed         | 11898       |\n",
      "|    total_timesteps      | 3319808     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029153062 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | -0.219      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 16200       |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    value_loss           | 0.177       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1622        |\n",
      "|    time_elapsed         | 11905       |\n",
      "|    total_timesteps      | 3321856     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019641723 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | -0.00958    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 11912       |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021731142 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0407      |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 0.554       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1624        |\n",
      "|    time_elapsed         | 11918       |\n",
      "|    total_timesteps      | 3325952     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020911157 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    value_loss           | 0.511       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 11925       |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020297794 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0417      |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 0.551       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1626        |\n",
      "|    time_elapsed         | 11932       |\n",
      "|    total_timesteps      | 3330048     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021261914 |\n",
      "|    clip_fraction        | 0.424       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.845      |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00612    |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.138       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1627       |\n",
      "|    time_elapsed         | 11939      |\n",
      "|    total_timesteps      | 3332096    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02050785 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.699     |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00704   |\n",
      "|    n_updates            | 16260      |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    value_loss           | 0.453      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 11945       |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016903067 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00537    |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1629        |\n",
      "|    time_elapsed         | 11952       |\n",
      "|    total_timesteps      | 3336192     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019415429 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1630       |\n",
      "|    time_elapsed         | 11959      |\n",
      "|    total_timesteps      | 3338240    |\n",
      "| total_reward_steps      | 83         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979469 |\n",
      "|    clip_fraction        | 0.355      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.765     |\n",
      "|    explained_variance   | 0.527      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0261     |\n",
      "|    n_updates            | 16290      |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1631        |\n",
      "|    time_elapsed         | 11966       |\n",
      "|    total_timesteps      | 3340288     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021903286 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 11972       |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017518528 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1633        |\n",
      "|    time_elapsed         | 11979       |\n",
      "|    total_timesteps      | 3344384     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020987066 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00315    |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1634        |\n",
      "|    time_elapsed         | 11986       |\n",
      "|    total_timesteps      | 3346432     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023076804 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 11993       |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013312971 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0378      |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0959      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1636        |\n",
      "|    time_elapsed         | 12000       |\n",
      "|    total_timesteps      | 3350528     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016268354 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00819     |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 1637      |\n",
      "|    time_elapsed         | 12006     |\n",
      "|    total_timesteps      | 3352576   |\n",
      "| total_reward_steps      | 62        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0167294 |\n",
      "|    clip_fraction        | 0.379     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.863    |\n",
      "|    explained_variance   | 0.726     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.114     |\n",
      "|    n_updates            | 16360     |\n",
      "|    policy_gradient_loss | -0.0157   |\n",
      "|    value_loss           | 0.0989    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 12013       |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014401963 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0366      |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.104       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 12020       |\n",
      "|    total_timesteps      | 3356672     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013087158 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0461      |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.0862      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1640        |\n",
      "|    time_elapsed         | 12027       |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018059071 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.00936    |\n",
      "|    value_loss           | 0.385       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1641       |\n",
      "|    time_elapsed         | 12034      |\n",
      "|    total_timesteps      | 3360768    |\n",
      "| total_reward_steps      | 82         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01979141 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.704     |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.163      |\n",
      "|    n_updates            | 16400      |\n",
      "|    policy_gradient_loss | -0.00321   |\n",
      "|    value_loss           | 0.6        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 12040       |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025031138 |\n",
      "|    clip_fraction        | 0.4         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.861      |\n",
      "|    explained_variance   | 0.468       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0608      |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 0.789       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1643        |\n",
      "|    time_elapsed         | 12047       |\n",
      "|    total_timesteps      | 3364864     |\n",
      "| total_reward_steps      | 126         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024698742 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00733     |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1644       |\n",
      "|    time_elapsed         | 12053      |\n",
      "|    total_timesteps      | 3366912    |\n",
      "| total_reward_steps      | 112        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11726551 |\n",
      "|    clip_fraction        | 0.445      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.564     |\n",
      "|    explained_variance   | 0.00777    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.205      |\n",
      "|    n_updates            | 16430      |\n",
      "|    policy_gradient_loss | 0.0378     |\n",
      "|    value_loss           | 13.5       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 1645      |\n",
      "|    time_elapsed         | 12059     |\n",
      "|    total_timesteps      | 3368960   |\n",
      "| total_reward_steps      | 75        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313142 |\n",
      "|    clip_fraction        | 0.398     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.663    |\n",
      "|    explained_variance   | 0.231     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.187     |\n",
      "|    n_updates            | 16440     |\n",
      "|    policy_gradient_loss | 0.00755   |\n",
      "|    value_loss           | 1.05      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1646        |\n",
      "|    time_elapsed         | 12066       |\n",
      "|    total_timesteps      | 3371008     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022755124 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | -0.00248    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0498      |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 12072       |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026536541 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0368      |\n",
      "|    n_updates            | 16460       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 0.687       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1648        |\n",
      "|    time_elapsed         | 12079       |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029054053 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | -0.241      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.000363   |\n",
      "|    value_loss           | 0.219       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 12085       |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023407355 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0886      |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    value_loss           | 0.434       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1650       |\n",
      "|    time_elapsed         | 12092      |\n",
      "|    total_timesteps      | 3379200    |\n",
      "| total_reward_steps      | 59         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01860005 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.855     |\n",
      "|    explained_variance   | 0.283      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 16490      |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 0.145      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1651        |\n",
      "|    time_elapsed         | 12099       |\n",
      "|    total_timesteps      | 3381248     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025705222 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.173       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.71        |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    value_loss           | 0.478       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 12105       |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022033416 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0198      |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1653       |\n",
      "|    time_elapsed         | 12112      |\n",
      "|    total_timesteps      | 3385344    |\n",
      "| total_reward_steps      | 67         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02038086 |\n",
      "|    clip_fraction        | 0.395      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.888     |\n",
      "|    explained_variance   | 0.52       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00182    |\n",
      "|    n_updates            | 16520      |\n",
      "|    policy_gradient_loss | -0.0143    |\n",
      "|    value_loss           | 0.128      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1654        |\n",
      "|    time_elapsed         | 12119       |\n",
      "|    total_timesteps      | 3387392     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021808602 |\n",
      "|    clip_fraction        | 0.391       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00333     |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    value_loss           | 0.422       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1655        |\n",
      "|    time_elapsed         | 12126       |\n",
      "|    total_timesteps      | 3389440     |\n",
      "| total_reward_steps      | 112         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026577145 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0208     |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1656        |\n",
      "|    time_elapsed         | 12133       |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030802406 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    value_loss           | 2.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 12139       |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023351908 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.122       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    value_loss           | 0.526       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1658        |\n",
      "|    time_elapsed         | 12146       |\n",
      "|    total_timesteps      | 3395584     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019110683 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0935      |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 0.367       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1659       |\n",
      "|    time_elapsed         | 12153      |\n",
      "|    total_timesteps      | 3397632    |\n",
      "| total_reward_steps      | 72         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01842243 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.87      |\n",
      "|    explained_variance   | 0.593      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 16580      |\n",
      "|    policy_gradient_loss | -0.00885   |\n",
      "|    value_loss           | 0.332      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1660        |\n",
      "|    time_elapsed         | 12160       |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019242687 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.164       |\n",
      "|    n_updates            | 16590       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=63.63 +/- 11.59\n",
      "Episode length: 949.07 +/- 115.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 949         |\n",
      "|    mean_reward          | 63.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015270084 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0282      |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.0977      |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 12202    |\n",
      "|    total_timesteps | 3401728  |\n",
      "| total_reward_steps | 70       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 12209       |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017837722 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.95       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.117       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1663        |\n",
      "|    time_elapsed         | 12215       |\n",
      "|    total_timesteps      | 3405824     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029656135 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.891      |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.218       |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    value_loss           | 0.556       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1664        |\n",
      "|    time_elapsed         | 12222       |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| total_reward_steps      | 208         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015617176 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0689      |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1665       |\n",
      "|    time_elapsed         | 12229      |\n",
      "|    total_timesteps      | 3409920    |\n",
      "| total_reward_steps      | 81         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08871868 |\n",
      "|    clip_fraction        | 0.499      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | 0.103      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 28.3       |\n",
      "|    n_updates            | 16640      |\n",
      "|    policy_gradient_loss | 0.0303     |\n",
      "|    value_loss           | 9.94       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1666        |\n",
      "|    time_elapsed         | 12236       |\n",
      "|    total_timesteps      | 3411968     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017395189 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 12243       |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029137813 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | -0.386      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0394      |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 2.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1668        |\n",
      "|    time_elapsed         | 12249       |\n",
      "|    total_timesteps      | 3416064     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017974121 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 12256       |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.067429736 |\n",
      "|    clip_fraction        | 0.477       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    value_loss           | 2.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1670        |\n",
      "|    time_elapsed         | 12263       |\n",
      "|    total_timesteps      | 3420160     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022239719 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0946      |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 0.395       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1671       |\n",
      "|    time_elapsed         | 12270      |\n",
      "|    total_timesteps      | 3422208    |\n",
      "| total_reward_steps      | 128        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02837849 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.773     |\n",
      "|    explained_variance   | 0.546      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.271      |\n",
      "|    n_updates            | 16700      |\n",
      "|    policy_gradient_loss | -0.00343   |\n",
      "|    value_loss           | 0.694      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 12276       |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039024796 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.677      |\n",
      "|    explained_variance   | 0.209       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0332      |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | 0.00618     |\n",
      "|    value_loss           | 2.08        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1673       |\n",
      "|    time_elapsed         | 12283      |\n",
      "|    total_timesteps      | 3426304    |\n",
      "| total_reward_steps      | 214        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03201036 |\n",
      "|    clip_fraction        | 0.407      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.798     |\n",
      "|    explained_variance   | 0.0943     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0227     |\n",
      "|    n_updates            | 16720      |\n",
      "|    policy_gradient_loss | -0.00162   |\n",
      "|    value_loss           | 0.337      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 278      |\n",
      "|    iterations           | 1674     |\n",
      "|    time_elapsed         | 12290    |\n",
      "|    total_timesteps      | 3428352  |\n",
      "| total_reward_steps      | 68       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.073062 |\n",
      "|    clip_fraction        | 0.413    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.682   |\n",
      "|    explained_variance   | 0.146    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 11.6     |\n",
      "|    n_updates            | 16730    |\n",
      "|    policy_gradient_loss | 0.0187   |\n",
      "|    value_loss           | 12.8     |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1675       |\n",
      "|    time_elapsed         | 12296      |\n",
      "|    total_timesteps      | 3430400    |\n",
      "| total_reward_steps      | 90         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05545206 |\n",
      "|    clip_fraction        | 0.438      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.666     |\n",
      "|    explained_variance   | -0.0229    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.235      |\n",
      "|    n_updates            | 16740      |\n",
      "|    policy_gradient_loss | 0.018      |\n",
      "|    value_loss           | 16.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1676       |\n",
      "|    time_elapsed         | 12303      |\n",
      "|    total_timesteps      | 3432448    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04015097 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.756     |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.039      |\n",
      "|    n_updates            | 16750      |\n",
      "|    policy_gradient_loss | 0.00163    |\n",
      "|    value_loss           | 0.194      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1677       |\n",
      "|    time_elapsed         | 12309      |\n",
      "|    total_timesteps      | 3434496    |\n",
      "| total_reward_steps      | 35         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04203818 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.632     |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0814     |\n",
      "|    n_updates            | 16760      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    value_loss           | 2.18       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1678        |\n",
      "|    time_elapsed         | 12316       |\n",
      "|    total_timesteps      | 3436544     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023582043 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00614     |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 12322       |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016140353 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.698      |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1680        |\n",
      "|    time_elapsed         | 12328       |\n",
      "|    total_timesteps      | 3440640     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016158914 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.675      |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00656     |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 12335       |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| total_reward_steps      | 131         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034026094 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0422      |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    value_loss           | 2.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 12342       |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016999511 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | 0.00408     |\n",
      "|    value_loss           | 1.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1683        |\n",
      "|    time_elapsed         | 12349       |\n",
      "|    total_timesteps      | 3446784     |\n",
      "| total_reward_steps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019626847 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.598      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0936      |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 12355       |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064868875 |\n",
      "|    clip_fraction        | 0.443       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.635      |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.064       |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | 0.0231      |\n",
      "|    value_loss           | 8.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1685        |\n",
      "|    time_elapsed         | 12362       |\n",
      "|    total_timesteps      | 3450880     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020008408 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.582      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0298      |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    value_loss           | 0.435       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1686       |\n",
      "|    time_elapsed         | 12369      |\n",
      "|    total_timesteps      | 3452928    |\n",
      "| total_reward_steps      | 123        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08366907 |\n",
      "|    clip_fraction        | 0.411      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.656     |\n",
      "|    explained_variance   | 0.0607     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.237      |\n",
      "|    n_updates            | 16850      |\n",
      "|    policy_gradient_loss | 0.0161     |\n",
      "|    value_loss           | 10.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1687        |\n",
      "|    time_elapsed         | 12376       |\n",
      "|    total_timesteps      | 3454976     |\n",
      "| total_reward_steps      | 204         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039813176 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.501       |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1688        |\n",
      "|    time_elapsed         | 12382       |\n",
      "|    total_timesteps      | 3457024     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040907383 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.377       |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | 0.00869     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1689       |\n",
      "|    time_elapsed         | 12389      |\n",
      "|    total_timesteps      | 3459072    |\n",
      "| total_reward_steps      | 70         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03183389 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.496     |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.102      |\n",
      "|    n_updates            | 16880      |\n",
      "|    policy_gradient_loss | 0.00778    |\n",
      "|    value_loss           | 2          |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1690        |\n",
      "|    time_elapsed         | 12396       |\n",
      "|    total_timesteps      | 3461120     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034394726 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | 0.00955     |\n",
      "|    value_loss           | 6.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 12403       |\n",
      "|    total_timesteps      | 3463168     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028183155 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.111       |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | 0.0077      |\n",
      "|    value_loss           | 0.531       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1692        |\n",
      "|    time_elapsed         | 12409       |\n",
      "|    total_timesteps      | 3465216     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023225795 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0199      |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | -0.000478   |\n",
      "|    value_loss           | 0.497       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 12416       |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019100966 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 12423       |\n",
      "|    total_timesteps      | 3469312     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060084328 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.0653      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 16930       |\n",
      "|    policy_gradient_loss | 0.0161      |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1695       |\n",
      "|    time_elapsed         | 12430      |\n",
      "|    total_timesteps      | 3471360    |\n",
      "| total_reward_steps      | 45         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03268472 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.564     |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.262      |\n",
      "|    n_updates            | 16940      |\n",
      "|    policy_gradient_loss | 0.00465    |\n",
      "|    value_loss           | 0.372      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 12437       |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038335294 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0906      |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1697       |\n",
      "|    time_elapsed         | 12443      |\n",
      "|    total_timesteps      | 3475456    |\n",
      "| total_reward_steps      | 125        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04637281 |\n",
      "|    clip_fraction        | 0.365      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.54      |\n",
      "|    explained_variance   | 0.228      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.252      |\n",
      "|    n_updates            | 16960      |\n",
      "|    policy_gradient_loss | 0.0227     |\n",
      "|    value_loss           | 11.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 12450       |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033368014 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.585       |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | 0.0203      |\n",
      "|    value_loss           | 4.25        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1699       |\n",
      "|    time_elapsed         | 12457      |\n",
      "|    total_timesteps      | 3479552    |\n",
      "| total_reward_steps      | 64         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02989673 |\n",
      "|    clip_fraction        | 0.429      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.709     |\n",
      "|    explained_variance   | 0.148      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0382     |\n",
      "|    n_updates            | 16980      |\n",
      "|    policy_gradient_loss | -0.000301  |\n",
      "|    value_loss           | 0.254      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1700        |\n",
      "|    time_elapsed         | 12464       |\n",
      "|    total_timesteps      | 3481600     |\n",
      "| total_reward_steps      | 123         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027204257 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 16990       |\n",
      "|    policy_gradient_loss | 0.00589     |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1701        |\n",
      "|    time_elapsed         | 12471       |\n",
      "|    total_timesteps      | 3483648     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029885128 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 17000       |\n",
      "|    policy_gradient_loss | -0.000219   |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1702       |\n",
      "|    time_elapsed         | 12477      |\n",
      "|    total_timesteps      | 3485696    |\n",
      "| total_reward_steps      | 90         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03357806 |\n",
      "|    clip_fraction        | 0.348      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.594     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.51       |\n",
      "|    n_updates            | 17010      |\n",
      "|    policy_gradient_loss | 0.0101     |\n",
      "|    value_loss           | 1.87       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1703       |\n",
      "|    time_elapsed         | 12484      |\n",
      "|    total_timesteps      | 3487744    |\n",
      "| total_reward_steps      | 119        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07271524 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.442     |\n",
      "|    explained_variance   | 0.797      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0892     |\n",
      "|    n_updates            | 17020      |\n",
      "|    policy_gradient_loss | -0.00386   |\n",
      "|    value_loss           | 0.98       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 12491       |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016370509 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0299      |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 0.454       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1705       |\n",
      "|    time_elapsed         | 12498      |\n",
      "|    total_timesteps      | 3491840    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01763248 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.753     |\n",
      "|    explained_variance   | 0.438      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0806     |\n",
      "|    n_updates            | 17040      |\n",
      "|    policy_gradient_loss | -0.00737   |\n",
      "|    value_loss           | 0.225      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 12504       |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020953784 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0184      |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.0082     |\n",
      "|    value_loss           | 0.156       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1707        |\n",
      "|    time_elapsed         | 12511       |\n",
      "|    total_timesteps      | 3495936     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024397086 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.143       |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 0.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1708        |\n",
      "|    time_elapsed         | 12518       |\n",
      "|    total_timesteps      | 3497984     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016477037 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0856      |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    value_loss           | 0.415       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3500000, episode_reward=83.80 +/- 37.43\n",
      "Episode length: 1217.33 +/- 187.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 83.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3500000     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032120664 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.154       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | 0.00464     |\n",
      "|    value_loss           | 2.01        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 278     |\n",
      "|    iterations      | 1709    |\n",
      "|    time_elapsed    | 12569   |\n",
      "|    total_timesteps | 3500032 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1710       |\n",
      "|    time_elapsed         | 12575      |\n",
      "|    total_timesteps      | 3502080    |\n",
      "| total_reward_steps      | 86         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01746236 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.73      |\n",
      "|    explained_variance   | 0.41       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0481     |\n",
      "|    n_updates            | 17090      |\n",
      "|    policy_gradient_loss | -0.00546   |\n",
      "|    value_loss           | 0.187      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 12582       |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| total_reward_steps      | 173         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018466907 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.834       |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | 0.00321     |\n",
      "|    value_loss           | 2.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 12589       |\n",
      "|    total_timesteps      | 3506176     |\n",
      "| total_reward_steps      | 184         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026722575 |\n",
      "|    clip_fraction        | 0.448       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.81        |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 12595       |\n",
      "|    total_timesteps      | 3508224     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017050227 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    value_loss           | 1.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1714        |\n",
      "|    time_elapsed         | 12602       |\n",
      "|    total_timesteps      | 3510272     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014084773 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 12609       |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021725059 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.776      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0164      |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1716       |\n",
      "|    time_elapsed         | 12616      |\n",
      "|    total_timesteps      | 3514368    |\n",
      "| total_reward_steps      | 109        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04277781 |\n",
      "|    clip_fraction        | 0.424      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.81      |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0645     |\n",
      "|    n_updates            | 17150      |\n",
      "|    policy_gradient_loss | 0.016      |\n",
      "|    value_loss           | 2.96       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1717        |\n",
      "|    time_elapsed         | 12623       |\n",
      "|    total_timesteps      | 3516416     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010722692 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.12        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | 0.00679     |\n",
      "|    value_loss           | 1.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 12629       |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018499669 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.685      |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | 0.00757     |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1719        |\n",
      "|    time_elapsed         | 12636       |\n",
      "|    total_timesteps      | 3520512     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015795453 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | 0.00386     |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 12643       |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020404387 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.606      |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.035       |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 12650       |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015929885 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0481      |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1722       |\n",
      "|    time_elapsed         | 12656      |\n",
      "|    total_timesteps      | 3526656    |\n",
      "| total_reward_steps      | 372        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09181314 |\n",
      "|    clip_fraction        | 0.518      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.67      |\n",
      "|    explained_variance   | -0.126     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 241        |\n",
      "|    n_updates            | 17210      |\n",
      "|    policy_gradient_loss | 0.0322     |\n",
      "|    value_loss           | 44         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 12663       |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053399906 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | -0.00518    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.142       |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | 0.0174      |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1724        |\n",
      "|    time_elapsed         | 12670       |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019091567 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0309      |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 12677       |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024146125 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | -0.285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | 0.00822     |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 12684       |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021432083 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0808      |\n",
      "|    n_updates            | 17250       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1727        |\n",
      "|    time_elapsed         | 12690       |\n",
      "|    total_timesteps      | 3536896     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017679123 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0179      |\n",
      "|    n_updates            | 17260       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 12697       |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020739663 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00927    |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1729        |\n",
      "|    time_elapsed         | 12704       |\n",
      "|    total_timesteps      | 3540992     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014441601 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00792    |\n",
      "|    n_updates            | 17280       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1730        |\n",
      "|    time_elapsed         | 12711       |\n",
      "|    total_timesteps      | 3543040     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015444018 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | -0.0323     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0766      |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.176       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1731        |\n",
      "|    time_elapsed         | 12717       |\n",
      "|    total_timesteps      | 3545088     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015400596 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0813      |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.0959      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1732       |\n",
      "|    time_elapsed         | 12724      |\n",
      "|    total_timesteps      | 3547136    |\n",
      "| total_reward_steps      | 359        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13819933 |\n",
      "|    clip_fraction        | 0.475      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.627     |\n",
      "|    explained_variance   | 0.0185     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.208      |\n",
      "|    n_updates            | 17310      |\n",
      "|    policy_gradient_loss | 0.0261     |\n",
      "|    value_loss           | 2.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 12731       |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031067349 |\n",
      "|    clip_fraction        | 0.444       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.0509      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | 0.0219      |\n",
      "|    value_loss           | 29.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1734        |\n",
      "|    time_elapsed         | 12738       |\n",
      "|    total_timesteps      | 3551232     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015764086 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | 0.00803     |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1735        |\n",
      "|    time_elapsed         | 12745       |\n",
      "|    total_timesteps      | 3553280     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021792337 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.616      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.024       |\n",
      "|    n_updates            | 17340       |\n",
      "|    policy_gradient_loss | -0.00821    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1736       |\n",
      "|    time_elapsed         | 12751      |\n",
      "|    total_timesteps      | 3555328    |\n",
      "| total_reward_steps      | 88         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06939163 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.637     |\n",
      "|    explained_variance   | 0.127      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.595      |\n",
      "|    n_updates            | 17350      |\n",
      "|    policy_gradient_loss | 0.00501    |\n",
      "|    value_loss           | 9.54       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 12758       |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058334894 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 0.00468     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0341      |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | 0.00327     |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 12765       |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017209534 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.685       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | 0.00262     |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1739       |\n",
      "|    time_elapsed         | 12772      |\n",
      "|    total_timesteps      | 3561472    |\n",
      "| total_reward_steps      | 78         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03901363 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.726     |\n",
      "|    explained_variance   | -0.00276   |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0651     |\n",
      "|    n_updates            | 17380      |\n",
      "|    policy_gradient_loss | 0.00606    |\n",
      "|    value_loss           | 1.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1740        |\n",
      "|    time_elapsed         | 12778       |\n",
      "|    total_timesteps      | 3563520     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028834105 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.671      |\n",
      "|    explained_variance   | 0.0435      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.436       |\n",
      "|    n_updates            | 17390       |\n",
      "|    policy_gradient_loss | 0.00931     |\n",
      "|    value_loss           | 9.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1741        |\n",
      "|    time_elapsed         | 12785       |\n",
      "|    total_timesteps      | 3565568     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.076796144 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.721       |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | 0.0285      |\n",
      "|    value_loss           | 25.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1742        |\n",
      "|    time_elapsed         | 12792       |\n",
      "|    total_timesteps      | 3567616     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034732353 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.295      |\n",
      "|    explained_variance   | -0.0196     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 17410       |\n",
      "|    policy_gradient_loss | 0.00375     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1743        |\n",
      "|    time_elapsed         | 12798       |\n",
      "|    total_timesteps      | 3569664     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072941035 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.392      |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.187       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1744       |\n",
      "|    time_elapsed         | 12805      |\n",
      "|    total_timesteps      | 3571712    |\n",
      "| total_reward_steps      | 179        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03030713 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.446     |\n",
      "|    explained_variance   | 0.27       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0554     |\n",
      "|    n_updates            | 17430      |\n",
      "|    policy_gradient_loss | 0.00705    |\n",
      "|    value_loss           | 1.77       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1745       |\n",
      "|    time_elapsed         | 12811      |\n",
      "|    total_timesteps      | 3573760    |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04558763 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.442     |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.45       |\n",
      "|    n_updates            | 17440      |\n",
      "|    policy_gradient_loss | 0.017      |\n",
      "|    value_loss           | 6.97       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1746        |\n",
      "|    time_elapsed         | 12818       |\n",
      "|    total_timesteps      | 3575808     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045641005 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.288      |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.03        |\n",
      "|    n_updates            | 17450       |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1747        |\n",
      "|    time_elapsed         | 12824       |\n",
      "|    total_timesteps      | 3577856     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042651862 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | -0.373      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.85        |\n",
      "|    n_updates            | 17460       |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    value_loss           | 0.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 12831       |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072452426 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 4.38        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | 0.0262      |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1749       |\n",
      "|    time_elapsed         | 12837      |\n",
      "|    total_timesteps      | 3581952    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03918487 |\n",
      "|    clip_fraction        | 0.393      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.622     |\n",
      "|    explained_variance   | -0.467     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.16       |\n",
      "|    n_updates            | 17480      |\n",
      "|    policy_gradient_loss | 0.00458    |\n",
      "|    value_loss           | 0.884      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 12844       |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027279641 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.0464      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0533      |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 0.248       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1751        |\n",
      "|    time_elapsed         | 12851       |\n",
      "|    total_timesteps      | 3586048     |\n",
      "| total_reward_steps      | 202         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051075235 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | 0.0305      |\n",
      "|    value_loss           | 11.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1752       |\n",
      "|    time_elapsed         | 12858      |\n",
      "|    total_timesteps      | 3588096    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05994404 |\n",
      "|    clip_fraction        | 0.493      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | -0.166     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.298      |\n",
      "|    n_updates            | 17510      |\n",
      "|    policy_gradient_loss | 0.0358     |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1753        |\n",
      "|    time_elapsed         | 12864       |\n",
      "|    total_timesteps      | 3590144     |\n",
      "| total_reward_steps      | 27          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050433334 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | -0.111      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 17520       |\n",
      "|    policy_gradient_loss | 0.00676     |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1754       |\n",
      "|    time_elapsed         | 12871      |\n",
      "|    total_timesteps      | 3592192    |\n",
      "| total_reward_steps      | 101        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02228478 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.596     |\n",
      "|    explained_variance   | 0.55       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 17530      |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    value_loss           | 0.247      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 1755       |\n",
      "|    time_elapsed         | 12878      |\n",
      "|    total_timesteps      | 3594240    |\n",
      "| total_reward_steps      | 110        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02330286 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.694     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.152      |\n",
      "|    n_updates            | 17540      |\n",
      "|    policy_gradient_loss | 0.000319   |\n",
      "|    value_loss           | 0.803      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1756        |\n",
      "|    time_elapsed         | 12885       |\n",
      "|    total_timesteps      | 3596288     |\n",
      "| total_reward_steps      | 179         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053769156 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.393       |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | 0.0247      |\n",
      "|    value_loss           | 14.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1757        |\n",
      "|    time_elapsed         | 12892       |\n",
      "|    total_timesteps      | 3598336     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028419262 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.072       |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    value_loss           | 6.17        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=36.23 +/- 2.20\n",
      "Episode length: 850.10 +/- 75.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 850         |\n",
      "|    mean_reward          | 36.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3600000     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024334338 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 278     |\n",
      "|    iterations      | 1758    |\n",
      "|    time_elapsed    | 12931   |\n",
      "|    total_timesteps | 3600384 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1759       |\n",
      "|    time_elapsed         | 12938      |\n",
      "|    total_timesteps      | 3602432    |\n",
      "| total_reward_steps      | 190        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01993471 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.657     |\n",
      "|    explained_variance   | 0.135      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0357     |\n",
      "|    n_updates            | 17580      |\n",
      "|    policy_gradient_loss | -0.0033    |\n",
      "|    value_loss           | 0.182      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 12945       |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041496262 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 17590       |\n",
      "|    policy_gradient_loss | 0.017       |\n",
      "|    value_loss           | 8.87        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1761       |\n",
      "|    time_elapsed         | 12952      |\n",
      "|    total_timesteps      | 3606528    |\n",
      "| total_reward_steps      | 22         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07594325 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.459     |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 9.01       |\n",
      "|    n_updates            | 17600      |\n",
      "|    policy_gradient_loss | 0.0416     |\n",
      "|    value_loss           | 59.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1762       |\n",
      "|    time_elapsed         | 12959      |\n",
      "|    total_timesteps      | 3608576    |\n",
      "| total_reward_steps      | 35         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18165915 |\n",
      "|    clip_fraction        | 0.479      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.603     |\n",
      "|    explained_variance   | -1.86      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.159      |\n",
      "|    n_updates            | 17610      |\n",
      "|    policy_gradient_loss | 0.0428     |\n",
      "|    value_loss           | 0.584      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1763        |\n",
      "|    time_elapsed         | 12966       |\n",
      "|    total_timesteps      | 3610624     |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037373804 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.559      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0155      |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | 0.000824    |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1764      |\n",
      "|    time_elapsed         | 12973     |\n",
      "|    total_timesteps      | 3612672   |\n",
      "| total_reward_steps      | 60        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0247016 |\n",
      "|    clip_fraction        | 0.325     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.558    |\n",
      "|    explained_variance   | -0.142    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0322    |\n",
      "|    n_updates            | 17630     |\n",
      "|    policy_gradient_loss | 0.00178   |\n",
      "|    value_loss           | 0.348     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 12979       |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029241418 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | -0.377      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.152       |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    value_loss           | 0.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1766        |\n",
      "|    time_elapsed         | 12986       |\n",
      "|    total_timesteps      | 3616768     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031919863 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | -0.0604     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0225     |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00896    |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1767        |\n",
      "|    time_elapsed         | 12993       |\n",
      "|    total_timesteps      | 3618816     |\n",
      "| total_reward_steps      | 179         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020349585 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.149       |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 0.721       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1768        |\n",
      "|    time_elapsed         | 13000       |\n",
      "|    total_timesteps      | 3620864     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032876007 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.175       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | 0.00957     |\n",
      "|    value_loss           | 8.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 13007       |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| total_reward_steps      | 30          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019692004 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0629      |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | 0.00986     |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1770      |\n",
      "|    time_elapsed         | 13013     |\n",
      "|    total_timesteps      | 3624960   |\n",
      "| total_reward_steps      | 45        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1476217 |\n",
      "|    clip_fraction        | 0.357     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.522    |\n",
      "|    explained_variance   | 0.129     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 2.1       |\n",
      "|    n_updates            | 17690     |\n",
      "|    policy_gradient_loss | 0.0584    |\n",
      "|    value_loss           | 49.8      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1771        |\n",
      "|    time_elapsed         | 13020       |\n",
      "|    total_timesteps      | 3627008     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031312957 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.54       |\n",
      "|    explained_variance   | -0.16       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0771      |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    value_loss           | 0.225       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 13027       |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.074487135 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.643       |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1773        |\n",
      "|    time_elapsed         | 13034       |\n",
      "|    total_timesteps      | 3631104     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018361567 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 13041       |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| total_reward_steps      | 179         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021748945 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.528      |\n",
      "|    explained_variance   | -0.533      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0324      |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | 0.00265     |\n",
      "|    value_loss           | 0.303       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1775        |\n",
      "|    time_elapsed         | 13047       |\n",
      "|    total_timesteps      | 3635200     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029097162 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.337       |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | 0.024       |\n",
      "|    value_loss           | 7.73        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1776       |\n",
      "|    time_elapsed         | 13054      |\n",
      "|    total_timesteps      | 3637248    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01759165 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.562     |\n",
      "|    explained_variance   | 0.694      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0765     |\n",
      "|    n_updates            | 17750      |\n",
      "|    policy_gradient_loss | 0.00767    |\n",
      "|    value_loss           | 0.686      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1777       |\n",
      "|    time_elapsed         | 13060      |\n",
      "|    total_timesteps      | 3639296    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02381358 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.598     |\n",
      "|    explained_variance   | 0.714      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.074      |\n",
      "|    n_updates            | 17760      |\n",
      "|    policy_gradient_loss | 0.0162     |\n",
      "|    value_loss           | 0.712      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1778       |\n",
      "|    time_elapsed         | 13067      |\n",
      "|    total_timesteps      | 3641344    |\n",
      "| total_reward_steps      | 42         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03389147 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.693     |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00675    |\n",
      "|    n_updates            | 17770      |\n",
      "|    policy_gradient_loss | -0.00648   |\n",
      "|    value_loss           | 0.141      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 13073       |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016022496 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0377      |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1780        |\n",
      "|    time_elapsed         | 13079       |\n",
      "|    total_timesteps      | 3645440     |\n",
      "| total_reward_steps      | 163         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013446095 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1781       |\n",
      "|    time_elapsed         | 13086      |\n",
      "|    total_timesteps      | 3647488    |\n",
      "| total_reward_steps      | 48         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07831104 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.606     |\n",
      "|    explained_variance   | 0.0475     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.548      |\n",
      "|    n_updates            | 17800      |\n",
      "|    policy_gradient_loss | 0.0258     |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1782       |\n",
      "|    time_elapsed         | 13093      |\n",
      "|    total_timesteps      | 3649536    |\n",
      "| total_reward_steps      | 32         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03527806 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.764     |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.159      |\n",
      "|    n_updates            | 17810      |\n",
      "|    policy_gradient_loss | 0.0265     |\n",
      "|    value_loss           | 36.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1783        |\n",
      "|    time_elapsed         | 13100       |\n",
      "|    total_timesteps      | 3651584     |\n",
      "| total_reward_steps      | 188         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015602832 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.079       |\n",
      "|    n_updates            | 17820       |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 0.196       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1784        |\n",
      "|    time_elapsed         | 13107       |\n",
      "|    total_timesteps      | 3653632     |\n",
      "| total_reward_steps      | 187         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025213804 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | 0.00778     |\n",
      "|    value_loss           | 3.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1785        |\n",
      "|    time_elapsed         | 13113       |\n",
      "|    total_timesteps      | 3655680     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039697416 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | -0.0737     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 13120       |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019031638 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1787       |\n",
      "|    time_elapsed         | 13127      |\n",
      "|    total_timesteps      | 3659776    |\n",
      "| total_reward_steps      | 107        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07397551 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.548     |\n",
      "|    explained_variance   | 0.292      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0661     |\n",
      "|    n_updates            | 17860      |\n",
      "|    policy_gradient_loss | 0.00189    |\n",
      "|    value_loss           | 4.57       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1788        |\n",
      "|    time_elapsed         | 13134       |\n",
      "|    total_timesteps      | 3661824     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017540233 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.071       |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | 0.00716     |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 13141       |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014642164 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.08        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1790        |\n",
      "|    time_elapsed         | 13147       |\n",
      "|    total_timesteps      | 3665920     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014234791 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0681      |\n",
      "|    n_updates            | 17890       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 13154       |\n",
      "|    total_timesteps      | 3667968     |\n",
      "| total_reward_steps      | 176         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014899896 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | 0.000473    |\n",
      "|    value_loss           | 1.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1792        |\n",
      "|    time_elapsed         | 13161       |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023396619 |\n",
      "|    clip_fraction        | 0.411       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | 0.00669     |\n",
      "|    value_loss           | 2.52        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1793      |\n",
      "|    time_elapsed         | 13168     |\n",
      "|    total_timesteps      | 3672064   |\n",
      "| total_reward_steps      | 65        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0221419 |\n",
      "|    clip_fraction        | 0.304     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.681    |\n",
      "|    explained_variance   | 0.745     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0365    |\n",
      "|    n_updates            | 17920     |\n",
      "|    policy_gradient_loss | -0.0131   |\n",
      "|    value_loss           | 0.101     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 13175       |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013447288 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.847      |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.095       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 13182       |\n",
      "|    total_timesteps      | 3676160     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014162067 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | -0.000609   |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 13188       |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021511005 |\n",
      "|    clip_fraction        | 0.361       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | -0.664      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | 0.000749    |\n",
      "|    value_loss           | 0.586       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1797        |\n",
      "|    time_elapsed         | 13195       |\n",
      "|    total_timesteps      | 3680256     |\n",
      "| total_reward_steps      | 33          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018407168 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 17960       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 0.404       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1798        |\n",
      "|    time_elapsed         | 13202       |\n",
      "|    total_timesteps      | 3682304     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018126404 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.757      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 0.256       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 13209       |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019722935 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | -0.288      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0578      |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    value_loss           | 0.536       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1800        |\n",
      "|    time_elapsed         | 13216       |\n",
      "|    total_timesteps      | 3686400     |\n",
      "| total_reward_steps      | 39          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020862967 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.694      |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 17990       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 0.853       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 13222       |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023686744 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00788     |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    value_loss           | 0.321       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1802       |\n",
      "|    time_elapsed         | 13229      |\n",
      "|    total_timesteps      | 3690496    |\n",
      "| total_reward_steps      | 57         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02098411 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.301      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0704     |\n",
      "|    n_updates            | 18010      |\n",
      "|    policy_gradient_loss | 0.00768    |\n",
      "|    value_loss           | 0.482      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 13236       |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021448597 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0526      |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1804       |\n",
      "|    time_elapsed         | 13243      |\n",
      "|    total_timesteps      | 3694592    |\n",
      "| total_reward_steps      | 110        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01691974 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.725     |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.178      |\n",
      "|    n_updates            | 18030      |\n",
      "|    policy_gradient_loss | 0.00352    |\n",
      "|    value_loss           | 1.56       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1805       |\n",
      "|    time_elapsed         | 13250      |\n",
      "|    total_timesteps      | 3696640    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02662684 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.722     |\n",
      "|    explained_variance   | 0.489      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 31.7       |\n",
      "|    n_updates            | 18040      |\n",
      "|    policy_gradient_loss | 0.00734    |\n",
      "|    value_loss           | 1.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 13256       |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014207077 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.00786    |\n",
      "|    value_loss           | 0.134       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=51.77 +/- 2.14\n",
      "Episode length: 935.73 +/- 42.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 936         |\n",
      "|    mean_reward          | 51.8        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3700000     |\n",
      "| total_reward_steps      | 179         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027796432 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | -0.332      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.488       |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    value_loss           | 0.793       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1807     |\n",
      "|    time_elapsed    | 13298    |\n",
      "|    total_timesteps | 3700736  |\n",
      "| total_reward_steps | 48       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 13305       |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021941682 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.178       |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    value_loss           | 5.85        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 13311       |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013437504 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0109      |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 13318       |\n",
      "|    total_timesteps      | 3706880     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015631802 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0922      |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    value_loss           | 0.752       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1811        |\n",
      "|    time_elapsed         | 13324       |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013236349 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0317      |\n",
      "|    n_updates            | 18100       |\n",
      "|    policy_gradient_loss | 3.85e-05    |\n",
      "|    value_loss           | 1.62        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1812       |\n",
      "|    time_elapsed         | 13330      |\n",
      "|    total_timesteps      | 3710976    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01668984 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0154     |\n",
      "|    n_updates            | 18110      |\n",
      "|    policy_gradient_loss | -0.0118    |\n",
      "|    value_loss           | 0.432      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 13337       |\n",
      "|    total_timesteps      | 3713024     |\n",
      "| total_reward_steps      | 178         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019801244 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | -0.91       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | 0.00536     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1814        |\n",
      "|    time_elapsed         | 13343       |\n",
      "|    total_timesteps      | 3715072     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017424017 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0979      |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    value_loss           | 4.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1815       |\n",
      "|    time_elapsed         | 13350      |\n",
      "|    total_timesteps      | 3717120    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01425311 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.622     |\n",
      "|    explained_variance   | 0.734      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0576     |\n",
      "|    n_updates            | 18140      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    value_loss           | 0.192      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 13357       |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016243905 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 0.517       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1817        |\n",
      "|    time_elapsed         | 13364       |\n",
      "|    total_timesteps      | 3721216     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016619656 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0702      |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.000473   |\n",
      "|    value_loss           | 0.506       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 13371       |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016092308 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0239      |\n",
      "|    n_updates            | 18170       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    value_loss           | 0.488       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1819       |\n",
      "|    time_elapsed         | 13377      |\n",
      "|    total_timesteps      | 3725312    |\n",
      "| total_reward_steps      | 75         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01379339 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.651     |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0617     |\n",
      "|    n_updates            | 18180      |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    value_loss           | 0.133      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 13384       |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031815253 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.25        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.115       |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 2.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 13391       |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021007635 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    value_loss           | 1.74        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1822       |\n",
      "|    time_elapsed         | 13398      |\n",
      "|    total_timesteps      | 3731456    |\n",
      "| total_reward_steps      | 188        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02079251 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | -0.0116    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0705     |\n",
      "|    n_updates            | 18210      |\n",
      "|    policy_gradient_loss | 0.00149    |\n",
      "|    value_loss           | 0.408      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1823       |\n",
      "|    time_elapsed         | 13405      |\n",
      "|    total_timesteps      | 3733504    |\n",
      "| total_reward_steps      | 37         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14523649 |\n",
      "|    clip_fraction        | 0.447      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.693     |\n",
      "|    explained_variance   | 0.082      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.198      |\n",
      "|    n_updates            | 18220      |\n",
      "|    policy_gradient_loss | 0.0473     |\n",
      "|    value_loss           | 13.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1824        |\n",
      "|    time_elapsed         | 13411       |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037941165 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0455      |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    value_loss           | 0.215       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 13418       |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019671187 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 0.163       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1826        |\n",
      "|    time_elapsed         | 13425       |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021050021 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0088      |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1827        |\n",
      "|    time_elapsed         | 13432       |\n",
      "|    total_timesteps      | 3741696     |\n",
      "| total_reward_steps      | 185         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025225593 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 13439       |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.064013116 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0889      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03        |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | 0.0207      |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1829        |\n",
      "|    time_elapsed         | 13445       |\n",
      "|    total_timesteps      | 3745792     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024121253 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0375      |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 13452       |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025727559 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | 0.0151      |\n",
      "|    value_loss           | 2.35        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1831        |\n",
      "|    time_elapsed         | 13459       |\n",
      "|    total_timesteps      | 3749888     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023273028 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00461    |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    value_loss           | 0.108       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1832        |\n",
      "|    time_elapsed         | 13466       |\n",
      "|    total_timesteps      | 3751936     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035395898 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.171       |\n",
      "|    n_updates            | 18310       |\n",
      "|    policy_gradient_loss | 0.00583     |\n",
      "|    value_loss           | 1.67        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1833       |\n",
      "|    time_elapsed         | 13473      |\n",
      "|    total_timesteps      | 3753984    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01694046 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.642     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 18320      |\n",
      "|    policy_gradient_loss | -0.00604   |\n",
      "|    value_loss           | 0.152      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1834       |\n",
      "|    time_elapsed         | 13479      |\n",
      "|    total_timesteps      | 3756032    |\n",
      "| total_reward_steps      | 183        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12398657 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.57      |\n",
      "|    explained_variance   | 0.378      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0683     |\n",
      "|    n_updates            | 18330      |\n",
      "|    policy_gradient_loss | 0.00461    |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1835        |\n",
      "|    time_elapsed         | 13486       |\n",
      "|    total_timesteps      | 3758080     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036423475 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.48        |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | 0.0229      |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1836        |\n",
      "|    time_elapsed         | 13493       |\n",
      "|    total_timesteps      | 3760128     |\n",
      "| total_reward_steps      | 194         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018657427 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 13500       |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045145832 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.368       |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | 0.0241      |\n",
      "|    value_loss           | 8.97        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 13507       |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019423023 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.666       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 18370       |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1839        |\n",
      "|    time_elapsed         | 13514       |\n",
      "|    total_timesteps      | 3766272     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050629962 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.344       |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | -0.000896   |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1840       |\n",
      "|    time_elapsed         | 13520      |\n",
      "|    total_timesteps      | 3768320    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04690532 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.574     |\n",
      "|    explained_variance   | 0.185      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.583      |\n",
      "|    n_updates            | 18390      |\n",
      "|    policy_gradient_loss | 0.0214     |\n",
      "|    value_loss           | 12.3       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1841      |\n",
      "|    time_elapsed         | 13527     |\n",
      "|    total_timesteps      | 3770368   |\n",
      "| total_reward_steps      | 52        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0571767 |\n",
      "|    clip_fraction        | 0.347     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.57     |\n",
      "|    explained_variance   | 0.561     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.29      |\n",
      "|    n_updates            | 18400     |\n",
      "|    policy_gradient_loss | 0.00328   |\n",
      "|    value_loss           | 1.44      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1842        |\n",
      "|    time_elapsed         | 13534       |\n",
      "|    total_timesteps      | 3772416     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022625946 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.607      |\n",
      "|    explained_variance   | -0.0354     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 18410       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1843       |\n",
      "|    time_elapsed         | 13541      |\n",
      "|    total_timesteps      | 3774464    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03337816 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.489     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.97       |\n",
      "|    n_updates            | 18420      |\n",
      "|    policy_gradient_loss | 0.00781    |\n",
      "|    value_loss           | 2.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1844        |\n",
      "|    time_elapsed         | 13548       |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021569304 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0691      |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | 0.00556     |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 13554       |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013897492 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00462     |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1846        |\n",
      "|    time_elapsed         | 13561       |\n",
      "|    total_timesteps      | 3780608     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008584395 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 18450       |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 13567       |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013799207 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00276     |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | -0.00534    |\n",
      "|    value_loss           | 0.504       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 13574       |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020221127 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 18470       |\n",
      "|    policy_gradient_loss | 0.0172      |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1849        |\n",
      "|    time_elapsed         | 13580       |\n",
      "|    total_timesteps      | 3786752     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033690225 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.667      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | 0.00251     |\n",
      "|    value_loss           | 0.45        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1850        |\n",
      "|    time_elapsed         | 13587       |\n",
      "|    total_timesteps      | 3788800     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024575781 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0935      |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    value_loss           | 0.469       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1851        |\n",
      "|    time_elapsed         | 13593       |\n",
      "|    total_timesteps      | 3790848     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015096014 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.247       |\n",
      "|    n_updates            | 18500       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    value_loss           | 0.254       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 13600       |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014987321 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0402      |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1853       |\n",
      "|    time_elapsed         | 13607      |\n",
      "|    total_timesteps      | 3794944    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03763201 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00779    |\n",
      "|    n_updates            | 18520      |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    value_loss           | 0.238      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1854        |\n",
      "|    time_elapsed         | 13613       |\n",
      "|    total_timesteps      | 3796992     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813746 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0114      |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 0.553       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1855       |\n",
      "|    time_elapsed         | 13620      |\n",
      "|    total_timesteps      | 3799040    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01773174 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.723     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00436    |\n",
      "|    n_updates            | 18540      |\n",
      "|    policy_gradient_loss | -0.00435   |\n",
      "|    value_loss           | 0.179      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=72.13 +/- 9.83\n",
      "Episode length: 1010.97 +/- 143.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | 72.1         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3800000      |\n",
      "| total_reward_steps      | 80           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120524485 |\n",
      "|    clip_fraction        | 0.296        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.749       |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.019        |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.0118      |\n",
      "|    value_loss           | 0.129        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 278      |\n",
      "|    iterations      | 1856     |\n",
      "|    time_elapsed    | 13665    |\n",
      "|    total_timesteps | 3801088  |\n",
      "| total_reward_steps | 79       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1857        |\n",
      "|    time_elapsed         | 13672       |\n",
      "|    total_timesteps      | 3803136     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010280594 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.762      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0319      |\n",
      "|    n_updates            | 18560       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1858        |\n",
      "|    time_elapsed         | 13679       |\n",
      "|    total_timesteps      | 3805184     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016430568 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.124       |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    value_loss           | 0.563       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1859        |\n",
      "|    time_elapsed         | 13686       |\n",
      "|    total_timesteps      | 3807232     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014846555 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0619      |\n",
      "|    n_updates            | 18580       |\n",
      "|    policy_gradient_loss | -0.00134    |\n",
      "|    value_loss           | 0.344       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1860        |\n",
      "|    time_elapsed         | 13693       |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010635044 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0409      |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    value_loss           | 0.124       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1861       |\n",
      "|    time_elapsed         | 13699      |\n",
      "|    total_timesteps      | 3811328    |\n",
      "| total_reward_steps      | 105        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01410437 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.723     |\n",
      "|    explained_variance   | 0.825      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0738     |\n",
      "|    n_updates            | 18600      |\n",
      "|    policy_gradient_loss | -0.00959   |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1862       |\n",
      "|    time_elapsed         | 13706      |\n",
      "|    total_timesteps      | 3813376    |\n",
      "| total_reward_steps      | 92         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943681 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.68      |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.127      |\n",
      "|    n_updates            | 18610      |\n",
      "|    policy_gradient_loss | 0.0101     |\n",
      "|    value_loss           | 2.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1863        |\n",
      "|    time_elapsed         | 13713       |\n",
      "|    total_timesteps      | 3815424     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018044489 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 18620       |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 13720       |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026859358 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.374       |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | 0.00626     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1865        |\n",
      "|    time_elapsed         | 13727       |\n",
      "|    total_timesteps      | 3819520     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019935891 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.181       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 18640       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 0.207       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1866       |\n",
      "|    time_elapsed         | 13734      |\n",
      "|    total_timesteps      | 3821568    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01287982 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.689     |\n",
      "|    explained_variance   | 0.635      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.118      |\n",
      "|    n_updates            | 18650      |\n",
      "|    policy_gradient_loss | -0.0077    |\n",
      "|    value_loss           | 0.156      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 13740       |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019109018 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 0.618       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1868        |\n",
      "|    time_elapsed         | 13747       |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019912168 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.794      |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 18670       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 278       |\n",
      "|    iterations           | 1869      |\n",
      "|    time_elapsed         | 13754     |\n",
      "|    total_timesteps      | 3827712   |\n",
      "| total_reward_steps      | 97        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0116302 |\n",
      "|    clip_fraction        | 0.268     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.781    |\n",
      "|    explained_variance   | 0.841     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.211     |\n",
      "|    n_updates            | 18680     |\n",
      "|    policy_gradient_loss | -0.00585  |\n",
      "|    value_loss           | 0.485     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1870        |\n",
      "|    time_elapsed         | 13761       |\n",
      "|    total_timesteps      | 3829760     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021313623 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0651      |\n",
      "|    n_updates            | 18690       |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1871        |\n",
      "|    time_elapsed         | 13768       |\n",
      "|    total_timesteps      | 3831808     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021840643 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.734      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | 0.000681    |\n",
      "|    value_loss           | 1.33        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1872        |\n",
      "|    time_elapsed         | 13774       |\n",
      "|    total_timesteps      | 3833856     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012676342 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 18710       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1873        |\n",
      "|    time_elapsed         | 13781       |\n",
      "|    total_timesteps      | 3835904     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015497016 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 18720       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 13788       |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017227972 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.832      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0423      |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1875        |\n",
      "|    time_elapsed         | 13795       |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015239124 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0185      |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 278          |\n",
      "|    iterations           | 1876         |\n",
      "|    time_elapsed         | 13802        |\n",
      "|    total_timesteps      | 3842048      |\n",
      "| total_reward_steps      | 87           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107192835 |\n",
      "|    clip_fraction        | 0.281        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.845       |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0762       |\n",
      "|    n_updates            | 18750        |\n",
      "|    policy_gradient_loss | -0.00902     |\n",
      "|    value_loss           | 0.0777       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1877       |\n",
      "|    time_elapsed         | 13808      |\n",
      "|    total_timesteps      | 3844096    |\n",
      "| total_reward_steps      | 91         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01163671 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.819     |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0594     |\n",
      "|    n_updates            | 18760      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.118      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1878        |\n",
      "|    time_elapsed         | 13815       |\n",
      "|    total_timesteps      | 3846144     |\n",
      "| total_reward_steps      | 94          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029094582 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00756    |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    value_loss           | 0.583       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1879       |\n",
      "|    time_elapsed         | 13821      |\n",
      "|    total_timesteps      | 3848192    |\n",
      "| total_reward_steps      | 89         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01849849 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.866     |\n",
      "|    explained_variance   | 0.807      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0352    |\n",
      "|    n_updates            | 18780      |\n",
      "|    policy_gradient_loss | -0.00949   |\n",
      "|    value_loss           | 0.234      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1880        |\n",
      "|    time_elapsed         | 13828       |\n",
      "|    total_timesteps      | 3850240     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012179744 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.791      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0468      |\n",
      "|    n_updates            | 18790       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1881        |\n",
      "|    time_elapsed         | 13834       |\n",
      "|    total_timesteps      | 3852288     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013357927 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.0667      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1882        |\n",
      "|    time_elapsed         | 13840       |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019788932 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    value_loss           | 3.98        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1883        |\n",
      "|    time_elapsed         | 13847       |\n",
      "|    total_timesteps      | 3856384     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014269449 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0709      |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.284       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1884       |\n",
      "|    time_elapsed         | 13853      |\n",
      "|    total_timesteps      | 3858432    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02828237 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.7       |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.118      |\n",
      "|    n_updates            | 18830      |\n",
      "|    policy_gradient_loss | 0.0184     |\n",
      "|    value_loss           | 12         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1885        |\n",
      "|    time_elapsed         | 13859       |\n",
      "|    total_timesteps      | 3860480     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021433966 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00197     |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00795    |\n",
      "|    value_loss           | 0.26        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1886       |\n",
      "|    time_elapsed         | 13865      |\n",
      "|    total_timesteps      | 3862528    |\n",
      "| total_reward_steps      | 99         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02711545 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.801     |\n",
      "|    explained_variance   | 0.69       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0613     |\n",
      "|    n_updates            | 18850      |\n",
      "|    policy_gradient_loss | -0.00976   |\n",
      "|    value_loss           | 0.159      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1887        |\n",
      "|    time_elapsed         | 13872       |\n",
      "|    total_timesteps      | 3864576     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013282855 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.132       |\n",
      "|    n_updates            | 18860       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.0972      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1888        |\n",
      "|    time_elapsed         | 13878       |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| total_reward_steps      | 100         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019185327 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0331      |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    value_loss           | 0.501       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1889        |\n",
      "|    time_elapsed         | 13885       |\n",
      "|    total_timesteps      | 3868672     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016995441 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0697      |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | 0.00401     |\n",
      "|    value_loss           | 0.557       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1890        |\n",
      "|    time_elapsed         | 13892       |\n",
      "|    total_timesteps      | 3870720     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011937111 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.0998      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1891        |\n",
      "|    time_elapsed         | 13899       |\n",
      "|    total_timesteps      | 3872768     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023369867 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.155       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 18900       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1892       |\n",
      "|    time_elapsed         | 13906      |\n",
      "|    total_timesteps      | 3874816    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01581232 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.516     |\n",
      "|    explained_variance   | 0.616      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.336      |\n",
      "|    n_updates            | 18910      |\n",
      "|    policy_gradient_loss | -0.00268   |\n",
      "|    value_loss           | 0.946      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1893        |\n",
      "|    time_elapsed         | 13913       |\n",
      "|    total_timesteps      | 3876864     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022312056 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0694      |\n",
      "|    n_updates            | 18920       |\n",
      "|    policy_gradient_loss | 0.00796     |\n",
      "|    value_loss           | 1.49        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1894       |\n",
      "|    time_elapsed         | 13919      |\n",
      "|    total_timesteps      | 3878912    |\n",
      "| total_reward_steps      | 83         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01768157 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.804     |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0199     |\n",
      "|    n_updates            | 18930      |\n",
      "|    policy_gradient_loss | -0.00199   |\n",
      "|    value_loss           | 0.312      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1895        |\n",
      "|    time_elapsed         | 13926       |\n",
      "|    total_timesteps      | 3880960     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020874131 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0202      |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1896       |\n",
      "|    time_elapsed         | 13933      |\n",
      "|    total_timesteps      | 3883008    |\n",
      "| total_reward_steps      | 358        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01896938 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.57      |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0995     |\n",
      "|    n_updates            | 18950      |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    value_loss           | 1.41       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1897        |\n",
      "|    time_elapsed         | 13940       |\n",
      "|    total_timesteps      | 3885056     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046819612 |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | 0.0252      |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1898        |\n",
      "|    time_elapsed         | 13947       |\n",
      "|    total_timesteps      | 3887104     |\n",
      "| total_reward_steps      | 154         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022599943 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.436       |\n",
      "|    n_updates            | 18970       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    value_loss           | 0.503       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 13954       |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034852307 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    value_loss           | 2.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1900        |\n",
      "|    time_elapsed         | 13961       |\n",
      "|    total_timesteps      | 3891200     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017350623 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00905     |\n",
      "|    n_updates            | 18990       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 13968       |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012284541 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0401      |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1902        |\n",
      "|    time_elapsed         | 13974       |\n",
      "|    total_timesteps      | 3895296     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.098953225 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0718      |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 13981       |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021091323 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.647      |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0412      |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 0.684       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1904        |\n",
      "|    time_elapsed         | 13988       |\n",
      "|    total_timesteps      | 3899392     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015421769 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 19030       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    value_loss           | 0.286       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=89.17 +/- 22.82\n",
      "Episode length: 1090.50 +/- 120.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.09e+03   |\n",
      "|    mean_reward          | 89.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3900000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02043448 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.687     |\n",
      "|    explained_variance   | 0.249      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.939      |\n",
      "|    n_updates            | 19040      |\n",
      "|    policy_gradient_loss | 0.0152     |\n",
      "|    value_loss           | 2.75       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1905     |\n",
      "|    time_elapsed    | 14036    |\n",
      "|    total_timesteps | 3901440  |\n",
      "| total_reward_steps | 93       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 14043       |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016557656 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00531    |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1907        |\n",
      "|    time_elapsed         | 14050       |\n",
      "|    total_timesteps      | 3905536     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017025322 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0672      |\n",
      "|    n_updates            | 19060       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 14057       |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| total_reward_steps      | 95          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009917891 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 19070       |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 14064       |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| total_reward_steps      | 91          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012338035 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0499      |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1910        |\n",
      "|    time_elapsed         | 14071       |\n",
      "|    total_timesteps      | 3911680     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009766764 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1911        |\n",
      "|    time_elapsed         | 14078       |\n",
      "|    total_timesteps      | 3913728     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013318995 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0536      |\n",
      "|    n_updates            | 19100       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.189       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1912       |\n",
      "|    time_elapsed         | 14085      |\n",
      "|    total_timesteps      | 3915776    |\n",
      "| total_reward_steps      | 100        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01318464 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.743     |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 19110      |\n",
      "|    policy_gradient_loss | -0.00741   |\n",
      "|    value_loss           | 0.227      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1913        |\n",
      "|    time_elapsed         | 14092       |\n",
      "|    total_timesteps      | 3917824     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014585509 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 14098       |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009534011 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1915        |\n",
      "|    time_elapsed         | 14105       |\n",
      "|    total_timesteps      | 3921920     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029685836 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.271       |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.244       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 14111       |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| total_reward_steps      | 98          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026314046 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.17        |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    value_loss           | 2.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1917        |\n",
      "|    time_elapsed         | 14118       |\n",
      "|    total_timesteps      | 3926016     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016511256 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0117      |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1918        |\n",
      "|    time_elapsed         | 14124       |\n",
      "|    total_timesteps      | 3928064     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013459651 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.607      |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00181    |\n",
      "|    n_updates            | 19170       |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1919        |\n",
      "|    time_elapsed         | 14131       |\n",
      "|    total_timesteps      | 3930112     |\n",
      "| total_reward_steps      | 125         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010035388 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0407     |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.141       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1920        |\n",
      "|    time_elapsed         | 14138       |\n",
      "|    total_timesteps      | 3932160     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015379554 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.358       |\n",
      "|    n_updates            | 19190       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 2.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1921        |\n",
      "|    time_elapsed         | 14145       |\n",
      "|    total_timesteps      | 3934208     |\n",
      "| total_reward_steps      | 377         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013506366 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 19200       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1922       |\n",
      "|    time_elapsed         | 14152      |\n",
      "|    total_timesteps      | 3936256    |\n",
      "| total_reward_steps      | 186        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28935164 |\n",
      "|    clip_fraction        | 0.538      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.572     |\n",
      "|    explained_variance   | 0.0125     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 73.2       |\n",
      "|    n_updates            | 19210      |\n",
      "|    policy_gradient_loss | 0.0613     |\n",
      "|    value_loss           | 52.8       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1923       |\n",
      "|    time_elapsed         | 14159      |\n",
      "|    total_timesteps      | 3938304    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08032586 |\n",
      "|    clip_fraction        | 0.446      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.642     |\n",
      "|    explained_variance   | 0.197      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.276      |\n",
      "|    n_updates            | 19220      |\n",
      "|    policy_gradient_loss | 0.0171     |\n",
      "|    value_loss           | 9.54       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1924        |\n",
      "|    time_elapsed         | 14166       |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025832947 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | 0.00892     |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 14173       |\n",
      "|    total_timesteps      | 3942400     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036131974 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    value_loss           | 0.416       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1926       |\n",
      "|    time_elapsed         | 14179      |\n",
      "|    total_timesteps      | 3944448    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03822214 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.67      |\n",
      "|    explained_variance   | 0.57       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.078      |\n",
      "|    n_updates            | 19250      |\n",
      "|    policy_gradient_loss | -0.000691  |\n",
      "|    value_loss           | 0.749      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1927       |\n",
      "|    time_elapsed         | 14186      |\n",
      "|    total_timesteps      | 3946496    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04991789 |\n",
      "|    clip_fraction        | 0.394      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.569     |\n",
      "|    explained_variance   | 0.422      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.314      |\n",
      "|    n_updates            | 19260      |\n",
      "|    policy_gradient_loss | 0.018      |\n",
      "|    value_loss           | 2.67       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1928       |\n",
      "|    time_elapsed         | 14193      |\n",
      "|    total_timesteps      | 3948544    |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07505948 |\n",
      "|    clip_fraction        | 0.322      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.446     |\n",
      "|    explained_variance   | 0.272      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.55       |\n",
      "|    n_updates            | 19270      |\n",
      "|    policy_gradient_loss | 0.0296     |\n",
      "|    value_loss           | 13.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1929       |\n",
      "|    time_elapsed         | 14200      |\n",
      "|    total_timesteps      | 3950592    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03147553 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.56      |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.18       |\n",
      "|    n_updates            | 19280      |\n",
      "|    policy_gradient_loss | 0.0134     |\n",
      "|    value_loss           | 1.83       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 14207       |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026801765 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 19290       |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.549       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1931        |\n",
      "|    time_elapsed         | 14213       |\n",
      "|    total_timesteps      | 3954688     |\n",
      "| total_reward_steps      | 186         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021564107 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.543      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.145       |\n",
      "|    n_updates            | 19300       |\n",
      "|    policy_gradient_loss | 0.000772    |\n",
      "|    value_loss           | 0.799       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1932       |\n",
      "|    time_elapsed         | 14220      |\n",
      "|    total_timesteps      | 3956736    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08960892 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.442     |\n",
      "|    explained_variance   | 0.266      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 19310      |\n",
      "|    policy_gradient_loss | 0.029      |\n",
      "|    value_loss           | 14.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1933        |\n",
      "|    time_elapsed         | 14227       |\n",
      "|    total_timesteps      | 3958784     |\n",
      "| total_reward_steps      | 107         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040819757 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | -0.00424    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.518       |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | 0.00967     |\n",
      "|    value_loss           | 0.464       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1934        |\n",
      "|    time_elapsed         | 14234       |\n",
      "|    total_timesteps      | 3960832     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045329094 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.02        |\n",
      "|    n_updates            | 19330       |\n",
      "|    policy_gradient_loss | 0.015       |\n",
      "|    value_loss           | 2.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 14241       |\n",
      "|    total_timesteps      | 3962880     |\n",
      "| total_reward_steps      | 26          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042077757 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.416      |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | 0.0239      |\n",
      "|    value_loss           | 2.84        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 14248       |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| total_reward_steps      | 75          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028562447 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    value_loss           | 0.321       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1937        |\n",
      "|    time_elapsed         | 14254       |\n",
      "|    total_timesteps      | 3966976     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025751332 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.565      |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 19360       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 0.358       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1938        |\n",
      "|    time_elapsed         | 14261       |\n",
      "|    total_timesteps      | 3969024     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015728477 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 19370       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.452       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1939       |\n",
      "|    time_elapsed         | 14268      |\n",
      "|    total_timesteps      | 3971072    |\n",
      "| total_reward_steps      | 75         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07009643 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.684     |\n",
      "|    explained_variance   | 0.472      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0284     |\n",
      "|    n_updates            | 19380      |\n",
      "|    policy_gradient_loss | -0.000404  |\n",
      "|    value_loss           | 1.53       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 14275       |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016446413 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.817      |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.184       |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 0.291       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1941        |\n",
      "|    time_elapsed         | 14282       |\n",
      "|    total_timesteps      | 3975168     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021538999 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.798      |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0714      |\n",
      "|    n_updates            | 19400       |\n",
      "|    policy_gradient_loss | 0.00351     |\n",
      "|    value_loss           | 1.78        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 14288       |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037074823 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0769      |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | 0.00907     |\n",
      "|    value_loss           | 2.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 14295       |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032143906 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.109       |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1944       |\n",
      "|    time_elapsed         | 14303      |\n",
      "|    total_timesteps      | 3981312    |\n",
      "| total_reward_steps      | 90         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02744053 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.649     |\n",
      "|    explained_variance   | 0.275      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.101      |\n",
      "|    n_updates            | 19430      |\n",
      "|    policy_gradient_loss | 0.0164     |\n",
      "|    value_loss           | 0.689      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1945        |\n",
      "|    time_elapsed         | 14310       |\n",
      "|    total_timesteps      | 3983360     |\n",
      "| total_reward_steps      | 115         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017112086 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0141      |\n",
      "|    n_updates            | 19440       |\n",
      "|    policy_gradient_loss | 0.000379    |\n",
      "|    value_loss           | 0.322       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1946        |\n",
      "|    time_elapsed         | 14318       |\n",
      "|    total_timesteps      | 3985408     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017252102 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 19450       |\n",
      "|    policy_gradient_loss | 0.00695     |\n",
      "|    value_loss           | 1.32        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1947        |\n",
      "|    time_elapsed         | 14326       |\n",
      "|    total_timesteps      | 3987456     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017392877 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0693      |\n",
      "|    n_updates            | 19460       |\n",
      "|    policy_gradient_loss | -0.000185   |\n",
      "|    value_loss           | 0.325       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 14334       |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015175302 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.274       |\n",
      "|    n_updates            | 19470       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 0.664       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1949        |\n",
      "|    time_elapsed         | 14341       |\n",
      "|    total_timesteps      | 3991552     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017141439 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.21        |\n",
      "|    n_updates            | 19480       |\n",
      "|    policy_gradient_loss | -0.000763   |\n",
      "|    value_loss           | 0.865       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 278        |\n",
      "|    iterations           | 1950       |\n",
      "|    time_elapsed         | 14349      |\n",
      "|    total_timesteps      | 3993600    |\n",
      "| total_reward_steps      | 71         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02769382 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.83      |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0576     |\n",
      "|    n_updates            | 19490      |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    value_loss           | 0.532      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1951        |\n",
      "|    time_elapsed         | 14356       |\n",
      "|    total_timesteps      | 3995648     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023655413 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 0.647       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1952        |\n",
      "|    time_elapsed         | 14363       |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034119517 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.745      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0584      |\n",
      "|    n_updates            | 19510       |\n",
      "|    policy_gradient_loss | 0.00751     |\n",
      "|    value_loss           | 1.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 1953        |\n",
      "|    time_elapsed         | 14371       |\n",
      "|    total_timesteps      | 3999744     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024460565 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.181       |\n",
      "|    n_updates            | 19520       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 0.431       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=70.80 +/- 9.20\n",
      "Episode length: 829.57 +/- 106.63\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 830        |\n",
      "|    mean_reward          | 70.8       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4000000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04417518 |\n",
      "|    clip_fraction        | 0.467      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.744     |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.27       |\n",
      "|    n_updates            | 19530      |\n",
      "|    policy_gradient_loss | 0.0168     |\n",
      "|    value_loss           | 2.12       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 277      |\n",
      "|    iterations      | 1954     |\n",
      "|    time_elapsed    | 14411    |\n",
      "|    total_timesteps | 4001792  |\n",
      "| total_reward_steps | 223      |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 277       |\n",
      "|    iterations           | 1955      |\n",
      "|    time_elapsed         | 14419     |\n",
      "|    total_timesteps      | 4003840   |\n",
      "| total_reward_steps      | 68        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1567766 |\n",
      "|    clip_fraction        | 0.462     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.604    |\n",
      "|    explained_variance   | 0.401     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 91        |\n",
      "|    n_updates            | 19540     |\n",
      "|    policy_gradient_loss | 0.0645    |\n",
      "|    value_loss           | 14.5      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1956       |\n",
      "|    time_elapsed         | 14426      |\n",
      "|    total_timesteps      | 4005888    |\n",
      "| total_reward_steps      | 100        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04457628 |\n",
      "|    clip_fraction        | 0.454      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.704     |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.207      |\n",
      "|    n_updates            | 19550      |\n",
      "|    policy_gradient_loss | 0.015      |\n",
      "|    value_loss           | 0.503      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 14434       |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035060316 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.665       |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 14442       |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018365694 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.592      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0698      |\n",
      "|    n_updates            | 19570       |\n",
      "|    policy_gradient_loss | 0.000518    |\n",
      "|    value_loss           | 0.338       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1959        |\n",
      "|    time_elapsed         | 14449       |\n",
      "|    total_timesteps      | 4012032     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017791687 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 19580       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 0.162       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 14457       |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012003511 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 19590       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1961        |\n",
      "|    time_elapsed         | 14464       |\n",
      "|    total_timesteps      | 4016128     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017912805 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 14472       |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| total_reward_steps      | 186         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017396014 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.781      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0853      |\n",
      "|    n_updates            | 19610       |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1963       |\n",
      "|    time_elapsed         | 14479      |\n",
      "|    total_timesteps      | 4020224    |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03227408 |\n",
      "|    clip_fraction        | 0.449      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.752     |\n",
      "|    explained_variance   | 0.208      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.198      |\n",
      "|    n_updates            | 19620      |\n",
      "|    policy_gradient_loss | 0.0297     |\n",
      "|    value_loss           | 6.09       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1964        |\n",
      "|    time_elapsed         | 14487       |\n",
      "|    total_timesteps      | 4022272     |\n",
      "| total_reward_steps      | 18          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019645074 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | -0.256      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 19630       |\n",
      "|    policy_gradient_loss | 0.0086      |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1965       |\n",
      "|    time_elapsed         | 14494      |\n",
      "|    total_timesteps      | 4024320    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06810206 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.652     |\n",
      "|    explained_variance   | 0.143      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.844      |\n",
      "|    n_updates            | 19640      |\n",
      "|    policy_gradient_loss | 0.0367     |\n",
      "|    value_loss           | 5.38       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1966       |\n",
      "|    time_elapsed         | 14502      |\n",
      "|    total_timesteps      | 4026368    |\n",
      "| total_reward_steps      | 55         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05199035 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.771     |\n",
      "|    explained_variance   | 0.202      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.272      |\n",
      "|    n_updates            | 19650      |\n",
      "|    policy_gradient_loss | 0.0151     |\n",
      "|    value_loss           | 2.29       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 14509       |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031595778 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0906      |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    value_loss           | 0.311       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1968        |\n",
      "|    time_elapsed         | 14517       |\n",
      "|    total_timesteps      | 4030464     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033090807 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.712      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    value_loss           | 1.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1969       |\n",
      "|    time_elapsed         | 14525      |\n",
      "|    total_timesteps      | 4032512    |\n",
      "| total_reward_steps      | 60         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01905268 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.798     |\n",
      "|    explained_variance   | 0.779      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0595     |\n",
      "|    n_updates            | 19680      |\n",
      "|    policy_gradient_loss | -0.00278   |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1970        |\n",
      "|    time_elapsed         | 14532       |\n",
      "|    total_timesteps      | 4034560     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023284506 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.799      |\n",
      "|    explained_variance   | 0.774       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0411      |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | 0.00273     |\n",
      "|    value_loss           | 0.491       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 14540       |\n",
      "|    total_timesteps      | 4036608     |\n",
      "| total_reward_steps      | 104         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018104902 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0397      |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1972        |\n",
      "|    time_elapsed         | 14548       |\n",
      "|    total_timesteps      | 4038656     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028507695 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00191    |\n",
      "|    value_loss           | 0.629       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1973        |\n",
      "|    time_elapsed         | 14555       |\n",
      "|    total_timesteps      | 4040704     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027146947 |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | -0.0206     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00621    |\n",
      "|    n_updates            | 19720       |\n",
      "|    policy_gradient_loss | -0.00784    |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 14563       |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019193117 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.953      |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | 0.00323     |\n",
      "|    value_loss           | 0.671       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1975        |\n",
      "|    time_elapsed         | 14571       |\n",
      "|    total_timesteps      | 4044800     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023718193 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 0.146       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1976        |\n",
      "|    time_elapsed         | 14578       |\n",
      "|    total_timesteps      | 4046848     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023090487 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.285       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 14586       |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014039258 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00148    |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1978        |\n",
      "|    time_elapsed         | 14594       |\n",
      "|    total_timesteps      | 4050944     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024374414 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.086       |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    value_loss           | 0.374       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1979        |\n",
      "|    time_elapsed         | 14601       |\n",
      "|    total_timesteps      | 4052992     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015831415 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.802      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 19780       |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    value_loss           | 5.87        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1980        |\n",
      "|    time_elapsed         | 14609       |\n",
      "|    total_timesteps      | 4055040     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013821296 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 14617       |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037237562 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.359       |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | 0.0196      |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1982        |\n",
      "|    time_elapsed         | 14624       |\n",
      "|    total_timesteps      | 4059136     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023256067 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0852      |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1983        |\n",
      "|    time_elapsed         | 14631       |\n",
      "|    total_timesteps      | 4061184     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025493097 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.242       |\n",
      "|    n_updates            | 19820       |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 14638       |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032941647 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0687      |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 0.261       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1985        |\n",
      "|    time_elapsed         | 14646       |\n",
      "|    total_timesteps      | 4065280     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023903187 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0671      |\n",
      "|    n_updates            | 19840       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1986        |\n",
      "|    time_elapsed         | 14653       |\n",
      "|    total_timesteps      | 4067328     |\n",
      "| total_reward_steps      | 108         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017819766 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0908      |\n",
      "|    n_updates            | 19850       |\n",
      "|    policy_gradient_loss | -0.000763   |\n",
      "|    value_loss           | 0.16        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1987        |\n",
      "|    time_elapsed         | 14660       |\n",
      "|    total_timesteps      | 4069376     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058388125 |\n",
      "|    clip_fraction        | 0.459       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | 0.00896     |\n",
      "|    value_loss           | 1.81        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1988        |\n",
      "|    time_elapsed         | 14668       |\n",
      "|    total_timesteps      | 4071424     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021068765 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.42        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    value_loss           | 0.486       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1989       |\n",
      "|    time_elapsed         | 14676      |\n",
      "|    total_timesteps      | 4073472    |\n",
      "| total_reward_steps      | 74         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03631723 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.777     |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0658     |\n",
      "|    n_updates            | 19880      |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    value_loss           | 5.48       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1990        |\n",
      "|    time_elapsed         | 14683       |\n",
      "|    total_timesteps      | 4075520     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016768176 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0388      |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.00612    |\n",
      "|    value_loss           | 0.356       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1991        |\n",
      "|    time_elapsed         | 14691       |\n",
      "|    total_timesteps      | 4077568     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040407248 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.753      |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.73        |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 14699       |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024869535 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.2         |\n",
      "|    n_updates            | 19910       |\n",
      "|    policy_gradient_loss | 0.00292     |\n",
      "|    value_loss           | 0.525       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1993       |\n",
      "|    time_elapsed         | 14706      |\n",
      "|    total_timesteps      | 4081664    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03057142 |\n",
      "|    clip_fraction        | 0.409      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.762     |\n",
      "|    explained_variance   | 0.431      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0812     |\n",
      "|    n_updates            | 19920      |\n",
      "|    policy_gradient_loss | 0.00976    |\n",
      "|    value_loss           | 1.51       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 14714       |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| total_reward_steps      | 92          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029663611 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.554       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.481       |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | 0.0038      |\n",
      "|    value_loss           | 0.689       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1995       |\n",
      "|    time_elapsed         | 14721      |\n",
      "|    total_timesteps      | 4085760    |\n",
      "| total_reward_steps      | 33         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02615928 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.723     |\n",
      "|    explained_variance   | 0.749      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.06       |\n",
      "|    n_updates            | 19940      |\n",
      "|    policy_gradient_loss | 0.00424    |\n",
      "|    value_loss           | 0.493      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 14729       |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026204986 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.67        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0764      |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1997        |\n",
      "|    time_elapsed         | 14736       |\n",
      "|    total_timesteps      | 4089856     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015836464 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0838      |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | -0.00822    |\n",
      "|    value_loss           | 0.127       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 1998        |\n",
      "|    time_elapsed         | 14744       |\n",
      "|    total_timesteps      | 4091904     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021072634 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | -0.000285   |\n",
      "|    value_loss           | 0.263       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 1999       |\n",
      "|    time_elapsed         | 14752      |\n",
      "|    total_timesteps      | 4093952    |\n",
      "| total_reward_steps      | 110        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03177179 |\n",
      "|    clip_fraction        | 0.443      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.818     |\n",
      "|    explained_variance   | 0.123      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 19980      |\n",
      "|    policy_gradient_loss | 0.0167     |\n",
      "|    value_loss           | 8.97       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 2000        |\n",
      "|    time_elapsed         | 14760       |\n",
      "|    total_timesteps      | 4096000     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023734476 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.934       |\n",
      "|    n_updates            | 19990       |\n",
      "|    policy_gradient_loss | 0.00923     |\n",
      "|    value_loss           | 2.15        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 277        |\n",
      "|    iterations           | 2001       |\n",
      "|    time_elapsed         | 14769      |\n",
      "|    total_timesteps      | 4098048    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02170406 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.717     |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0638     |\n",
      "|    n_updates            | 20000      |\n",
      "|    policy_gradient_loss | -0.00438   |\n",
      "|    value_loss           | 0.161      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=67.70 +/- 8.77\n",
      "Episode length: 937.73 +/- 141.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 938         |\n",
      "|    mean_reward          | 67.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4100000     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022346087 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.769      |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0759      |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 0.142       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 276     |\n",
      "|    iterations      | 2002    |\n",
      "|    time_elapsed    | 14821   |\n",
      "|    total_timesteps | 4100096 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2003       |\n",
      "|    time_elapsed         | 14830      |\n",
      "|    total_timesteps      | 4102144    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07402272 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.622     |\n",
      "|    explained_variance   | 0.145      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 20020      |\n",
      "|    policy_gradient_loss | 0.0349     |\n",
      "|    value_loss           | 9.32       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2004        |\n",
      "|    time_elapsed         | 14839       |\n",
      "|    total_timesteps      | 4104192     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029925194 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.804      |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.412       |\n",
      "|    n_updates            | 20030       |\n",
      "|    policy_gradient_loss | 0.0219      |\n",
      "|    value_loss           | 3.53        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2005        |\n",
      "|    time_elapsed         | 14847       |\n",
      "|    total_timesteps      | 4106240     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020146973 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | 0.000285    |\n",
      "|    value_loss           | 1.27        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2006       |\n",
      "|    time_elapsed         | 14855      |\n",
      "|    total_timesteps      | 4108288    |\n",
      "| total_reward_steps      | 212        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02829761 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.677     |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.22       |\n",
      "|    n_updates            | 20050      |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    value_loss           | 6.37       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2007        |\n",
      "|    time_elapsed         | 14864       |\n",
      "|    total_timesteps      | 4110336     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023700312 |\n",
      "|    clip_fraction        | 0.427       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.918      |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0033      |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    value_loss           | 0.216       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 14873       |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017411731 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.187       |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 0.444       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2009        |\n",
      "|    time_elapsed         | 14882       |\n",
      "|    total_timesteps      | 4114432     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013297419 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.106       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2010        |\n",
      "|    time_elapsed         | 14891       |\n",
      "|    total_timesteps      | 4116480     |\n",
      "| total_reward_steps      | 347         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012301514 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.873      |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.031       |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2011       |\n",
      "|    time_elapsed         | 14901      |\n",
      "|    total_timesteps      | 4118528    |\n",
      "| total_reward_steps      | 56         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07400733 |\n",
      "|    clip_fraction        | 0.478      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.827     |\n",
      "|    explained_variance   | 0.0726     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.195      |\n",
      "|    n_updates            | 20100      |\n",
      "|    policy_gradient_loss | 0.0229     |\n",
      "|    value_loss           | 42         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2012        |\n",
      "|    time_elapsed         | 14910       |\n",
      "|    total_timesteps      | 4120576     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020635782 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 0.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 14919       |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019946676 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | 0.000543    |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2014        |\n",
      "|    time_elapsed         | 14928       |\n",
      "|    total_timesteps      | 4124672     |\n",
      "| total_reward_steps      | 68          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030989358 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | -0.0634     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.087       |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    value_loss           | 0.858       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2015        |\n",
      "|    time_elapsed         | 14936       |\n",
      "|    total_timesteps      | 4126720     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034441926 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.729      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | 0.0212      |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2016        |\n",
      "|    time_elapsed         | 14945       |\n",
      "|    total_timesteps      | 4128768     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028420202 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | -0.375      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.185       |\n",
      "|    n_updates            | 20150       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    value_loss           | 2.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2017        |\n",
      "|    time_elapsed         | 14953       |\n",
      "|    total_timesteps      | 4130816     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014504941 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0914      |\n",
      "|    n_updates            | 20160       |\n",
      "|    policy_gradient_loss | 0.00637     |\n",
      "|    value_loss           | 0.613       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 14961       |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| total_reward_steps      | 346         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022092093 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.0832      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 20170       |\n",
      "|    policy_gradient_loss | 0.00665     |\n",
      "|    value_loss           | 0.553       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 276       |\n",
      "|    iterations           | 2019      |\n",
      "|    time_elapsed         | 14970     |\n",
      "|    total_timesteps      | 4134912   |\n",
      "| total_reward_steps      | 78        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1475759 |\n",
      "|    clip_fraction        | 0.47      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.579    |\n",
      "|    explained_variance   | 0.211     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.975     |\n",
      "|    n_updates            | 20180     |\n",
      "|    policy_gradient_loss | 0.0468    |\n",
      "|    value_loss           | 35.4      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2020       |\n",
      "|    time_elapsed         | 14979      |\n",
      "|    total_timesteps      | 4136960    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06696976 |\n",
      "|    clip_fraction        | 0.478      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.671     |\n",
      "|    explained_variance   | -0.695     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0721     |\n",
      "|    n_updates            | 20190      |\n",
      "|    policy_gradient_loss | 0.0326     |\n",
      "|    value_loss           | 0.859      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2021        |\n",
      "|    time_elapsed         | 14988       |\n",
      "|    total_timesteps      | 4139008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028376613 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0549      |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    value_loss           | 0.273       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2022       |\n",
      "|    time_elapsed         | 14997      |\n",
      "|    total_timesteps      | 4141056    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03521505 |\n",
      "|    clip_fraction        | 0.472      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.751     |\n",
      "|    explained_variance   | -0.059     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0499     |\n",
      "|    n_updates            | 20210      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 0.742      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2023        |\n",
      "|    time_elapsed         | 15006       |\n",
      "|    total_timesteps      | 4143104     |\n",
      "| total_reward_steps      | 350         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031362396 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.11        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    value_loss           | 6.83        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2024       |\n",
      "|    time_elapsed         | 15015      |\n",
      "|    total_timesteps      | 4145152    |\n",
      "| total_reward_steps      | 108        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07874404 |\n",
      "|    clip_fraction        | 0.419      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.6        |\n",
      "|    n_updates            | 20230      |\n",
      "|    policy_gradient_loss | 0.033      |\n",
      "|    value_loss           | 30.6       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 276        |\n",
      "|    iterations           | 2025       |\n",
      "|    time_elapsed         | 15024      |\n",
      "|    total_timesteps      | 4147200    |\n",
      "| total_reward_steps      | 117        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03419264 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.23      |\n",
      "|    explained_variance   | 0.473      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 39.3       |\n",
      "|    n_updates            | 20240      |\n",
      "|    policy_gradient_loss | 0.0181     |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 2026        |\n",
      "|    time_elapsed         | 15033       |\n",
      "|    total_timesteps      | 4149248     |\n",
      "| total_reward_steps      | 114         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025143784 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.349       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.401       |\n",
      "|    n_updates            | 20250       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    value_loss           | 0.625       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 275       |\n",
      "|    iterations           | 2027      |\n",
      "|    time_elapsed         | 15042     |\n",
      "|    total_timesteps      | 4151296   |\n",
      "| total_reward_steps      | 193       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0598308 |\n",
      "|    clip_fraction        | 0.497     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.719    |\n",
      "|    explained_variance   | -0.144    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.351     |\n",
      "|    n_updates            | 20260     |\n",
      "|    policy_gradient_loss | 0.00454   |\n",
      "|    value_loss           | 1.65      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2028       |\n",
      "|    time_elapsed         | 15051      |\n",
      "|    total_timesteps      | 4153344    |\n",
      "| total_reward_steps      | 63         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05501205 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.633     |\n",
      "|    explained_variance   | 0.362      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.248      |\n",
      "|    n_updates            | 20270      |\n",
      "|    policy_gradient_loss | 0.0186     |\n",
      "|    value_loss           | 9.95       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2029        |\n",
      "|    time_elapsed         | 15060       |\n",
      "|    total_timesteps      | 4155392     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025012173 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.605      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00681     |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    value_loss           | 0.409       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2030        |\n",
      "|    time_elapsed         | 15069       |\n",
      "|    total_timesteps      | 4157440     |\n",
      "| total_reward_steps      | 182         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030413402 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.688      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 20290       |\n",
      "|    policy_gradient_loss | 0.000805    |\n",
      "|    value_loss           | 0.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2031        |\n",
      "|    time_elapsed         | 15078       |\n",
      "|    total_timesteps      | 4159488     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058826074 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.946       |\n",
      "|    n_updates            | 20300       |\n",
      "|    policy_gradient_loss | 0.0357      |\n",
      "|    value_loss           | 13.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2032        |\n",
      "|    time_elapsed         | 15086       |\n",
      "|    total_timesteps      | 4161536     |\n",
      "| total_reward_steps      | 229         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047293328 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.223       |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    value_loss           | 2.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2033        |\n",
      "|    time_elapsed         | 15095       |\n",
      "|    total_timesteps      | 4163584     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048942283 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 7.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2034        |\n",
      "|    time_elapsed         | 15104       |\n",
      "|    total_timesteps      | 4165632     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020022174 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.108       |\n",
      "|    n_updates            | 20330       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    value_loss           | 0.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 15113       |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| total_reward_steps      | 196         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037308726 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0796      |\n",
      "|    n_updates            | 20340       |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2036       |\n",
      "|    time_elapsed         | 15122      |\n",
      "|    total_timesteps      | 4169728    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02872104 |\n",
      "|    clip_fraction        | 0.422      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.791     |\n",
      "|    explained_variance   | 0.516      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.23       |\n",
      "|    n_updates            | 20350      |\n",
      "|    policy_gradient_loss | 0.0156     |\n",
      "|    value_loss           | 9.01       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2037        |\n",
      "|    time_elapsed         | 15131       |\n",
      "|    total_timesteps      | 4171776     |\n",
      "| total_reward_steps      | 343         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040265556 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.439      |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.223       |\n",
      "|    n_updates            | 20360       |\n",
      "|    policy_gradient_loss | 0.0184      |\n",
      "|    value_loss           | 3.37        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2038       |\n",
      "|    time_elapsed         | 15140      |\n",
      "|    total_timesteps      | 4173824    |\n",
      "| total_reward_steps      | 190        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07048724 |\n",
      "|    clip_fraction        | 0.339      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.486     |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.242      |\n",
      "|    n_updates            | 20370      |\n",
      "|    policy_gradient_loss | 0.0563     |\n",
      "|    value_loss           | 36.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2039        |\n",
      "|    time_elapsed         | 15150       |\n",
      "|    total_timesteps      | 4175872     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045106713 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 20380       |\n",
      "|    policy_gradient_loss | 0.019       |\n",
      "|    value_loss           | 9.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2040        |\n",
      "|    time_elapsed         | 15159       |\n",
      "|    total_timesteps      | 4177920     |\n",
      "| total_reward_steps      | 105         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034423213 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.202       |\n",
      "|    n_updates            | 20390       |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    value_loss           | 12.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2041        |\n",
      "|    time_elapsed         | 15168       |\n",
      "|    total_timesteps      | 4179968     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024791623 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.978       |\n",
      "|    n_updates            | 20400       |\n",
      "|    policy_gradient_loss | 0.0135      |\n",
      "|    value_loss           | 12.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2042       |\n",
      "|    time_elapsed         | 15177      |\n",
      "|    total_timesteps      | 4182016    |\n",
      "| total_reward_steps      | 87         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03275721 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.459     |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.172      |\n",
      "|    n_updates            | 20410      |\n",
      "|    policy_gradient_loss | 0.00959    |\n",
      "|    value_loss           | 2.09       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2043       |\n",
      "|    time_elapsed         | 15186      |\n",
      "|    total_timesteps      | 4184064    |\n",
      "| total_reward_steps      | 111        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01934407 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.58      |\n",
      "|    explained_variance   | 0.727      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.33       |\n",
      "|    n_updates            | 20420      |\n",
      "|    policy_gradient_loss | 0.00797    |\n",
      "|    value_loss           | 4.81       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2044        |\n",
      "|    time_elapsed         | 15195       |\n",
      "|    total_timesteps      | 4186112     |\n",
      "| total_reward_steps      | 342         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027135935 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.597      |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.413       |\n",
      "|    n_updates            | 20430       |\n",
      "|    policy_gradient_loss | 0.00332     |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2045       |\n",
      "|    time_elapsed         | 15204      |\n",
      "|    total_timesteps      | 4188160    |\n",
      "| total_reward_steps      | 183        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03866069 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.553     |\n",
      "|    explained_variance   | 0.0744     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 28.4       |\n",
      "|    n_updates            | 20440      |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    value_loss           | 33         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2046        |\n",
      "|    time_elapsed         | 15213       |\n",
      "|    total_timesteps      | 4190208     |\n",
      "| total_reward_steps      | 74          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.099685274 |\n",
      "|    clip_fraction        | 0.43        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.983       |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | 0.0322      |\n",
      "|    value_loss           | 12.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 15222       |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| total_reward_steps      | 180         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029766347 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.653      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | 0.017       |\n",
      "|    value_loss           | 0.821       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 15231       |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| total_reward_steps      | 199         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057761744 |\n",
      "|    clip_fraction        | 0.381       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.589      |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 9.97        |\n",
      "|    n_updates            | 20470       |\n",
      "|    policy_gradient_loss | 0.0324      |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2049       |\n",
      "|    time_elapsed         | 15239      |\n",
      "|    total_timesteps      | 4196352    |\n",
      "| total_reward_steps      | 191        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07964781 |\n",
      "|    clip_fraction        | 0.34       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.463     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 82.2       |\n",
      "|    n_updates            | 20480      |\n",
      "|    policy_gradient_loss | 0.0293     |\n",
      "|    value_loss           | 10.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 15248       |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017802926 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | 0.0216      |\n",
      "|    value_loss           | 6.12        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=141.30 +/- 103.33\n",
      "Episode length: 765.80 +/- 84.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 766         |\n",
      "|    mean_reward          | 141         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4200000     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020203635 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.671       |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | 0.00792     |\n",
      "|    value_loss           | 3.11        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 274      |\n",
      "|    iterations      | 2051     |\n",
      "|    time_elapsed    | 15292    |\n",
      "|    total_timesteps | 4200448  |\n",
      "| total_reward_steps | 107      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2052        |\n",
      "|    time_elapsed         | 15301       |\n",
      "|    total_timesteps      | 4202496     |\n",
      "| total_reward_steps      | 189         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034208354 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | 0.00359     |\n",
      "|    value_loss           | 0.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 15310       |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| total_reward_steps      | 183         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028545015 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.949       |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    value_loss           | 4.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2054        |\n",
      "|    time_elapsed         | 15319       |\n",
      "|    total_timesteps      | 4206592     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023738988 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.26        |\n",
      "|    n_updates            | 20530       |\n",
      "|    policy_gradient_loss | 0.0079      |\n",
      "|    value_loss           | 5.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2055        |\n",
      "|    time_elapsed         | 15328       |\n",
      "|    total_timesteps      | 4208640     |\n",
      "| total_reward_steps      | 351         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013976887 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0968      |\n",
      "|    n_updates            | 20540       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2056       |\n",
      "|    time_elapsed         | 15337      |\n",
      "|    total_timesteps      | 4210688    |\n",
      "| total_reward_steps      | 122        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04582742 |\n",
      "|    clip_fraction        | 0.435      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.638     |\n",
      "|    explained_variance   | 0.191      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.09       |\n",
      "|    n_updates            | 20550      |\n",
      "|    policy_gradient_loss | 0.0377     |\n",
      "|    value_loss           | 37.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 15346       |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025238067 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 20560       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 0.542       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2058        |\n",
      "|    time_elapsed         | 15355       |\n",
      "|    total_timesteps      | 4214784     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034147263 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 3.87        |\n",
      "|    n_updates            | 20570       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    value_loss           | 12.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2059        |\n",
      "|    time_elapsed         | 15364       |\n",
      "|    total_timesteps      | 4216832     |\n",
      "| total_reward_steps      | 198         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023543518 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.183       |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | 0.00703     |\n",
      "|    value_loss           | 0.758       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2060        |\n",
      "|    time_elapsed         | 15373       |\n",
      "|    total_timesteps      | 4218880     |\n",
      "| total_reward_steps      | 194         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040621858 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 20590       |\n",
      "|    policy_gradient_loss | 0.0207      |\n",
      "|    value_loss           | 13.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2061        |\n",
      "|    time_elapsed         | 15382       |\n",
      "|    total_timesteps      | 4220928     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042698063 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.755       |\n",
      "|    n_updates            | 20600       |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2062        |\n",
      "|    time_elapsed         | 15391       |\n",
      "|    total_timesteps      | 4222976     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046715938 |\n",
      "|    clip_fraction        | 0.42        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.7        |\n",
      "|    explained_variance   | -0.196      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.194       |\n",
      "|    n_updates            | 20610       |\n",
      "|    policy_gradient_loss | 0.0155      |\n",
      "|    value_loss           | 0.772       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 15401       |\n",
      "|    total_timesteps      | 4225024     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033165134 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 20620       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    value_loss           | 8.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2064        |\n",
      "|    time_elapsed         | 15409       |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028170079 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 20630       |\n",
      "|    policy_gradient_loss | 0.00509     |\n",
      "|    value_loss           | 1.41        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2065       |\n",
      "|    time_elapsed         | 15419      |\n",
      "|    total_timesteps      | 4229120    |\n",
      "| total_reward_steps      | 194        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03269168 |\n",
      "|    clip_fraction        | 0.406      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.685     |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.11       |\n",
      "|    n_updates            | 20640      |\n",
      "|    policy_gradient_loss | 0.0308     |\n",
      "|    value_loss           | 11.1       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2066       |\n",
      "|    time_elapsed         | 15428      |\n",
      "|    total_timesteps      | 4231168    |\n",
      "| total_reward_steps      | 355        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01940846 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.556     |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.142      |\n",
      "|    n_updates            | 20650      |\n",
      "|    policy_gradient_loss | 0.00603    |\n",
      "|    value_loss           | 4.79       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 15437       |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044785723 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 267         |\n",
      "|    n_updates            | 20660       |\n",
      "|    policy_gradient_loss | 0.0216      |\n",
      "|    value_loss           | 31.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2068        |\n",
      "|    time_elapsed         | 15446       |\n",
      "|    total_timesteps      | 4235264     |\n",
      "| total_reward_steps      | 188         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029673934 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.527      |\n",
      "|    explained_variance   | -0.243      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 20670       |\n",
      "|    policy_gradient_loss | 0.00636     |\n",
      "|    value_loss           | 0.83        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 15455       |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| total_reward_steps      | 181         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049942985 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.542       |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | 0.0324      |\n",
      "|    value_loss           | 9.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 15464       |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| total_reward_steps      | 193         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025043031 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | 0.0175      |\n",
      "|    value_loss           | 13.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2071       |\n",
      "|    time_elapsed         | 15473      |\n",
      "|    total_timesteps      | 4241408    |\n",
      "| total_reward_steps      | 130        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01759944 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.513     |\n",
      "|    explained_variance   | 0.796      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0944     |\n",
      "|    n_updates            | 20700      |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    value_loss           | 7.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 2072        |\n",
      "|    time_elapsed         | 15482       |\n",
      "|    total_timesteps      | 4243456     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023322016 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.27        |\n",
      "|    n_updates            | 20710       |\n",
      "|    policy_gradient_loss | 0.00664     |\n",
      "|    value_loss           | 2.18        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2073       |\n",
      "|    time_elapsed         | 15492      |\n",
      "|    total_timesteps      | 4245504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13189346 |\n",
      "|    clip_fraction        | 0.432      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.606     |\n",
      "|    explained_variance   | 0.0429     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.725      |\n",
      "|    n_updates            | 20720      |\n",
      "|    policy_gradient_loss | 0.0777     |\n",
      "|    value_loss           | 48.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 274        |\n",
      "|    iterations           | 2074       |\n",
      "|    time_elapsed         | 15501      |\n",
      "|    total_timesteps      | 4247552    |\n",
      "| total_reward_steps      | 208        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02270816 |\n",
      "|    clip_fraction        | 0.308      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.522     |\n",
      "|    explained_variance   | 0.468      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.363      |\n",
      "|    n_updates            | 20730      |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    value_loss           | 3.08       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2075       |\n",
      "|    time_elapsed         | 15510      |\n",
      "|    total_timesteps      | 4249600    |\n",
      "| total_reward_steps      | 44         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06291993 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.503     |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 2.01       |\n",
      "|    n_updates            | 20740      |\n",
      "|    policy_gradient_loss | 0.0196     |\n",
      "|    value_loss           | 8.78       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2076       |\n",
      "|    time_elapsed         | 15519      |\n",
      "|    total_timesteps      | 4251648    |\n",
      "| total_reward_steps      | 201        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05273807 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.585     |\n",
      "|    explained_variance   | -0.339     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0448     |\n",
      "|    n_updates            | 20750      |\n",
      "|    policy_gradient_loss | 0.00135    |\n",
      "|    value_loss           | 0.262      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2077       |\n",
      "|    time_elapsed         | 15529      |\n",
      "|    total_timesteps      | 4253696    |\n",
      "| total_reward_steps      | 63         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04061816 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.663     |\n",
      "|    explained_variance   | 0.221      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.392      |\n",
      "|    n_updates            | 20760      |\n",
      "|    policy_gradient_loss | 0.0308     |\n",
      "|    value_loss           | 7.2        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 273       |\n",
      "|    iterations           | 2078      |\n",
      "|    time_elapsed         | 15538     |\n",
      "|    total_timesteps      | 4255744   |\n",
      "| total_reward_steps      | 68        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1318044 |\n",
      "|    clip_fraction        | 0.352     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.444    |\n",
      "|    explained_variance   | 0.141     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.351     |\n",
      "|    n_updates            | 20770     |\n",
      "|    policy_gradient_loss | 0.0286    |\n",
      "|    value_loss           | 9.03      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2079       |\n",
      "|    time_elapsed         | 15547      |\n",
      "|    total_timesteps      | 4257792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02859147 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.519     |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0692     |\n",
      "|    n_updates            | 20780      |\n",
      "|    policy_gradient_loss | 0.00514    |\n",
      "|    value_loss           | 0.436      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2080        |\n",
      "|    time_elapsed         | 15555       |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016343065 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.231       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0735      |\n",
      "|    n_updates            | 20790       |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    value_loss           | 0.332       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 2081         |\n",
      "|    time_elapsed         | 15564        |\n",
      "|    total_timesteps      | 4261888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063272435 |\n",
      "|    clip_fraction        | 0.301        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | -3.47        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00455      |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | 0.00212      |\n",
      "|    value_loss           | 0.016        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 273          |\n",
      "|    iterations           | 2082         |\n",
      "|    time_elapsed         | 15573        |\n",
      "|    total_timesteps      | 4263936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065278094 |\n",
      "|    clip_fraction        | 0.287        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | -3.04        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0141       |\n",
      "|    n_updates            | 20810        |\n",
      "|    policy_gradient_loss | -0.000185    |\n",
      "|    value_loss           | 0.0123       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2083        |\n",
      "|    time_elapsed         | 15581       |\n",
      "|    total_timesteps      | 4265984     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004264213 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -20.4       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00906    |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.000933   |\n",
      "|    value_loss           | 0.0044      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2084       |\n",
      "|    time_elapsed         | 15590      |\n",
      "|    total_timesteps      | 4268032    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02849651 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.734     |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0301     |\n",
      "|    n_updates            | 20830      |\n",
      "|    policy_gradient_loss | 0.00666    |\n",
      "|    value_loss           | 0.106      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2085        |\n",
      "|    time_elapsed         | 15599       |\n",
      "|    total_timesteps      | 4270080     |\n",
      "| total_reward_steps      | 30          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031056654 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.129       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.179       |\n",
      "|    n_updates            | 20840       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2086        |\n",
      "|    time_elapsed         | 15608       |\n",
      "|    total_timesteps      | 4272128     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034397688 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 0.573       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2087        |\n",
      "|    time_elapsed         | 15617       |\n",
      "|    total_timesteps      | 4274176     |\n",
      "| total_reward_steps      | 195         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034617186 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.096       |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | 0.00978     |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2088        |\n",
      "|    time_elapsed         | 15626       |\n",
      "|    total_timesteps      | 4276224     |\n",
      "| total_reward_steps      | 204         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.120300174 |\n",
      "|    clip_fraction        | 0.571       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.118       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 20870       |\n",
      "|    policy_gradient_loss | 0.0541      |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2089       |\n",
      "|    time_elapsed         | 15636      |\n",
      "|    total_timesteps      | 4278272    |\n",
      "| total_reward_steps      | 68         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07303867 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.589     |\n",
      "|    explained_variance   | 0.452      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.8        |\n",
      "|    n_updates            | 20880      |\n",
      "|    policy_gradient_loss | 0.0245     |\n",
      "|    value_loss           | 32.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2090        |\n",
      "|    time_elapsed         | 15645       |\n",
      "|    total_timesteps      | 4280320     |\n",
      "| total_reward_steps      | 32          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035125032 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.034       |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    value_loss           | 0.238       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2091       |\n",
      "|    time_elapsed         | 15654      |\n",
      "|    total_timesteps      | 4282368    |\n",
      "| total_reward_steps      | 98         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06246874 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.543     |\n",
      "|    explained_variance   | -0.00343   |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0745     |\n",
      "|    n_updates            | 20900      |\n",
      "|    policy_gradient_loss | 0.00114    |\n",
      "|    value_loss           | 0.158      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2092        |\n",
      "|    time_elapsed         | 15663       |\n",
      "|    total_timesteps      | 4284416     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026581192 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0634      |\n",
      "|    n_updates            | 20910       |\n",
      "|    policy_gradient_loss | 0.00649     |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2093        |\n",
      "|    time_elapsed         | 15672       |\n",
      "|    total_timesteps      | 4286464     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039975867 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.528      |\n",
      "|    explained_variance   | 0.295       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 0.169       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2094        |\n",
      "|    time_elapsed         | 15681       |\n",
      "|    total_timesteps      | 4288512     |\n",
      "| total_reward_steps      | 348         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019129269 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.0343      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0599      |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    value_loss           | 0.624       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2095        |\n",
      "|    time_elapsed         | 15690       |\n",
      "|    total_timesteps      | 4290560     |\n",
      "| total_reward_steps      | 9           |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.124770164 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | 0.0357      |\n",
      "|    value_loss           | 22.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 15699       |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| total_reward_steps      | 12          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042582206 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 0.0893      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0296      |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    value_loss           | 0.233       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2097       |\n",
      "|    time_elapsed         | 15709      |\n",
      "|    total_timesteps      | 4294656    |\n",
      "| total_reward_steps      | 11         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04863071 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.548     |\n",
      "|    explained_variance   | -0.384     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0124    |\n",
      "|    n_updates            | 20960      |\n",
      "|    policy_gradient_loss | 0.00644    |\n",
      "|    value_loss           | 0.38       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 273        |\n",
      "|    iterations           | 2098       |\n",
      "|    time_elapsed         | 15718      |\n",
      "|    total_timesteps      | 4296704    |\n",
      "| total_reward_steps      | 9          |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11770122 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.457     |\n",
      "|    explained_variance   | -0.346     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00856    |\n",
      "|    n_updates            | 20970      |\n",
      "|    policy_gradient_loss | 0.00117    |\n",
      "|    value_loss           | 0.14       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 2099        |\n",
      "|    time_elapsed         | 15727       |\n",
      "|    total_timesteps      | 4298752     |\n",
      "| total_reward_steps      | 23          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037203416 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.218      |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0377      |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 0.0445      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=19.90 +/- 7.15\n",
      "Episode length: 559.50 +/- 84.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 560         |\n",
      "|    mean_reward          | 19.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4300000     |\n",
      "| total_reward_steps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033643186 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.349      |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0795      |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 0.058       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 272      |\n",
      "|    iterations      | 2100     |\n",
      "|    time_elapsed    | 15763    |\n",
      "|    total_timesteps | 4300800  |\n",
      "| total_reward_steps | 59       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 15772       |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019807914 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00887    |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2102        |\n",
      "|    time_elapsed         | 15781       |\n",
      "|    total_timesteps      | 4304896     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027802117 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00662    |\n",
      "|    n_updates            | 21010       |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 2103       |\n",
      "|    time_elapsed         | 15790      |\n",
      "|    total_timesteps      | 4306944    |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05039588 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.602     |\n",
      "|    explained_variance   | 0.0648     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.00618   |\n",
      "|    n_updates            | 21020      |\n",
      "|    policy_gradient_loss | -0.000455  |\n",
      "|    value_loss           | 0.505      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 15799       |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031217424 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.649      |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 21030       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2105        |\n",
      "|    time_elapsed         | 15809       |\n",
      "|    total_timesteps      | 4311040     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022190046 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.771      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.065       |\n",
      "|    n_updates            | 21040       |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 2106       |\n",
      "|    time_elapsed         | 15818      |\n",
      "|    total_timesteps      | 4313088    |\n",
      "| total_reward_steps      | 48         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06202031 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.783     |\n",
      "|    explained_variance   | 0.683      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0672     |\n",
      "|    n_updates            | 21050      |\n",
      "|    policy_gradient_loss | -0.00402   |\n",
      "|    value_loss           | 0.337      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2107        |\n",
      "|    time_elapsed         | 15827       |\n",
      "|    total_timesteps      | 4315136     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021551475 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0162      |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2108        |\n",
      "|    time_elapsed         | 15836       |\n",
      "|    total_timesteps      | 4317184     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028040603 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.696      |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0406      |\n",
      "|    n_updates            | 21070       |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    value_loss           | 0.616       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2109        |\n",
      "|    time_elapsed         | 15845       |\n",
      "|    total_timesteps      | 4319232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012627706 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.039       |\n",
      "|    n_updates            | 21080       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 0.112       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 2110         |\n",
      "|    time_elapsed         | 15854        |\n",
      "|    total_timesteps      | 4321280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059173205 |\n",
      "|    clip_fraction        | 0.194        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.782       |\n",
      "|    explained_variance   | -16.5        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0193       |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.000471    |\n",
      "|    value_loss           | 0.00852      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 15863       |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005834586 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.844      |\n",
      "|    explained_variance   | -16.5       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    value_loss           | 0.00405     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 2112         |\n",
      "|    time_elapsed         | 15872        |\n",
      "|    total_timesteps      | 4325376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054110466 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.752       |\n",
      "|    explained_variance   | -29.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00982     |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 0.00293      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 2113         |\n",
      "|    time_elapsed         | 15881        |\n",
      "|    total_timesteps      | 4327424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038066143 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.794       |\n",
      "|    explained_variance   | -34.7        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0125       |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    value_loss           | 0.00232      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 2114       |\n",
      "|    time_elapsed         | 15889      |\n",
      "|    total_timesteps      | 4329472    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00802134 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.782     |\n",
      "|    explained_variance   | -23.5      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.00731    |\n",
      "|    n_updates            | 21130      |\n",
      "|    policy_gradient_loss | 0.00051    |\n",
      "|    value_loss           | 0.00211    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 272          |\n",
      "|    iterations           | 2115         |\n",
      "|    time_elapsed         | 15898        |\n",
      "|    total_timesteps      | 4331520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045321938 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.822       |\n",
      "|    explained_variance   | -33.3        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0195      |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    value_loss           | 0.00186      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 15906       |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006433914 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | -31.8       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00471    |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00253    |\n",
      "|    value_loss           | 0.00141     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2117        |\n",
      "|    time_elapsed         | 15915       |\n",
      "|    total_timesteps      | 4335616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006254471 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | -35         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0214      |\n",
      "|    n_updates            | 21160       |\n",
      "|    policy_gradient_loss | -0.00286    |\n",
      "|    value_loss           | 0.00144     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 15924       |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007567424 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | -13.8       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0381     |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 0.00112     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2119        |\n",
      "|    time_elapsed         | 15933       |\n",
      "|    total_timesteps      | 4339712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004498897 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | -32.7       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 0.00129     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2120        |\n",
      "|    time_elapsed         | 15942       |\n",
      "|    total_timesteps      | 4341760     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008968915 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | -18.9       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00101     |\n",
      "|    n_updates            | 21190       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2121        |\n",
      "|    time_elapsed         | 15951       |\n",
      "|    total_timesteps      | 4343808     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025932718 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0169      |\n",
      "|    n_updates            | 21200       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2122        |\n",
      "|    time_elapsed         | 15961       |\n",
      "|    total_timesteps      | 4345856     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022924915 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0614      |\n",
      "|    n_updates            | 21210       |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2123        |\n",
      "|    time_elapsed         | 15970       |\n",
      "|    total_timesteps      | 4347904     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023258511 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.174       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00303     |\n",
      "|    n_updates            | 21220       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 0.506       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2124        |\n",
      "|    time_elapsed         | 15979       |\n",
      "|    total_timesteps      | 4349952     |\n",
      "| total_reward_steps      | 22          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025871309 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0348      |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.115       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 2125       |\n",
      "|    time_elapsed         | 15988      |\n",
      "|    total_timesteps      | 4352000    |\n",
      "| total_reward_steps      | 77         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02543614 |\n",
      "|    clip_fraction        | 0.343      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.758     |\n",
      "|    explained_variance   | 0.713      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0493     |\n",
      "|    n_updates            | 21240      |\n",
      "|    policy_gradient_loss | -0.00765   |\n",
      "|    value_loss           | 0.153      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 15997       |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019444676 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 21250       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2127        |\n",
      "|    time_elapsed         | 16007       |\n",
      "|    total_timesteps      | 4356096     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013379635 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.05        |\n",
      "|    n_updates            | 21260       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2128        |\n",
      "|    time_elapsed         | 16016       |\n",
      "|    total_timesteps      | 4358144     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015026327 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0568      |\n",
      "|    n_updates            | 21270       |\n",
      "|    policy_gradient_loss | 0.000142    |\n",
      "|    value_loss           | 0.61        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 272        |\n",
      "|    iterations           | 2129       |\n",
      "|    time_elapsed         | 16025      |\n",
      "|    total_timesteps      | 4360192    |\n",
      "| total_reward_steps      | 65         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03699955 |\n",
      "|    clip_fraction        | 0.385      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.049      |\n",
      "|    n_updates            | 21280      |\n",
      "|    policy_gradient_loss | -0.00438   |\n",
      "|    value_loss           | 0.154      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2130        |\n",
      "|    time_elapsed         | 16034       |\n",
      "|    total_timesteps      | 4362240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011845663 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 21290       |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    value_loss           | 0.0632      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 2131        |\n",
      "|    time_elapsed         | 16043       |\n",
      "|    total_timesteps      | 4364288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005634501 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -4.05       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0392     |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 0.012       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2132         |\n",
      "|    time_elapsed         | 16053        |\n",
      "|    total_timesteps      | 4366336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056247944 |\n",
      "|    clip_fraction        | 0.297        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | -2.85        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0124       |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 0.00632      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 16062       |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005664068 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.874      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 21320       |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    value_loss           | 0.00853     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2134         |\n",
      "|    time_elapsed         | 16071        |\n",
      "|    total_timesteps      | 4370432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059482944 |\n",
      "|    clip_fraction        | 0.251        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.34        |\n",
      "|    explained_variance   | -5.74        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0135      |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    value_loss           | 0.00229      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 16080       |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003405807 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -8.96       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    value_loss           | 0.00126     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 2136       |\n",
      "|    time_elapsed         | 16089      |\n",
      "|    total_timesteps      | 4374528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00359633 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | -11.4      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.034     |\n",
      "|    n_updates            | 21350      |\n",
      "|    policy_gradient_loss | -0.00514   |\n",
      "|    value_loss           | 0.000971   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2137         |\n",
      "|    time_elapsed         | 16098        |\n",
      "|    total_timesteps      | 4376576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033334652 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | -11.9        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0288      |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 0.000842     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2138         |\n",
      "|    time_elapsed         | 16107        |\n",
      "|    total_timesteps      | 4378624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043211034 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.35        |\n",
      "|    explained_variance   | -16.1        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0188      |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 0.000866     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2139        |\n",
      "|    time_elapsed         | 16117       |\n",
      "|    total_timesteps      | 4380672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005103482 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | -7.8        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    value_loss           | 0.000935    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 16126        |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036446566 |\n",
      "|    clip_fraction        | 0.189        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -11.9        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0245      |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 0.000876     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2141        |\n",
      "|    time_elapsed         | 16135       |\n",
      "|    total_timesteps      | 4384768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004521858 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | -24         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 21400       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    value_loss           | 0.00071     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 271          |\n",
      "|    iterations           | 2142         |\n",
      "|    time_elapsed         | 16144        |\n",
      "|    total_timesteps      | 4386816      |\n",
      "| total_reward_steps      | 44           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037476402 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | -20.1        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0301      |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00781     |\n",
      "|    value_loss           | 0.000797     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2143        |\n",
      "|    time_elapsed         | 16154       |\n",
      "|    total_timesteps      | 4388864     |\n",
      "| total_reward_steps      | 21          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019813694 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 21420       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    value_loss           | 0.0411      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2144        |\n",
      "|    time_elapsed         | 16163       |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022951301 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0349      |\n",
      "|    n_updates            | 21430       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 0.598       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 16172       |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018605521 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000501    |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0963      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 271        |\n",
      "|    iterations           | 2146       |\n",
      "|    time_elapsed         | 16181      |\n",
      "|    total_timesteps      | 4395008    |\n",
      "| total_reward_steps      | 34         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01558749 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.896     |\n",
      "|    explained_variance   | 0.669      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0228     |\n",
      "|    n_updates            | 21450      |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 0.086      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2147        |\n",
      "|    time_elapsed         | 16190       |\n",
      "|    total_timesteps      | 4397056     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063408695 |\n",
      "|    clip_fraction        | 0.513       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 76.9        |\n",
      "|    n_updates            | 21460       |\n",
      "|    policy_gradient_loss | 0.028       |\n",
      "|    value_loss           | 7.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 16199       |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| total_reward_steps      | 116         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031868655 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0779      |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 0.164       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4400000, episode_reward=46.43 +/- 19.37\n",
      "Episode length: 881.80 +/- 126.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 882         |\n",
      "|    mean_reward          | 46.4        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4400000     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027998911 |\n",
      "|    clip_fraction        | 0.433       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | 0.0187      |\n",
      "|    value_loss           | 2.02        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 270      |\n",
      "|    iterations      | 2149     |\n",
      "|    time_elapsed    | 16248    |\n",
      "|    total_timesteps | 4401152  |\n",
      "| total_reward_steps | 141      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2150        |\n",
      "|    time_elapsed         | 16257       |\n",
      "|    total_timesteps      | 4403200     |\n",
      "| total_reward_steps      | 78          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038635947 |\n",
      "|    clip_fraction        | 0.419       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 6.51        |\n",
      "|    n_updates            | 21490       |\n",
      "|    policy_gradient_loss | 0.00809     |\n",
      "|    value_loss           | 1.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2151        |\n",
      "|    time_elapsed         | 16266       |\n",
      "|    total_timesteps      | 4405248     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026963716 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0611      |\n",
      "|    n_updates            | 21500       |\n",
      "|    policy_gradient_loss | 0.00764     |\n",
      "|    value_loss           | 0.545       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 16275       |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022562353 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.352       |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2153        |\n",
      "|    time_elapsed         | 16284       |\n",
      "|    total_timesteps      | 4409344     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020638704 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0225      |\n",
      "|    n_updates            | 21520       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2154        |\n",
      "|    time_elapsed         | 16293       |\n",
      "|    total_timesteps      | 4411392     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021794297 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0736      |\n",
      "|    n_updates            | 21530       |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    value_loss           | 0.195       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2155        |\n",
      "|    time_elapsed         | 16302       |\n",
      "|    total_timesteps      | 4413440     |\n",
      "| total_reward_steps      | 199         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018240038 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0472      |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2156       |\n",
      "|    time_elapsed         | 16311      |\n",
      "|    total_timesteps      | 4415488    |\n",
      "| total_reward_steps      | 56         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05903694 |\n",
      "|    clip_fraction        | 0.483      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.927     |\n",
      "|    explained_variance   | 0.0568     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.359      |\n",
      "|    n_updates            | 21550      |\n",
      "|    policy_gradient_loss | 0.0493     |\n",
      "|    value_loss           | 7.07       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2157       |\n",
      "|    time_elapsed         | 16321      |\n",
      "|    total_timesteps      | 4417536    |\n",
      "| total_reward_steps      | 102        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01481489 |\n",
      "|    clip_fraction        | 0.331      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.836     |\n",
      "|    explained_variance   | -0.271     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0248     |\n",
      "|    n_updates            | 21560      |\n",
      "|    policy_gradient_loss | 0.000832   |\n",
      "|    value_loss           | 0.228      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2158        |\n",
      "|    time_elapsed         | 16330       |\n",
      "|    total_timesteps      | 4419584     |\n",
      "| total_reward_steps      | 186         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013667714 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0462      |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 0.459       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2159        |\n",
      "|    time_elapsed         | 16339       |\n",
      "|    total_timesteps      | 4421632     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035288446 |\n",
      "|    clip_fraction        | 0.45        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.14        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | 0.0233      |\n",
      "|    value_loss           | 10.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2160        |\n",
      "|    time_elapsed         | 16349       |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013902102 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.963      |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.055       |\n",
      "|    n_updates            | 21590       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2161        |\n",
      "|    time_elapsed         | 16358       |\n",
      "|    total_timesteps      | 4425728     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011410559 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.042       |\n",
      "|    n_updates            | 21600       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 0.0927      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2162       |\n",
      "|    time_elapsed         | 16367      |\n",
      "|    total_timesteps      | 4427776    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01686895 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.954     |\n",
      "|    explained_variance   | 0.768      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 21610      |\n",
      "|    policy_gradient_loss | -0.00539   |\n",
      "|    value_loss           | 0.149      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 16376        |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| total_reward_steps      | 66           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106699355 |\n",
      "|    clip_fraction        | 0.303        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.00253     |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.0135      |\n",
      "|    value_loss           | 0.112        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2164        |\n",
      "|    time_elapsed         | 16385       |\n",
      "|    total_timesteps      | 4431872     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022343615 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.256       |\n",
      "|    n_updates            | 21630       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2165       |\n",
      "|    time_elapsed         | 16394      |\n",
      "|    total_timesteps      | 4433920    |\n",
      "| total_reward_steps      | 103        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02135747 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.691      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0186    |\n",
      "|    n_updates            | 21640      |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 0.107      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2166        |\n",
      "|    time_elapsed         | 16403       |\n",
      "|    total_timesteps      | 4435968     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047179103 |\n",
      "|    clip_fraction        | 0.484       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.981      |\n",
      "|    explained_variance   | -0.0266     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0796      |\n",
      "|    n_updates            | 21650       |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    value_loss           | 2.53        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2167       |\n",
      "|    time_elapsed         | 16412      |\n",
      "|    total_timesteps      | 4438016    |\n",
      "| total_reward_steps      | 66         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02410524 |\n",
      "|    clip_fraction        | 0.397      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.547      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0019    |\n",
      "|    n_updates            | 21660      |\n",
      "|    policy_gradient_loss | 0.00129    |\n",
      "|    value_loss           | 0.333      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2168        |\n",
      "|    time_elapsed         | 16421       |\n",
      "|    total_timesteps      | 4440064     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017067574 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00283     |\n",
      "|    n_updates            | 21670       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 16430       |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375296 |\n",
      "|    clip_fraction        | 0.415       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00755    |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00804    |\n",
      "|    value_loss           | 0.0979      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2170        |\n",
      "|    time_elapsed         | 16439       |\n",
      "|    total_timesteps      | 4444160     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012564973 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0175      |\n",
      "|    n_updates            | 21690       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0884      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 2171       |\n",
      "|    time_elapsed         | 16449      |\n",
      "|    total_timesteps      | 4446208    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01417556 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.894      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.012     |\n",
      "|    n_updates            | 21700      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    value_loss           | 0.0932     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 16458       |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009483592 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.997      |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.101       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2173        |\n",
      "|    time_elapsed         | 16467       |\n",
      "|    total_timesteps      | 4450304     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015642766 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.731       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.094       |\n",
      "|    n_updates            | 21720       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 16476        |\n",
      "|    total_timesteps      | 4452352      |\n",
      "| total_reward_steps      | 85           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136234425 |\n",
      "|    clip_fraction        | 0.315        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00519      |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.0117      |\n",
      "|    value_loss           | 0.0814       |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 270          |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 16486        |\n",
      "|    total_timesteps      | 4454400      |\n",
      "| total_reward_steps      | 63           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147617785 |\n",
      "|    clip_fraction        | 0.355        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.00731      |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    value_loss           | 0.279        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2176        |\n",
      "|    time_elapsed         | 16495       |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012416677 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00903    |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0741      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2177        |\n",
      "|    time_elapsed         | 16504       |\n",
      "|    total_timesteps      | 4458496     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017854668 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0268      |\n",
      "|    n_updates            | 21760       |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.0956      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2178        |\n",
      "|    time_elapsed         | 16513       |\n",
      "|    total_timesteps      | 4460544     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009935555 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0169      |\n",
      "|    n_updates            | 21770       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.0708      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2179        |\n",
      "|    time_elapsed         | 16521       |\n",
      "|    total_timesteps      | 4462592     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012409024 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0215      |\n",
      "|    n_updates            | 21780       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.0858      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2180        |\n",
      "|    time_elapsed         | 16530       |\n",
      "|    total_timesteps      | 4464640     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011195989 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0998      |\n",
      "|    n_updates            | 21790       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2181        |\n",
      "|    time_elapsed         | 16538       |\n",
      "|    total_timesteps      | 4466688     |\n",
      "| total_reward_steps      | 89          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014740969 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0363      |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.0698      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2182        |\n",
      "|    time_elapsed         | 16547       |\n",
      "|    total_timesteps      | 4468736     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011856361 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000626   |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00793    |\n",
      "|    value_loss           | 0.251       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2183        |\n",
      "|    time_elapsed         | 16556       |\n",
      "|    total_timesteps      | 4470784     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022377592 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 21820       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 270         |\n",
      "|    iterations           | 2184        |\n",
      "|    time_elapsed         | 16565       |\n",
      "|    total_timesteps      | 4472832     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013027145 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00122     |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2185        |\n",
      "|    time_elapsed         | 16574       |\n",
      "|    total_timesteps      | 4474880     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010743277 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000835   |\n",
      "|    n_updates            | 21840       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.0654      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2186        |\n",
      "|    time_elapsed         | 16583       |\n",
      "|    total_timesteps      | 4476928     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010917689 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00655    |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.0843      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2187        |\n",
      "|    time_elapsed         | 16592       |\n",
      "|    total_timesteps      | 4478976     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020584248 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0151      |\n",
      "|    n_updates            | 21860       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 0.509       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2188        |\n",
      "|    time_elapsed         | 16602       |\n",
      "|    total_timesteps      | 4481024     |\n",
      "| total_reward_steps      | 122         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021028586 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | 0.00833     |\n",
      "|    value_loss           | 8.05        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 2189       |\n",
      "|    time_elapsed         | 16611      |\n",
      "|    total_timesteps      | 4483072    |\n",
      "| total_reward_steps      | 136        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06270676 |\n",
      "|    clip_fraction        | 0.513      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.949     |\n",
      "|    explained_variance   | -0.456     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.923      |\n",
      "|    n_updates            | 21880      |\n",
      "|    policy_gradient_loss | 0.0321     |\n",
      "|    value_loss           | 4.31       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2190        |\n",
      "|    time_elapsed         | 16620       |\n",
      "|    total_timesteps      | 4485120     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033749793 |\n",
      "|    clip_fraction        | 0.494       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.177       |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | 0.0216      |\n",
      "|    value_loss           | 2.72        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 269       |\n",
      "|    iterations           | 2191      |\n",
      "|    time_elapsed         | 16629     |\n",
      "|    total_timesteps      | 4487168   |\n",
      "| total_reward_steps      | 63        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0130268 |\n",
      "|    clip_fraction        | 0.389     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.03     |\n",
      "|    explained_variance   | 0.614     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.013     |\n",
      "|    n_updates            | 21900     |\n",
      "|    policy_gradient_loss | 0.00201   |\n",
      "|    value_loss           | 0.17      |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 2192       |\n",
      "|    time_elapsed         | 16638      |\n",
      "|    total_timesteps      | 4489216    |\n",
      "| total_reward_steps      | 64         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01587445 |\n",
      "|    clip_fraction        | 0.418      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.13      |\n",
      "|    explained_variance   | 0.699      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0197     |\n",
      "|    n_updates            | 21910      |\n",
      "|    policy_gradient_loss | -0.00465   |\n",
      "|    value_loss           | 0.138      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 269        |\n",
      "|    iterations           | 2193       |\n",
      "|    time_elapsed         | 16647      |\n",
      "|    total_timesteps      | 4491264    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01512862 |\n",
      "|    clip_fraction        | 0.356      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.877      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0708     |\n",
      "|    n_updates            | 21920      |\n",
      "|    policy_gradient_loss | -0.0132    |\n",
      "|    value_loss           | 0.0986     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 16656       |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015231071 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0374      |\n",
      "|    n_updates            | 21930       |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.0953      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2195        |\n",
      "|    time_elapsed         | 16665       |\n",
      "|    total_timesteps      | 4495360     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012242238 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 21940       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.0954      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2196        |\n",
      "|    time_elapsed         | 16674       |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020737076 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.975      |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00447     |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 2197        |\n",
      "|    time_elapsed         | 16683       |\n",
      "|    total_timesteps      | 4499456     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024288256 |\n",
      "|    clip_fraction        | 0.359       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.18        |\n",
      "|    n_updates            | 21960       |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=60.87 +/- 6.44\n",
      "Episode length: 1054.33 +/- 117.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.05e+03    |\n",
      "|    mean_reward          | 60.9        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011417583 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00352     |\n",
      "|    n_updates            | 21970       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 268      |\n",
      "|    iterations      | 2198     |\n",
      "|    time_elapsed    | 16743    |\n",
      "|    total_timesteps | 4501504  |\n",
      "| total_reward_steps | 62       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 16753       |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012523726 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00384    |\n",
      "|    n_updates            | 21980       |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.0701      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2200        |\n",
      "|    time_elapsed         | 16762       |\n",
      "|    total_timesteps      | 4505600     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039095405 |\n",
      "|    clip_fraction        | 0.504       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.0752      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.211       |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | 0.0229      |\n",
      "|    value_loss           | 9.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 16771       |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019651774 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.897      |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0308      |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    value_loss           | 0.135       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 268          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 16780        |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| total_reward_steps      | 63           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099541005 |\n",
      "|    clip_fraction        | 0.328        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0214       |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.0115      |\n",
      "|    value_loss           | 0.0962       |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2203       |\n",
      "|    time_elapsed         | 16789      |\n",
      "|    total_timesteps      | 4511744    |\n",
      "| total_reward_steps      | 37         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01252132 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.123      |\n",
      "|    n_updates            | 22020      |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    value_loss           | 0.0899     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2204        |\n",
      "|    time_elapsed         | 16798       |\n",
      "|    total_timesteps      | 4513792     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024187693 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00927     |\n",
      "|    n_updates            | 22030       |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2205        |\n",
      "|    time_elapsed         | 16807       |\n",
      "|    total_timesteps      | 4515840     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025777444 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0877      |\n",
      "|    n_updates            | 22040       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0868      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 268       |\n",
      "|    iterations           | 2206      |\n",
      "|    time_elapsed         | 16816     |\n",
      "|    total_timesteps      | 4517888   |\n",
      "| total_reward_steps      | 57        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0116942 |\n",
      "|    clip_fraction        | 0.3       |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.01     |\n",
      "|    explained_variance   | 0.936     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | -0.0147   |\n",
      "|    n_updates            | 22050     |\n",
      "|    policy_gradient_loss | -0.0128   |\n",
      "|    value_loss           | 0.0762    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 16825       |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019434191 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00398    |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.0095     |\n",
      "|    value_loss           | 0.0966      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 268        |\n",
      "|    iterations           | 2208       |\n",
      "|    time_elapsed         | 16834      |\n",
      "|    total_timesteps      | 4521984    |\n",
      "| total_reward_steps      | 60         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01069335 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0215    |\n",
      "|    n_updates            | 22070      |\n",
      "|    policy_gradient_loss | -0.0101    |\n",
      "|    value_loss           | 0.0759     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2209        |\n",
      "|    time_elapsed         | 16843       |\n",
      "|    total_timesteps      | 4524032     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009629142 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.052       |\n",
      "|    n_updates            | 22080       |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.0695      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2210        |\n",
      "|    time_elapsed         | 16851       |\n",
      "|    total_timesteps      | 4526080     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012382714 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0104     |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 0.0729      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2211        |\n",
      "|    time_elapsed         | 16860       |\n",
      "|    total_timesteps      | 4528128     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029696565 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0459      |\n",
      "|    n_updates            | 22100       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 0.0823      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2212        |\n",
      "|    time_elapsed         | 16869       |\n",
      "|    total_timesteps      | 4530176     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022657588 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0166     |\n",
      "|    n_updates            | 22110       |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.0983      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 16878       |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016385462 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.924      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0555      |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.103       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2214        |\n",
      "|    time_elapsed         | 16887       |\n",
      "|    total_timesteps      | 4534272     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010766391 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 22130       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0692      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2215        |\n",
      "|    time_elapsed         | 16896       |\n",
      "|    total_timesteps      | 4536320     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012097706 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 22140       |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 0.0671      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 16906       |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| total_reward_steps      | 31          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008144783 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 22150       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    value_loss           | 0.0561      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2217        |\n",
      "|    time_elapsed         | 16915       |\n",
      "|    total_timesteps      | 4540416     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015473079 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00713    |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.0716      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 16924       |\n",
      "|    total_timesteps      | 4542464     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014284236 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.0779      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2219        |\n",
      "|    time_elapsed         | 16933       |\n",
      "|    total_timesteps      | 4544512     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018174479 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.967      |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 22180       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2220        |\n",
      "|    time_elapsed         | 16942       |\n",
      "|    total_timesteps      | 4546560     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011909252 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00858    |\n",
      "|    n_updates            | 22190       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2221        |\n",
      "|    time_elapsed         | 16951       |\n",
      "|    total_timesteps      | 4548608     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013796293 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0259     |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2222        |\n",
      "|    time_elapsed         | 16960       |\n",
      "|    total_timesteps      | 4550656     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013570208 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00773    |\n",
      "|    n_updates            | 22210       |\n",
      "|    policy_gradient_loss | -0.00949    |\n",
      "|    value_loss           | 0.154       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2223        |\n",
      "|    time_elapsed         | 16970       |\n",
      "|    total_timesteps      | 4552704     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016872026 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 22220       |\n",
      "|    policy_gradient_loss | -0.000887   |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 16979       |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014566192 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0646      |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 0.102       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2225        |\n",
      "|    time_elapsed         | 16989       |\n",
      "|    total_timesteps      | 4556800     |\n",
      "| total_reward_steps      | 50          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012042854 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 22240       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.119       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2226        |\n",
      "|    time_elapsed         | 16998       |\n",
      "|    total_timesteps      | 4558848     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012016204 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00709     |\n",
      "|    n_updates            | 22250       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2227        |\n",
      "|    time_elapsed         | 17007       |\n",
      "|    total_timesteps      | 4560896     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010434399 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0296     |\n",
      "|    n_updates            | 22260       |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.0689      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2228        |\n",
      "|    time_elapsed         | 17016       |\n",
      "|    total_timesteps      | 4562944     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016557522 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0537      |\n",
      "|    n_updates            | 22270       |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    value_loss           | 0.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2229        |\n",
      "|    time_elapsed         | 17025       |\n",
      "|    total_timesteps      | 4564992     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015153058 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.966      |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.051       |\n",
      "|    n_updates            | 22280       |\n",
      "|    policy_gradient_loss | -0.0081     |\n",
      "|    value_loss           | 0.738       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2230        |\n",
      "|    time_elapsed         | 17034       |\n",
      "|    total_timesteps      | 4567040     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012664935 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00415     |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.093       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2231        |\n",
      "|    time_elapsed         | 17043       |\n",
      "|    total_timesteps      | 4569088     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012965791 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0196      |\n",
      "|    n_updates            | 22300       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.11        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2232        |\n",
      "|    time_elapsed         | 17052       |\n",
      "|    total_timesteps      | 4571136     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020450216 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00605     |\n",
      "|    n_updates            | 22310       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.0982      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2233        |\n",
      "|    time_elapsed         | 17061       |\n",
      "|    total_timesteps      | 4573184     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012212674 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 22320       |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.0925      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 2234        |\n",
      "|    time_elapsed         | 17070       |\n",
      "|    total_timesteps      | 4575232     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016212974 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2235        |\n",
      "|    time_elapsed         | 17080       |\n",
      "|    total_timesteps      | 4577280     |\n",
      "| total_reward_steps      | 38          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013665748 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00313     |\n",
      "|    n_updates            | 22340       |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.0712      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2236        |\n",
      "|    time_elapsed         | 17089       |\n",
      "|    total_timesteps      | 4579328     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011624105 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00205     |\n",
      "|    n_updates            | 22350       |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.0687      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2237        |\n",
      "|    time_elapsed         | 17099       |\n",
      "|    total_timesteps      | 4581376     |\n",
      "| total_reward_steps      | 66          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010819819 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.0743      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 17108       |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011030467 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.044       |\n",
      "|    n_updates            | 22370       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2239        |\n",
      "|    time_elapsed         | 17118       |\n",
      "|    total_timesteps      | 4585472     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012000783 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0191      |\n",
      "|    n_updates            | 22380       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.0822      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2240        |\n",
      "|    time_elapsed         | 17127       |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009545296 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0241      |\n",
      "|    n_updates            | 22390       |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.0794      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2241        |\n",
      "|    time_elapsed         | 17136       |\n",
      "|    total_timesteps      | 4589568     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012689644 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00568     |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.0877      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2242        |\n",
      "|    time_elapsed         | 17144       |\n",
      "|    total_timesteps      | 4591616     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015674625 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0267      |\n",
      "|    n_updates            | 22410       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    value_loss           | 0.576       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2243        |\n",
      "|    time_elapsed         | 17153       |\n",
      "|    total_timesteps      | 4593664     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012572607 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.000375    |\n",
      "|    n_updates            | 22420       |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.0955      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2244        |\n",
      "|    time_elapsed         | 17162       |\n",
      "|    total_timesteps      | 4595712     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014296406 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.0882      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 17171       |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012044923 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0761      |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 0.0696      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 267        |\n",
      "|    iterations           | 2246       |\n",
      "|    time_elapsed         | 17179      |\n",
      "|    total_timesteps      | 4599808    |\n",
      "| total_reward_steps      | 108        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01378919 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.912     |\n",
      "|    explained_variance   | 0.748      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.113      |\n",
      "|    n_updates            | 22450      |\n",
      "|    policy_gradient_loss | -0.00548   |\n",
      "|    value_loss           | 0.543      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=79.17 +/- 44.89\n",
      "Episode length: 937.37 +/- 143.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 937         |\n",
      "|    mean_reward          | 79.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032550022 |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | -0.122      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0558      |\n",
      "|    n_updates            | 22460       |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    value_loss           | 3.02        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 267      |\n",
      "|    iterations      | 2247     |\n",
      "|    time_elapsed    | 17233    |\n",
      "|    total_timesteps | 4601856  |\n",
      "| total_reward_steps | 55       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 267         |\n",
      "|    iterations           | 2248        |\n",
      "|    time_elapsed         | 17242       |\n",
      "|    total_timesteps      | 4603904     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016154293 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.053       |\n",
      "|    n_updates            | 22470       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2249        |\n",
      "|    time_elapsed         | 17251       |\n",
      "|    total_timesteps      | 4605952     |\n",
      "| total_reward_steps      | 90          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017109867 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0256      |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.128       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2250        |\n",
      "|    time_elapsed         | 17261       |\n",
      "|    total_timesteps      | 4608000     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047974702 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.116       |\n",
      "|    n_updates            | 22490       |\n",
      "|    policy_gradient_loss | 0.0277      |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2251        |\n",
      "|    time_elapsed         | 17270       |\n",
      "|    total_timesteps      | 4610048     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018021427 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.921      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0321      |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | 0.00329     |\n",
      "|    value_loss           | 0.42        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2252        |\n",
      "|    time_elapsed         | 17279       |\n",
      "|    total_timesteps      | 4612096     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017756063 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0432      |\n",
      "|    n_updates            | 22510       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    value_loss           | 0.475       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2253        |\n",
      "|    time_elapsed         | 17288       |\n",
      "|    total_timesteps      | 4614144     |\n",
      "| total_reward_steps      | 81          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013685351 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 22520       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.0891      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2254        |\n",
      "|    time_elapsed         | 17298       |\n",
      "|    total_timesteps      | 4616192     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013122316 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0685      |\n",
      "|    n_updates            | 22530       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 0.513       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 17307       |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012145169 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0492      |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    value_loss           | 0.445       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2256        |\n",
      "|    time_elapsed         | 17316       |\n",
      "|    total_timesteps      | 4620288     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015451783 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00498     |\n",
      "|    n_updates            | 22550       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    value_loss           | 0.315       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2257        |\n",
      "|    time_elapsed         | 17326       |\n",
      "|    total_timesteps      | 4622336     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015393164 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.131       |\n",
      "|    n_updates            | 22560       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2258        |\n",
      "|    time_elapsed         | 17335       |\n",
      "|    total_timesteps      | 4624384     |\n",
      "| total_reward_steps      | 86          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019499697 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.127       |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | 0.00935     |\n",
      "|    value_loss           | 1.87        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2259       |\n",
      "|    time_elapsed         | 17344      |\n",
      "|    total_timesteps      | 4626432    |\n",
      "| total_reward_steps      | 81         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01676606 |\n",
      "|    clip_fraction        | 0.33       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.896     |\n",
      "|    explained_variance   | 0.708      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.139      |\n",
      "|    n_updates            | 22580      |\n",
      "|    policy_gradient_loss | 0.00353    |\n",
      "|    value_loss           | 0.306      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2260        |\n",
      "|    time_elapsed         | 17354       |\n",
      "|    total_timesteps      | 4628480     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015398519 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0675      |\n",
      "|    n_updates            | 22590       |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 0.167       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2261        |\n",
      "|    time_elapsed         | 17363       |\n",
      "|    total_timesteps      | 4630528     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020297501 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 22600       |\n",
      "|    policy_gradient_loss | -0.00954    |\n",
      "|    value_loss           | 0.158       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2262        |\n",
      "|    time_elapsed         | 17372       |\n",
      "|    total_timesteps      | 4632576     |\n",
      "| total_reward_steps      | 83          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015761439 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -9.69e-05   |\n",
      "|    n_updates            | 22610       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 0.107       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2263        |\n",
      "|    time_elapsed         | 17381       |\n",
      "|    total_timesteps      | 4634624     |\n",
      "| total_reward_steps      | 69          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017400619 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.448       |\n",
      "|    n_updates            | 22620       |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 0.479       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2264        |\n",
      "|    time_elapsed         | 17390       |\n",
      "|    total_timesteps      | 4636672     |\n",
      "| total_reward_steps      | 65          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012168938 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0124      |\n",
      "|    n_updates            | 22630       |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.293       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2265        |\n",
      "|    time_elapsed         | 17400       |\n",
      "|    total_timesteps      | 4638720     |\n",
      "| total_reward_steps      | 80          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017064199 |\n",
      "|    clip_fraction        | 0.408       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00937    |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 0.317       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2266        |\n",
      "|    time_elapsed         | 17409       |\n",
      "|    total_timesteps      | 4640768     |\n",
      "| total_reward_steps      | 46          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224076 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 22650       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    value_loss           | 0.438       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2267       |\n",
      "|    time_elapsed         | 17418      |\n",
      "|    total_timesteps      | 4642816    |\n",
      "| total_reward_steps      | 94         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02623984 |\n",
      "|    clip_fraction        | 0.436      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.244      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0782     |\n",
      "|    n_updates            | 22660      |\n",
      "|    policy_gradient_loss | 0.00692    |\n",
      "|    value_loss           | 2.24       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2268        |\n",
      "|    time_elapsed         | 17428       |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018237764 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.973      |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    value_loss           | 0.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2269        |\n",
      "|    time_elapsed         | 17437       |\n",
      "|    total_timesteps      | 4646912     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019858632 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0281      |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | 0.00923     |\n",
      "|    value_loss           | 1.9         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2270       |\n",
      "|    time_elapsed         | 17446      |\n",
      "|    total_timesteps      | 4648960    |\n",
      "| total_reward_steps      | 53         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02724984 |\n",
      "|    clip_fraction        | 0.516      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.982     |\n",
      "|    explained_variance   | 0.109      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0771     |\n",
      "|    n_updates            | 22690      |\n",
      "|    policy_gradient_loss | -0.000508  |\n",
      "|    value_loss           | 0.632      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2271        |\n",
      "|    time_elapsed         | 17455       |\n",
      "|    total_timesteps      | 4651008     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014781283 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.134       |\n",
      "|    n_updates            | 22700       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    value_loss           | 0.197       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 17464       |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010517683 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2273       |\n",
      "|    time_elapsed         | 17473      |\n",
      "|    total_timesteps      | 4655104    |\n",
      "| total_reward_steps      | 56         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03717216 |\n",
      "|    clip_fraction        | 0.424      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.841     |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0466     |\n",
      "|    n_updates            | 22720      |\n",
      "|    policy_gradient_loss | 0.0135     |\n",
      "|    value_loss           | 3.1        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2274        |\n",
      "|    time_elapsed         | 17481       |\n",
      "|    total_timesteps      | 4657152     |\n",
      "| total_reward_steps      | 365         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013205664 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0704      |\n",
      "|    n_updates            | 22730       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 0.265       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2275       |\n",
      "|    time_elapsed         | 17490      |\n",
      "|    total_timesteps      | 4659200    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05107025 |\n",
      "|    clip_fraction        | 0.503      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.958     |\n",
      "|    explained_variance   | 0.101      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 22740      |\n",
      "|    policy_gradient_loss | 0.0224     |\n",
      "|    value_loss           | 47.3       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2276       |\n",
      "|    time_elapsed         | 17499      |\n",
      "|    total_timesteps      | 4661248    |\n",
      "| total_reward_steps      | 79         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03635826 |\n",
      "|    clip_fraction        | 0.444      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.821     |\n",
      "|    explained_variance   | 0.317      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.136      |\n",
      "|    n_updates            | 22750      |\n",
      "|    policy_gradient_loss | 0.0158     |\n",
      "|    value_loss           | 2.25       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 17508        |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| total_reward_steps      | 84           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140102655 |\n",
      "|    clip_fraction        | 0.328        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.824       |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0337       |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | 0.000627     |\n",
      "|    value_loss           | 0.297        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2278        |\n",
      "|    time_elapsed         | 17517       |\n",
      "|    total_timesteps      | 4665344     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029846894 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.243       |\n",
      "|    n_updates            | 22770       |\n",
      "|    policy_gradient_loss | 0.00931     |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2279        |\n",
      "|    time_elapsed         | 17526       |\n",
      "|    total_timesteps      | 4667392     |\n",
      "| total_reward_steps      | 202         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016440677 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00717    |\n",
      "|    n_updates            | 22780       |\n",
      "|    policy_gradient_loss | -0.000542   |\n",
      "|    value_loss           | 0.218       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2280       |\n",
      "|    time_elapsed         | 17535      |\n",
      "|    total_timesteps      | 4669440    |\n",
      "| total_reward_steps      | 67         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03168907 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.703     |\n",
      "|    explained_variance   | 0.149      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.608      |\n",
      "|    n_updates            | 22790      |\n",
      "|    policy_gradient_loss | 0.00938    |\n",
      "|    value_loss           | 13.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2281        |\n",
      "|    time_elapsed         | 17544       |\n",
      "|    total_timesteps      | 4671488     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020179912 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0172      |\n",
      "|    n_updates            | 22800       |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    value_loss           | 0.477       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 17552       |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025537021 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.868      |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.063       |\n",
      "|    n_updates            | 22810       |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    value_loss           | 0.236       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2283        |\n",
      "|    time_elapsed         | 17560       |\n",
      "|    total_timesteps      | 4675584     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018634554 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0334      |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | 0.000727    |\n",
      "|    value_loss           | 0.305       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2284        |\n",
      "|    time_elapsed         | 17568       |\n",
      "|    total_timesteps      | 4677632     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015413503 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.000271   |\n",
      "|    n_updates            | 22830       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 0.264       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2285       |\n",
      "|    time_elapsed         | 17575      |\n",
      "|    total_timesteps      | 4679680    |\n",
      "| total_reward_steps      | 75         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01835625 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | 0.552      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0162     |\n",
      "|    n_updates            | 22840      |\n",
      "|    policy_gradient_loss | 0.000872   |\n",
      "|    value_loss           | 0.553      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2286        |\n",
      "|    time_elapsed         | 17583       |\n",
      "|    total_timesteps      | 4681728     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016086802 |\n",
      "|    clip_fraction        | 0.396       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00368    |\n",
      "|    n_updates            | 22850       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 0.204       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2287        |\n",
      "|    time_elapsed         | 17591       |\n",
      "|    total_timesteps      | 4683776     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013934187 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0462      |\n",
      "|    n_updates            | 22860       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    value_loss           | 0.147       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 266          |\n",
      "|    iterations           | 2288         |\n",
      "|    time_elapsed         | 17598        |\n",
      "|    total_timesteps      | 4685824      |\n",
      "| total_reward_steps      | 87           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138736535 |\n",
      "|    clip_fraction        | 0.391        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.986       |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.102        |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    value_loss           | 0.187        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 2289       |\n",
      "|    time_elapsed         | 17606      |\n",
      "|    total_timesteps      | 4687872    |\n",
      "| total_reward_steps      | 76         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01453832 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.892     |\n",
      "|    explained_variance   | 0.82       |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0551     |\n",
      "|    n_updates            | 22880      |\n",
      "|    policy_gradient_loss | -0.00687   |\n",
      "|    value_loss           | 0.183      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2290        |\n",
      "|    time_elapsed         | 17614       |\n",
      "|    total_timesteps      | 4689920     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013539002 |\n",
      "|    clip_fraction        | 0.342       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.946      |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.12        |\n",
      "|    n_updates            | 22890       |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    value_loss           | 0.442       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2291        |\n",
      "|    time_elapsed         | 17621       |\n",
      "|    total_timesteps      | 4691968     |\n",
      "| total_reward_steps      | 201         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014282102 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.91       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0235      |\n",
      "|    n_updates            | 22900       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 17629       |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040020086 |\n",
      "|    clip_fraction        | 0.467       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.85       |\n",
      "|    explained_variance   | 0.201       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | 0.0302      |\n",
      "|    value_loss           | 8.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2293        |\n",
      "|    time_elapsed         | 17636       |\n",
      "|    total_timesteps      | 4696064     |\n",
      "| total_reward_steps      | 87          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016981976 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0242      |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.209       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 266         |\n",
      "|    iterations           | 2294        |\n",
      "|    time_elapsed         | 17644       |\n",
      "|    total_timesteps      | 4698112     |\n",
      "| total_reward_steps      | 70          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015409185 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00492    |\n",
      "|    n_updates            | 22930       |\n",
      "|    policy_gradient_loss | -0.000537   |\n",
      "|    value_loss           | 0.243       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=117.87 +/- 75.55\n",
      "Episode length: 954.30 +/- 134.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 954         |\n",
      "|    mean_reward          | 118         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4700000     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012725813 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0732      |\n",
      "|    n_updates            | 22940       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 0.159       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 265      |\n",
      "|    iterations      | 2295     |\n",
      "|    time_elapsed    | 17691    |\n",
      "|    total_timesteps | 4700160  |\n",
      "| total_reward_steps | 78       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2296        |\n",
      "|    time_elapsed         | 17698       |\n",
      "|    total_timesteps      | 4702208     |\n",
      "| total_reward_steps      | 88          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018883744 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0452      |\n",
      "|    n_updates            | 22950       |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.123       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 17705       |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013870278 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.985      |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00346    |\n",
      "|    n_updates            | 22960       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    value_loss           | 0.441       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2298        |\n",
      "|    time_elapsed         | 17713       |\n",
      "|    total_timesteps      | 4706304     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014704516 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 22970       |\n",
      "|    policy_gradient_loss | 0.00883     |\n",
      "|    value_loss           | 1.72        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 17721       |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| total_reward_steps      | 77          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020247122 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.00321     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | 0.00495     |\n",
      "|    value_loss           | 21.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2300        |\n",
      "|    time_elapsed         | 17728       |\n",
      "|    total_timesteps      | 4710400     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034938272 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0476      |\n",
      "|    n_updates            | 22990       |\n",
      "|    policy_gradient_loss | 0.00643     |\n",
      "|    value_loss           | 2.13        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2301       |\n",
      "|    time_elapsed         | 17736      |\n",
      "|    total_timesteps      | 4712448    |\n",
      "| total_reward_steps      | 109        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01883792 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | 0.505      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.148      |\n",
      "|    n_updates            | 23000      |\n",
      "|    policy_gradient_loss | 0.00394    |\n",
      "|    value_loss           | 0.497      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2302       |\n",
      "|    time_elapsed         | 17744      |\n",
      "|    total_timesteps      | 4714496    |\n",
      "| total_reward_steps      | 104        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02627771 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.775     |\n",
      "|    explained_variance   | 0.379      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.189      |\n",
      "|    n_updates            | 23010      |\n",
      "|    policy_gradient_loss | 0.0122     |\n",
      "|    value_loss           | 2          |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2303        |\n",
      "|    time_elapsed         | 17751       |\n",
      "|    total_timesteps      | 4716544     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035181858 |\n",
      "|    clip_fraction        | 0.465       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0862      |\n",
      "|    n_updates            | 23020       |\n",
      "|    policy_gradient_loss | 0.016       |\n",
      "|    value_loss           | 2.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2304        |\n",
      "|    time_elapsed         | 17758       |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| total_reward_steps      | 102         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020197568 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0.16        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.137       |\n",
      "|    n_updates            | 23030       |\n",
      "|    policy_gradient_loss | 0.00351     |\n",
      "|    value_loss           | 0.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2305        |\n",
      "|    time_elapsed         | 17765       |\n",
      "|    total_timesteps      | 4720640     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016809402 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.758      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.617       |\n",
      "|    n_updates            | 23040       |\n",
      "|    policy_gradient_loss | 0.00513     |\n",
      "|    value_loss           | 2.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 17773       |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| total_reward_steps      | 76          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014374008 |\n",
      "|    clip_fraction        | 0.372       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0416      |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 17781       |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| total_reward_steps      | 103         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016646083 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.929      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0755      |\n",
      "|    n_updates            | 23060       |\n",
      "|    policy_gradient_loss | 0.000129    |\n",
      "|    value_loss           | 0.386       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2308       |\n",
      "|    time_elapsed         | 17788      |\n",
      "|    total_timesteps      | 4726784    |\n",
      "| total_reward_steps      | 67         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04182578 |\n",
      "|    clip_fraction        | 0.478      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.91      |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 23070      |\n",
      "|    policy_gradient_loss | 0.0175     |\n",
      "|    value_loss           | 14.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2309        |\n",
      "|    time_elapsed         | 17796       |\n",
      "|    total_timesteps      | 4728832     |\n",
      "| total_reward_steps      | 191         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024325343 |\n",
      "|    clip_fraction        | 0.425       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.000305    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0477      |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 0.301       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2310        |\n",
      "|    time_elapsed         | 17803       |\n",
      "|    total_timesteps      | 4730880     |\n",
      "| total_reward_steps      | 51          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034831718 |\n",
      "|    clip_fraction        | 0.469       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.854      |\n",
      "|    explained_variance   | 0.289       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.544       |\n",
      "|    n_updates            | 23090       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    value_loss           | 13.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 17811       |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| total_reward_steps      | 84          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026588736 |\n",
      "|    clip_fraction        | 0.429       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 5.08        |\n",
      "|    n_updates            | 23100       |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    value_loss           | 7.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2312        |\n",
      "|    time_elapsed         | 17818       |\n",
      "|    total_timesteps      | 4734976     |\n",
      "| total_reward_steps      | 186         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019374821 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0554      |\n",
      "|    n_updates            | 23110       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    value_loss           | 2.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2313        |\n",
      "|    time_elapsed         | 17825       |\n",
      "|    total_timesteps      | 4737024     |\n",
      "| total_reward_steps      | 197         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038715683 |\n",
      "|    clip_fraction        | 0.426       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.334       |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    value_loss           | 11.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2314        |\n",
      "|    time_elapsed         | 17833       |\n",
      "|    total_timesteps      | 4739072     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023477241 |\n",
      "|    clip_fraction        | 0.395       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.846      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 23130       |\n",
      "|    policy_gradient_loss | 0.0161      |\n",
      "|    value_loss           | 6.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2315        |\n",
      "|    time_elapsed         | 17841       |\n",
      "|    total_timesteps      | 4741120     |\n",
      "| total_reward_steps      | 345         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.081308305 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0826      |\n",
      "|    n_updates            | 23140       |\n",
      "|    policy_gradient_loss | 0.00685     |\n",
      "|    value_loss           | 1.42        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2316       |\n",
      "|    time_elapsed         | 17849      |\n",
      "|    total_timesteps      | 4743168    |\n",
      "| total_reward_steps      | 33         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07510248 |\n",
      "|    clip_fraction        | 0.525      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.86      |\n",
      "|    explained_variance   | 0.122      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 757        |\n",
      "|    n_updates            | 23150      |\n",
      "|    policy_gradient_loss | 0.0289     |\n",
      "|    value_loss           | 51.5       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 2317      |\n",
      "|    time_elapsed         | 17856     |\n",
      "|    total_timesteps      | 4745216   |\n",
      "| total_reward_steps      | 47        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0716088 |\n",
      "|    clip_fraction        | 0.409     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.734    |\n",
      "|    explained_variance   | 0.394     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 3.75      |\n",
      "|    n_updates            | 23160     |\n",
      "|    policy_gradient_loss | 0.0189    |\n",
      "|    value_loss           | 8.56      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 2318      |\n",
      "|    time_elapsed         | 17864     |\n",
      "|    total_timesteps      | 4747264   |\n",
      "| total_reward_steps      | 72        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4949442 |\n",
      "|    clip_fraction        | 0.437     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.822    |\n",
      "|    explained_variance   | 0.143     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0592    |\n",
      "|    n_updates            | 23170     |\n",
      "|    policy_gradient_loss | 0.0148    |\n",
      "|    value_loss           | 0.212     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2319        |\n",
      "|    time_elapsed         | 17872       |\n",
      "|    total_timesteps      | 4749312     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024357114 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0602      |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 0.173       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2320       |\n",
      "|    time_elapsed         | 17879      |\n",
      "|    total_timesteps      | 4751360    |\n",
      "| total_reward_steps      | 41         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03680441 |\n",
      "|    clip_fraction        | 0.378      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.849     |\n",
      "|    explained_variance   | 0.693      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0833     |\n",
      "|    n_updates            | 23190      |\n",
      "|    policy_gradient_loss | -0.0031    |\n",
      "|    value_loss           | 0.137      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2321        |\n",
      "|    time_elapsed         | 17887       |\n",
      "|    total_timesteps      | 4753408     |\n",
      "| total_reward_steps      | 28          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017969407 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 23200       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    value_loss           | 0.148       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2322        |\n",
      "|    time_elapsed         | 17894       |\n",
      "|    total_timesteps      | 4755456     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070015505 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.786      |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.089       |\n",
      "|    n_updates            | 23210       |\n",
      "|    policy_gradient_loss | 0.0333      |\n",
      "|    value_loss           | 2.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2323        |\n",
      "|    time_elapsed         | 17902       |\n",
      "|    total_timesteps      | 4757504     |\n",
      "| total_reward_steps      | 14          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028494235 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.772      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0482      |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2324       |\n",
      "|    time_elapsed         | 17910      |\n",
      "|    total_timesteps      | 4759552    |\n",
      "| total_reward_steps      | 36         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03814973 |\n",
      "|    clip_fraction        | 0.381      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.808     |\n",
      "|    explained_variance   | 0.279      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.245      |\n",
      "|    n_updates            | 23230      |\n",
      "|    policy_gradient_loss | 0.00518    |\n",
      "|    value_loss           | 2.79       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2325        |\n",
      "|    time_elapsed         | 17918       |\n",
      "|    total_timesteps      | 4761600     |\n",
      "| total_reward_steps      | 185         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026666548 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 23240       |\n",
      "|    policy_gradient_loss | 0.00894     |\n",
      "|    value_loss           | 1.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2326        |\n",
      "|    time_elapsed         | 17926       |\n",
      "|    total_timesteps      | 4763648     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025492143 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.788      |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 23250       |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    value_loss           | 5.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2327        |\n",
      "|    time_elapsed         | 17933       |\n",
      "|    total_timesteps      | 4765696     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021701772 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 0.143       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2328        |\n",
      "|    time_elapsed         | 17941       |\n",
      "|    total_timesteps      | 4767744     |\n",
      "| total_reward_steps      | 109         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022171736 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0643      |\n",
      "|    n_updates            | 23270       |\n",
      "|    policy_gradient_loss | 9.77e-05    |\n",
      "|    value_loss           | 0.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2329        |\n",
      "|    time_elapsed         | 17948       |\n",
      "|    total_timesteps      | 4769792     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035939023 |\n",
      "|    clip_fraction        | 0.354       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 23280       |\n",
      "|    policy_gradient_loss | 0.00808     |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2330        |\n",
      "|    time_elapsed         | 17956       |\n",
      "|    total_timesteps      | 4771840     |\n",
      "| total_reward_steps      | 12          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035124186 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0359      |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | 0.000906    |\n",
      "|    value_loss           | 0.299       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2331       |\n",
      "|    time_elapsed         | 17965      |\n",
      "|    total_timesteps      | 4773888    |\n",
      "| total_reward_steps      | 70         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10879376 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.665     |\n",
      "|    explained_variance   | 0.634      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 7.07       |\n",
      "|    n_updates            | 23300      |\n",
      "|    policy_gradient_loss | 0.0114     |\n",
      "|    value_loss           | 1.81       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2332        |\n",
      "|    time_elapsed         | 17974       |\n",
      "|    total_timesteps      | 4775936     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023670323 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00142     |\n",
      "|    n_updates            | 23310       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 17983       |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| total_reward_steps      | 101         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030449029 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | 0.00196     |\n",
      "|    value_loss           | 0.437       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2334        |\n",
      "|    time_elapsed         | 17992       |\n",
      "|    total_timesteps      | 4780032     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029665206 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 23330       |\n",
      "|    policy_gradient_loss | 0.00763     |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2335        |\n",
      "|    time_elapsed         | 18001       |\n",
      "|    total_timesteps      | 4782080     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025634695 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.881      |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.107       |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | 0.00799     |\n",
      "|    value_loss           | 0.489       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2336       |\n",
      "|    time_elapsed         | 18010      |\n",
      "|    total_timesteps      | 4784128    |\n",
      "| total_reward_steps      | 67         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06498961 |\n",
      "|    clip_fraction        | 0.352      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.635     |\n",
      "|    explained_variance   | 0.299      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.111      |\n",
      "|    n_updates            | 23350      |\n",
      "|    policy_gradient_loss | 0.0148     |\n",
      "|    value_loss           | 1.32       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 265       |\n",
      "|    iterations           | 2337      |\n",
      "|    time_elapsed         | 18019     |\n",
      "|    total_timesteps      | 4786176   |\n",
      "| total_reward_steps      | 180       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0249908 |\n",
      "|    clip_fraction        | 0.356     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.751    |\n",
      "|    explained_variance   | 0.51      |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0499    |\n",
      "|    n_updates            | 23360     |\n",
      "|    policy_gradient_loss | 0.00345   |\n",
      "|    value_loss           | 0.328     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2338       |\n",
      "|    time_elapsed         | 18029      |\n",
      "|    total_timesteps      | 4788224    |\n",
      "| total_reward_steps      | 100        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10285236 |\n",
      "|    clip_fraction        | 0.541      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.784     |\n",
      "|    explained_variance   | 0.153      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 25.5       |\n",
      "|    n_updates            | 23370      |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    value_loss           | 7.28       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2339        |\n",
      "|    time_elapsed         | 18038       |\n",
      "|    total_timesteps      | 4790272     |\n",
      "| total_reward_steps      | 386         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045229677 |\n",
      "|    clip_fraction        | 0.399       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01        |\n",
      "|    n_updates            | 23380       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    value_loss           | 3.06        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2340       |\n",
      "|    time_elapsed         | 18047      |\n",
      "|    total_timesteps      | 4792320    |\n",
      "| total_reward_steps      | 94         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31844804 |\n",
      "|    clip_fraction        | 0.67       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.782     |\n",
      "|    explained_variance   | 0.067      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.44       |\n",
      "|    n_updates            | 23390      |\n",
      "|    policy_gradient_loss | 0.0513     |\n",
      "|    value_loss           | 42.4       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2341       |\n",
      "|    time_elapsed         | 18055      |\n",
      "|    total_timesteps      | 4794368    |\n",
      "| total_reward_steps      | 47         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.10628242 |\n",
      "|    clip_fraction        | 0.471      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.646     |\n",
      "|    explained_variance   | -0.587     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.52       |\n",
      "|    n_updates            | 23400      |\n",
      "|    policy_gradient_loss | 0.0257     |\n",
      "|    value_loss           | 1.33       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 2342       |\n",
      "|    time_elapsed         | 18064      |\n",
      "|    total_timesteps      | 4796416    |\n",
      "| total_reward_steps      | 17         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06592153 |\n",
      "|    clip_fraction        | 0.35       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.658     |\n",
      "|    explained_variance   | 0.557      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.128      |\n",
      "|    n_updates            | 23410      |\n",
      "|    policy_gradient_loss | 0.0236     |\n",
      "|    value_loss           | 7.49       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 265         |\n",
      "|    iterations           | 2343        |\n",
      "|    time_elapsed         | 18073       |\n",
      "|    total_timesteps      | 4798464     |\n",
      "| total_reward_steps      | 172         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042598907 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.612       |\n",
      "|    n_updates            | 23420       |\n",
      "|    policy_gradient_loss | 0.0184      |\n",
      "|    value_loss           | 3.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=27.17 +/- 8.73\n",
      "Episode length: 826.60 +/- 85.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 827        |\n",
      "|    mean_reward          | 27.2       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4800000    |\n",
      "| total_reward_steps      | 39         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07063131 |\n",
      "|    clip_fraction        | 0.45       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.823     |\n",
      "|    explained_variance   | 0.052      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.319      |\n",
      "|    n_updates            | 23430      |\n",
      "|    policy_gradient_loss | 0.0323     |\n",
      "|    value_loss           | 4.08       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 264      |\n",
      "|    iterations      | 2344     |\n",
      "|    time_elapsed    | 18117    |\n",
      "|    total_timesteps | 4800512  |\n",
      "| total_reward_steps | 20       |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2345        |\n",
      "|    time_elapsed         | 18126       |\n",
      "|    total_timesteps      | 4802560     |\n",
      "| total_reward_steps      | 29          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046122838 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.725      |\n",
      "|    explained_variance   | -0.615      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0279      |\n",
      "|    n_updates            | 23440       |\n",
      "|    policy_gradient_loss | 0.00786     |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2346        |\n",
      "|    time_elapsed         | 18135       |\n",
      "|    total_timesteps      | 4804608     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034481294 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 23450       |\n",
      "|    policy_gradient_loss | 0.00517     |\n",
      "|    value_loss           | 0.401       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2347       |\n",
      "|    time_elapsed         | 18144      |\n",
      "|    total_timesteps      | 4806656    |\n",
      "| total_reward_steps      | 46         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02634508 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.75      |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.132      |\n",
      "|    n_updates            | 23460      |\n",
      "|    policy_gradient_loss | 0.00676    |\n",
      "|    value_loss           | 1.76       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2348        |\n",
      "|    time_elapsed         | 18152       |\n",
      "|    total_timesteps      | 4808704     |\n",
      "| total_reward_steps      | 183         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024675904 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | -0.296      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0993      |\n",
      "|    n_updates            | 23470       |\n",
      "|    policy_gradient_loss | 0.00176     |\n",
      "|    value_loss           | 0.495       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2349        |\n",
      "|    time_elapsed         | 18161       |\n",
      "|    total_timesteps      | 4810752     |\n",
      "| total_reward_steps      | 11          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.122224435 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0999      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 23480       |\n",
      "|    policy_gradient_loss | 0.0232      |\n",
      "|    value_loss           | 19          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2350        |\n",
      "|    time_elapsed         | 18170       |\n",
      "|    total_timesteps      | 4812800     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034501955 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 8.73        |\n",
      "|    n_updates            | 23490       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    value_loss           | 1.85        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 2351      |\n",
      "|    time_elapsed         | 18179     |\n",
      "|    total_timesteps      | 4814848   |\n",
      "| total_reward_steps      | 185       |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0308972 |\n",
      "|    clip_fraction        | 0.388     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.773    |\n",
      "|    explained_variance   | -0.481    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.0415    |\n",
      "|    n_updates            | 23500     |\n",
      "|    policy_gradient_loss | 0.0111    |\n",
      "|    value_loss           | 0.369     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2352        |\n",
      "|    time_elapsed         | 18187       |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| total_reward_steps      | 57          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016850118 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0229      |\n",
      "|    n_updates            | 23510       |\n",
      "|    policy_gradient_loss | 0.00912     |\n",
      "|    value_loss           | 7.62        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2353        |\n",
      "|    time_elapsed         | 18196       |\n",
      "|    total_timesteps      | 4818944     |\n",
      "| total_reward_steps      | 25          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057982817 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 23520       |\n",
      "|    policy_gradient_loss | 0.00766     |\n",
      "|    value_loss           | 1.59        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2354        |\n",
      "|    time_elapsed         | 18205       |\n",
      "|    total_timesteps      | 4820992     |\n",
      "| total_reward_steps      | 56          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022083558 |\n",
      "|    clip_fraction        | 0.375       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.759      |\n",
      "|    explained_variance   | -0.044      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0784      |\n",
      "|    n_updates            | 23530       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 0.214       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2355        |\n",
      "|    time_elapsed         | 18214       |\n",
      "|    total_timesteps      | 4823040     |\n",
      "| total_reward_steps      | 40          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014592497 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.186       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00955     |\n",
      "|    n_updates            | 23540       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 0.184       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2356       |\n",
      "|    time_elapsed         | 18223      |\n",
      "|    total_timesteps      | 4825088    |\n",
      "| total_reward_steps      | 77         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01562713 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.866     |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0588     |\n",
      "|    n_updates            | 23550      |\n",
      "|    policy_gradient_loss | -0.00933   |\n",
      "|    value_loss           | 0.121      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 264      |\n",
      "|    iterations           | 2357     |\n",
      "|    time_elapsed         | 18232    |\n",
      "|    total_timesteps      | 4827136  |\n",
      "| total_reward_steps      | 52       |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.021233 |\n",
      "|    clip_fraction        | 0.379    |\n",
      "|    clip_range           | 0.1      |\n",
      "|    entropy_loss         | -0.866   |\n",
      "|    explained_variance   | 0.545    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.147    |\n",
      "|    n_updates            | 23560    |\n",
      "|    policy_gradient_loss | 0.0059   |\n",
      "|    value_loss           | 0.522    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2358        |\n",
      "|    time_elapsed         | 18241       |\n",
      "|    total_timesteps      | 4829184     |\n",
      "| total_reward_steps      | 49          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009771084 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 23570       |\n",
      "|    policy_gradient_loss | -0.00052    |\n",
      "|    value_loss           | 0.152       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2359        |\n",
      "|    time_elapsed         | 18250       |\n",
      "|    total_timesteps      | 4831232     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019278184 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0915      |\n",
      "|    n_updates            | 23580       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2360        |\n",
      "|    time_elapsed         | 18259       |\n",
      "|    total_timesteps      | 4833280     |\n",
      "| total_reward_steps      | 60          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015009953 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00314     |\n",
      "|    n_updates            | 23590       |\n",
      "|    policy_gradient_loss | -0.00738    |\n",
      "|    value_loss           | 0.0874      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2361       |\n",
      "|    time_elapsed         | 18269      |\n",
      "|    total_timesteps      | 4835328    |\n",
      "| total_reward_steps      | 54         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01072989 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.641      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.144      |\n",
      "|    n_updates            | 23600      |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    value_loss           | 0.279      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2362       |\n",
      "|    time_elapsed         | 18278      |\n",
      "|    total_timesteps      | 4837376    |\n",
      "| total_reward_steps      | 181        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04318843 |\n",
      "|    clip_fraction        | 0.497      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.887     |\n",
      "|    explained_variance   | 0.0433     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 5.85       |\n",
      "|    n_updates            | 23610      |\n",
      "|    policy_gradient_loss | 0.038      |\n",
      "|    value_loss           | 40.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2363        |\n",
      "|    time_elapsed         | 18287       |\n",
      "|    total_timesteps      | 4839424     |\n",
      "| total_reward_steps      | 73          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029166467 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.842       |\n",
      "|    n_updates            | 23620       |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    value_loss           | 6.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2364        |\n",
      "|    time_elapsed         | 18296       |\n",
      "|    total_timesteps      | 4841472     |\n",
      "| total_reward_steps      | 106         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035693813 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0909      |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2365       |\n",
      "|    time_elapsed         | 18305      |\n",
      "|    total_timesteps      | 4843520    |\n",
      "| total_reward_steps      | 89         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05787629 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.612     |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.82       |\n",
      "|    n_updates            | 23640      |\n",
      "|    policy_gradient_loss | 0.0135     |\n",
      "|    value_loss           | 2.03       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2366        |\n",
      "|    time_elapsed         | 18314       |\n",
      "|    total_timesteps      | 4845568     |\n",
      "| total_reward_steps      | 111         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014962564 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0799      |\n",
      "|    n_updates            | 23650       |\n",
      "|    policy_gradient_loss | 0.0028      |\n",
      "|    value_loss           | 0.492       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2367        |\n",
      "|    time_elapsed         | 18324       |\n",
      "|    total_timesteps      | 4847616     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015347108 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.026       |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2368        |\n",
      "|    time_elapsed         | 18332       |\n",
      "|    total_timesteps      | 4849664     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016936252 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | 0.00499     |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2369        |\n",
      "|    time_elapsed         | 18341       |\n",
      "|    total_timesteps      | 4851712     |\n",
      "| total_reward_steps      | 223         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014732283 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.735      |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.121       |\n",
      "|    n_updates            | 23680       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    value_loss           | 0.972       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2370        |\n",
      "|    time_elapsed         | 18350       |\n",
      "|    total_timesteps      | 4853760     |\n",
      "| total_reward_steps      | 110         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056961894 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.677       |\n",
      "|    n_updates            | 23690       |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2371        |\n",
      "|    time_elapsed         | 18359       |\n",
      "|    total_timesteps      | 4855808     |\n",
      "| total_reward_steps      | 99          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048011344 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 23700       |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    value_loss           | 2.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2372        |\n",
      "|    time_elapsed         | 18368       |\n",
      "|    total_timesteps      | 4857856     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022515591 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0506      |\n",
      "|    n_updates            | 23710       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    value_loss           | 0.323       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2373        |\n",
      "|    time_elapsed         | 18378       |\n",
      "|    total_timesteps      | 4859904     |\n",
      "| total_reward_steps      | 96          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022591028 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | -0.0651     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0647      |\n",
      "|    n_updates            | 23720       |\n",
      "|    policy_gradient_loss | 0.00417     |\n",
      "|    value_loss           | 0.281       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 2374      |\n",
      "|    time_elapsed         | 18387     |\n",
      "|    total_timesteps      | 4861952   |\n",
      "| total_reward_steps      | 23        |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3056264 |\n",
      "|    clip_fraction        | 0.57      |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.5      |\n",
      "|    explained_variance   | 0.0234    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 7.61      |\n",
      "|    n_updates            | 23730     |\n",
      "|    policy_gradient_loss | 0.0667    |\n",
      "|    value_loss           | 52.7      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2375        |\n",
      "|    time_elapsed         | 18396       |\n",
      "|    total_timesteps      | 4864000     |\n",
      "| total_reward_steps      | 21          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035997983 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.94        |\n",
      "|    n_updates            | 23740       |\n",
      "|    policy_gradient_loss | 0.0224      |\n",
      "|    value_loss           | 2.65        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2376       |\n",
      "|    time_elapsed         | 18405      |\n",
      "|    total_timesteps      | 4866048    |\n",
      "| total_reward_steps      | 62         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06489504 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.544     |\n",
      "|    explained_variance   | -0.043     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 98.8       |\n",
      "|    n_updates            | 23750      |\n",
      "|    policy_gradient_loss | 0.0293     |\n",
      "|    value_loss           | 8.79       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2377        |\n",
      "|    time_elapsed         | 18414       |\n",
      "|    total_timesteps      | 4868096     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036883794 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.703      |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.126       |\n",
      "|    n_updates            | 23760       |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    value_loss           | 2.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2378        |\n",
      "|    time_elapsed         | 18423       |\n",
      "|    total_timesteps      | 4870144     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029555468 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.3         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.353       |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    value_loss           | 0.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2379        |\n",
      "|    time_elapsed         | 18433       |\n",
      "|    total_timesteps      | 4872192     |\n",
      "| total_reward_steps      | 24          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027959736 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | -0.0536     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.173       |\n",
      "|    n_updates            | 23780       |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    value_loss           | 0.775       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2380       |\n",
      "|    time_elapsed         | 18441      |\n",
      "|    total_timesteps      | 4874240    |\n",
      "| total_reward_steps      | 50         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01733491 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.588     |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.041      |\n",
      "|    n_updates            | 23790      |\n",
      "|    policy_gradient_loss | 0.00172    |\n",
      "|    value_loss           | 0.113      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2381        |\n",
      "|    time_elapsed         | 18450       |\n",
      "|    total_timesteps      | 4876288     |\n",
      "| total_reward_steps      | 47          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013558801 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.167       |\n",
      "|    n_updates            | 23800       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    value_loss           | 0.122       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 18458       |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017486941 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.101       |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00997    |\n",
      "|    value_loss           | 0.121       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2383        |\n",
      "|    time_elapsed         | 18467       |\n",
      "|    total_timesteps      | 4880384     |\n",
      "| total_reward_steps      | 97          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012526709 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.025       |\n",
      "|    n_updates            | 23820       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    value_loss           | 0.074       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2384        |\n",
      "|    time_elapsed         | 18475       |\n",
      "|    total_timesteps      | 4882432     |\n",
      "| total_reward_steps      | 63          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043928593 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.756      |\n",
      "|    explained_variance   | 0.371       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 23830       |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    value_loss           | 1.88        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2385        |\n",
      "|    time_elapsed         | 18484       |\n",
      "|    total_timesteps      | 4884480     |\n",
      "| total_reward_steps      | 22          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018761955 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.0895      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.162       |\n",
      "|    n_updates            | 23840       |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    value_loss           | 0.387       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2386        |\n",
      "|    time_elapsed         | 18492       |\n",
      "|    total_timesteps      | 4886528     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013353698 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 23850       |\n",
      "|    policy_gradient_loss | 5.06e-05    |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2387        |\n",
      "|    time_elapsed         | 18500       |\n",
      "|    total_timesteps      | 4888576     |\n",
      "| total_reward_steps      | 48          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014145581 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.608      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.135       |\n",
      "|    n_updates            | 23860       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 0.116       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2388        |\n",
      "|    time_elapsed         | 18508       |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| total_reward_steps      | 20          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027316216 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.768      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0904      |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    value_loss           | 0.595       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2389        |\n",
      "|    time_elapsed         | 18517       |\n",
      "|    total_timesteps      | 4892672     |\n",
      "| total_reward_steps      | 93          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016773447 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00664     |\n",
      "|    n_updates            | 23880       |\n",
      "|    policy_gradient_loss | -0.000812   |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2390        |\n",
      "|    time_elapsed         | 18526       |\n",
      "|    total_timesteps      | 4894720     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019960728 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0497      |\n",
      "|    n_updates            | 23890       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    value_loss           | 0.803       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 2391        |\n",
      "|    time_elapsed         | 18535       |\n",
      "|    total_timesteps      | 4896768     |\n",
      "| total_reward_steps      | 36          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020596026 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 23900       |\n",
      "|    policy_gradient_loss | 0.00717     |\n",
      "|    value_loss           | 0.622       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 264        |\n",
      "|    iterations           | 2392       |\n",
      "|    time_elapsed         | 18543      |\n",
      "|    total_timesteps      | 4898816    |\n",
      "| total_reward_steps      | 87         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03941317 |\n",
      "|    clip_fraction        | 0.397      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.714     |\n",
      "|    explained_variance   | -0.0901    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.316      |\n",
      "|    n_updates            | 23910      |\n",
      "|    policy_gradient_loss | 0.024      |\n",
      "|    value_loss           | 9.18       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=28.67 +/- 9.44\n",
      "Episode length: 768.20 +/- 161.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 768         |\n",
      "|    mean_reward          | 28.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4900000     |\n",
      "| total_reward_steps      | 117         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019421322 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.743      |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0392      |\n",
      "|    n_updates            | 23920       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 0.181       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 263     |\n",
      "|    iterations      | 2393    |\n",
      "|    time_elapsed    | 18589   |\n",
      "|    total_timesteps | 4900864 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2394        |\n",
      "|    time_elapsed         | 18598       |\n",
      "|    total_timesteps      | 4902912     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026864119 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.889      |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0604      |\n",
      "|    n_updates            | 23930       |\n",
      "|    policy_gradient_loss | 0.0224      |\n",
      "|    value_loss           | 1.69        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 18607       |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032857414 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | 0.00506     |\n",
      "|    value_loss           | 0.681       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2396        |\n",
      "|    time_elapsed         | 18616       |\n",
      "|    total_timesteps      | 4907008     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034227557 |\n",
      "|    clip_fraction        | 0.35        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 23950       |\n",
      "|    policy_gradient_loss | 0.000723    |\n",
      "|    value_loss           | 0.165       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2397        |\n",
      "|    time_elapsed         | 18625       |\n",
      "|    total_timesteps      | 4909056     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014052926 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0255      |\n",
      "|    n_updates            | 23960       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 0.129       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2398        |\n",
      "|    time_elapsed         | 18634       |\n",
      "|    total_timesteps      | 4911104     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013657145 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0372      |\n",
      "|    n_updates            | 23970       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 0.126       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2399        |\n",
      "|    time_elapsed         | 18643       |\n",
      "|    total_timesteps      | 4913152     |\n",
      "| total_reward_steps      | 62          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907332 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0538      |\n",
      "|    n_updates            | 23980       |\n",
      "|    policy_gradient_loss | -0.00806    |\n",
      "|    value_loss           | 0.137       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2400        |\n",
      "|    time_elapsed         | 18653       |\n",
      "|    total_timesteps      | 4915200     |\n",
      "| total_reward_steps      | 72          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026932605 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36        |\n",
      "|    n_updates            | 23990       |\n",
      "|    policy_gradient_loss | 0.0073      |\n",
      "|    value_loss           | 2.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2401        |\n",
      "|    time_elapsed         | 18662       |\n",
      "|    total_timesteps      | 4917248     |\n",
      "| total_reward_steps      | 53          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026385635 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.682      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 24000       |\n",
      "|    policy_gradient_loss | 0.00651     |\n",
      "|    value_loss           | 0.434       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 18671       |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024862446 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.655      |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0809      |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 0.175       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2403        |\n",
      "|    time_elapsed         | 18680       |\n",
      "|    total_timesteps      | 4921344     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013330243 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0301      |\n",
      "|    n_updates            | 24020       |\n",
      "|    policy_gradient_loss | 0.00277     |\n",
      "|    value_loss           | 0.621       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2404        |\n",
      "|    time_elapsed         | 18689       |\n",
      "|    total_timesteps      | 4923392     |\n",
      "| total_reward_steps      | 30          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011309983 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.782      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.037       |\n",
      "|    n_updates            | 24030       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 0.0796      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2405        |\n",
      "|    time_elapsed         | 18699       |\n",
      "|    total_timesteps      | 4925440     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011269074 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.775      |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.023       |\n",
      "|    n_updates            | 24040       |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    value_loss           | 0.111       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 18708       |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017605115 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.112       |\n",
      "|    n_updates            | 24050       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    value_loss           | 0.579       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2407        |\n",
      "|    time_elapsed         | 18717       |\n",
      "|    total_timesteps      | 4929536     |\n",
      "| total_reward_steps      | 54          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014242945 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0514      |\n",
      "|    n_updates            | 24060       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    value_loss           | 0.0768      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2408        |\n",
      "|    time_elapsed         | 18726       |\n",
      "|    total_timesteps      | 4931584     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013425313 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0161      |\n",
      "|    n_updates            | 24070       |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    value_loss           | 0.374       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2409        |\n",
      "|    time_elapsed         | 18736       |\n",
      "|    total_timesteps      | 4933632     |\n",
      "| total_reward_steps      | 82          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595109 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 24080       |\n",
      "|    policy_gradient_loss | -0.00981    |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2410        |\n",
      "|    time_elapsed         | 18745       |\n",
      "|    total_timesteps      | 4935680     |\n",
      "| total_reward_steps      | 67          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018475853 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0318      |\n",
      "|    n_updates            | 24090       |\n",
      "|    policy_gradient_loss | -0.00976    |\n",
      "|    value_loss           | 0.223       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2411       |\n",
      "|    time_elapsed         | 18754      |\n",
      "|    total_timesteps      | 4937728    |\n",
      "| total_reward_steps      | 85         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01450594 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.781     |\n",
      "|    explained_variance   | 0.726      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.266      |\n",
      "|    n_updates            | 24100      |\n",
      "|    policy_gradient_loss | -0.00299   |\n",
      "|    value_loss           | 0.334      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 18763       |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| total_reward_steps      | 64          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031134903 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2413        |\n",
      "|    time_elapsed         | 18772       |\n",
      "|    total_timesteps      | 4941824     |\n",
      "| total_reward_steps      | 79          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015480135 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.954      |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0445      |\n",
      "|    n_updates            | 24120       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.133       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2414        |\n",
      "|    time_elapsed         | 18782       |\n",
      "|    total_timesteps      | 4943872     |\n",
      "| total_reward_steps      | 55          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012453234 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.864      |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00274     |\n",
      "|    n_updates            | 24130       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 0.13        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2415        |\n",
      "|    time_elapsed         | 18791       |\n",
      "|    total_timesteps      | 4945920     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013658682 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0421      |\n",
      "|    n_updates            | 24140       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 0.113       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2416        |\n",
      "|    time_elapsed         | 18799       |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| total_reward_steps      | 61          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010517613 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00788    |\n",
      "|    n_updates            | 24150       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    value_loss           | 0.118       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2417        |\n",
      "|    time_elapsed         | 18808       |\n",
      "|    total_timesteps      | 4950016     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011917107 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 24160       |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    value_loss           | 0.717       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2418       |\n",
      "|    time_elapsed         | 18817      |\n",
      "|    total_timesteps      | 4952064    |\n",
      "| total_reward_steps      | 49         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666169 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.806     |\n",
      "|    explained_variance   | 0.653      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0219     |\n",
      "|    n_updates            | 24170      |\n",
      "|    policy_gradient_loss | -0.00393   |\n",
      "|    value_loss           | 0.123      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 18825       |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010477776 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.843      |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00504     |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 0.0996      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2420       |\n",
      "|    time_elapsed         | 18834      |\n",
      "|    total_timesteps      | 4956160    |\n",
      "| total_reward_steps      | 47         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00926806 |\n",
      "|    clip_fraction        | 0.288      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.877     |\n",
      "|    explained_variance   | 0.845      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.108      |\n",
      "|    n_updates            | 24190      |\n",
      "|    policy_gradient_loss | -0.00637   |\n",
      "|    value_loss           | 0.11       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2421        |\n",
      "|    time_elapsed         | 18843       |\n",
      "|    total_timesteps      | 4958208     |\n",
      "| total_reward_steps      | 71          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008783248 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.103       |\n",
      "|    n_updates            | 24200       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    value_loss           | 0.12        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2422        |\n",
      "|    time_elapsed         | 18852       |\n",
      "|    total_timesteps      | 4960256     |\n",
      "| total_reward_steps      | 35          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015257078 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.118       |\n",
      "|    n_updates            | 24210       |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.109       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2423        |\n",
      "|    time_elapsed         | 18861       |\n",
      "|    total_timesteps      | 4962304     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013576014 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 24220       |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    value_loss           | 0.0749      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2424        |\n",
      "|    time_elapsed         | 18870       |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008743521 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00616     |\n",
      "|    n_updates            | 24230       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.0916      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 263          |\n",
      "|    iterations           | 2425         |\n",
      "|    time_elapsed         | 18879        |\n",
      "|    total_timesteps      | 4966400      |\n",
      "| total_reward_steps      | 32           |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143164545 |\n",
      "|    clip_fraction        | 0.268        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 0.0349       |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 0.0719       |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 263         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 18888       |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| total_reward_steps      | 52          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039083786 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0284      |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 0.0839      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2427       |\n",
      "|    time_elapsed         | 18897      |\n",
      "|    total_timesteps      | 4970496    |\n",
      "| total_reward_steps      | 37         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01471178 |\n",
      "|    clip_fraction        | 0.366      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.962     |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0174     |\n",
      "|    n_updates            | 24260      |\n",
      "|    policy_gradient_loss | -0.00219   |\n",
      "|    value_loss           | 0.579      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 2428       |\n",
      "|    time_elapsed         | 18906      |\n",
      "|    total_timesteps      | 4972544    |\n",
      "| total_reward_steps      | 37         |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01936666 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.918     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | -0.0203    |\n",
      "|    n_updates            | 24270      |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    value_loss           | 0.0767     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2429        |\n",
      "|    time_elapsed         | 18915       |\n",
      "|    total_timesteps      | 4974592     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013443162 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00713     |\n",
      "|    n_updates            | 24280       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    value_loss           | 0.0768      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2430        |\n",
      "|    time_elapsed         | 18924       |\n",
      "|    total_timesteps      | 4976640     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014390947 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.017       |\n",
      "|    n_updates            | 24290       |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.0814      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2431        |\n",
      "|    time_elapsed         | 18933       |\n",
      "|    total_timesteps      | 4978688     |\n",
      "| total_reward_steps      | 41          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011310738 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00485     |\n",
      "|    n_updates            | 24300       |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.0753      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2432        |\n",
      "|    time_elapsed         | 18943       |\n",
      "|    total_timesteps      | 4980736     |\n",
      "| total_reward_steps      | 45          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012441375 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 24310       |\n",
      "|    policy_gradient_loss | -0.00763    |\n",
      "|    value_loss           | 0.0767      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2433        |\n",
      "|    time_elapsed         | 18952       |\n",
      "|    total_timesteps      | 4982784     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012240786 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.803      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.214       |\n",
      "|    n_updates            | 24320       |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 0.0843      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2434        |\n",
      "|    time_elapsed         | 18962       |\n",
      "|    total_timesteps      | 4984832     |\n",
      "| total_reward_steps      | 37          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007398597 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.898      |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0467      |\n",
      "|    n_updates            | 24330       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.0438      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2435        |\n",
      "|    time_elapsed         | 18971       |\n",
      "|    total_timesteps      | 4986880     |\n",
      "| total_reward_steps      | 44          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012201333 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00615    |\n",
      "|    n_updates            | 24340       |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.0912      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2436        |\n",
      "|    time_elapsed         | 18981       |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| total_reward_steps      | 59          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019228023 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.852      |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.033       |\n",
      "|    n_updates            | 24350       |\n",
      "|    policy_gradient_loss | 0.00406     |\n",
      "|    value_loss           | 1.66        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2437        |\n",
      "|    time_elapsed         | 18990       |\n",
      "|    total_timesteps      | 4990976     |\n",
      "| total_reward_steps      | 58          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016168673 |\n",
      "|    clip_fraction        | 0.405       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.982      |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 24360       |\n",
      "|    policy_gradient_loss | 0.00403     |\n",
      "|    value_loss           | 0.402       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2438        |\n",
      "|    time_elapsed         | 19000       |\n",
      "|    total_timesteps      | 4993024     |\n",
      "| total_reward_steps      | 34          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012244763 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 24370       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 0.0841      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2439        |\n",
      "|    time_elapsed         | 19009       |\n",
      "|    total_timesteps      | 4995072     |\n",
      "| total_reward_steps      | 85          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016961802 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.944      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.00902     |\n",
      "|    n_updates            | 24380       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 19018       |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| total_reward_steps      | 42          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014929086 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0265      |\n",
      "|    n_updates            | 24390       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 0.384       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 262         |\n",
      "|    iterations           | 2441        |\n",
      "|    time_elapsed         | 19028       |\n",
      "|    total_timesteps      | 4999168     |\n",
      "| total_reward_steps      | 43          |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009371099 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | -0.00683    |\n",
      "|    n_updates            | 24400       |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    value_loss           | 0.0609      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=41.37 +/- 9.92\n",
      "Episode length: 1108.00 +/- 130.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.11e+03     |\n",
      "|    mean_reward          | 41.4         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105605805 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -0.819       |\n",
      "|    explained_variance   | 0.89         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | -0.0197      |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    value_loss           | 0.0753       |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 261      |\n",
      "|    iterations      | 2442     |\n",
      "|    time_elapsed    | 19091    |\n",
      "|    total_timesteps | 5001216  |\n",
      "| total_reward_steps | 61       |\n",
      "---------------------------------\n",
      "Start evaluation Nr. 0:\n",
      "Episode 1 Reward: [245.]\n",
      "Episode 2 Reward: [119.]\n",
      "Episode 3 Reward: [250.]\n",
      "Episode 4 Reward: [402.]\n",
      "Episode 5 Reward: [240.]\n",
      "Episode 6 Reward: [234.]\n",
      "Episode 7 Reward: [251.]\n",
      "Episode 8 Reward: [56.]\n",
      "Episode 9 Reward: [117.]\n",
      "Episode 10 Reward: [405.]\n",
      "Episode 11 Reward: [98.]\n",
      "Episode 12 Reward: [102.]\n",
      "Episode 13 Reward: [252.]\n",
      "Episode 14 Reward: [252.]\n",
      "Episode 15 Reward: [175.]\n",
      "Episode 16 Reward: [251.]\n",
      "Episode 17 Reward: [268.]\n",
      "Episode 18 Reward: [268.]\n",
      "Episode 19 Reward: [97.]\n",
      "Episode 20 Reward: [252.]\n",
      "Episode 21 Reward: [241.]\n",
      "Episode 22 Reward: [246.]\n",
      "Episode 23 Reward: [101.]\n",
      "Episode 24 Reward: [85.]\n",
      "Episode 25 Reward: [253.]\n",
      "Episode 26 Reward: [237.]\n",
      "Episode 27 Reward: [402.]\n",
      "Episode 28 Reward: [245.]\n",
      "Episode 29 Reward: [161.]\n",
      "Episode 30 Reward: [273.]\n",
      "Durchschnittliche Belohnung: 219.26666\n",
      "Standardabweichung der Belohnungen: 90.8559\n"
     ]
    }
   ],
   "source": [
    "for i in range(loop_start, 1):\n",
    "    if i != 1 or i != 3 or i != 6:\n",
    "        hparam_callback = HParamCallback()\n",
    "        reward_callback = RewardTensorboardCallback()\n",
    "        eval_callback = CustomEvalCallback(eval_env, best_model_save_path=f\"{BEST_MODEL_DIR}{str(i)}/\",\n",
    "                                          log_path=f\"{BEST_MODEL_LOG_DIR}{str(i)}/\", eval_freq=custom_eval_freq,\n",
    "                                          deterministic=True, render=False, n_eval_episodes=eval_episodes)\n",
    "        callback_list = CallbackList([eval_callback, reward_callback, hparam_callback])\n",
    "\n",
    "        learning_rate = 0.0001\n",
    "        gamma = 0.95\n",
    "        batch_size = 32\n",
    "        ent_coef = 0.01\n",
    "\n",
    "        # Modell erstellen\n",
    "        model = PPO('CnnPolicy', env, gamma=gamma, learning_rate=learning_rate, verbose=2,            \n",
    "                batch_size=batch_size, tensorboard_log=f\"{LOG_DIR}{str(i)}/\",\n",
    "                ent_coef=ent_coef, vf_coef=vf_coef, clip_range=clip_range)\n",
    "\n",
    "        # Modell trainieren\n",
    "        model.learn(total_timesteps=training_steps, callback=callback_list)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "        # Bestes Modell laden\n",
    "        best_model = PPO.load(f\"{BEST_MODEL_DIR}{i}/{MODEL_WEIGHTS_FILE}\")\n",
    "\n",
    "        # Modell evaluieren\n",
    "        observation = env.reset()\n",
    "        episodes = 0\n",
    "        done = False\n",
    "        all_rewards = []\n",
    "        total_reward = 0\n",
    "\n",
    "        print(f\"Start evaluation Nr. {i}:\")\n",
    "\n",
    "        while episodes < eval_episodes:\n",
    "            if done:\n",
    "                observation = env.reset()\n",
    "                all_rewards.append(total_reward)\n",
    "                episodes += 1\n",
    "                print(\"Episode\", episodes, \"Reward:\", total_reward)\n",
    "                total_reward = 0\n",
    "\n",
    "            action, _ = best_model.predict(observation, deterministic=True)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "        env.reset()\n",
    "\n",
    "        del best_model\n",
    "        gc.collect()\n",
    "\n",
    "        mean_reward = np.mean(all_rewards)\n",
    "        std_reward = np.std(all_rewards)\n",
    "\n",
    "        print(\"Durchschnittliche Belohnung:\", mean_reward)\n",
    "        print(\"Standardabweichung der Belohnungen:\", std_reward)\n",
    "\n",
    "        # Ergebnisse in CSV-Datei schreiben\n",
    "        neue_zeile = [i, mean_reward, std_reward]\n",
    "\n",
    "        with open(ergebnisse_path, 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(neue_zeile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c92e0-2237-40fb-b9a6-3202734ac3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
